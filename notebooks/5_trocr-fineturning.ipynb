{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12001849,"sourceType":"datasetVersion","datasetId":7549834},{"sourceId":470387,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":379478,"modelId":399409}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/htrnguyen/compare_ocr_benchmark.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-13T15:00:11.746923Z","iopub.execute_input":"2025-07-13T15:00:11.747089Z","iopub.status.idle":"2025-07-13T15:00:11.894278Z","shell.execute_reply.started":"2025-07-13T15:00:11.747075Z","shell.execute_reply":"2025-07-13T15:00:11.893566Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'compare_ocr_benchmark' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install python-Levenshtein jiwer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T15:00:11.895298Z","iopub.execute_input":"2025-07-13T15:00:11.895596Z","iopub.status.idle":"2025-07-13T15:00:14.957190Z","shell.execute_reply.started":"2025-07-13T15:00:11.895568Z","shell.execute_reply":"2025-07-13T15:00:14.956171Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.11/dist-packages (0.27.1)\nRequirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (4.0.0)\nRequirement already satisfied: Levenshtein==0.27.1 in /usr/local/lib/python3.11/dist-packages (from python-Levenshtein) (0.27.1)\nRequirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.13.0)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.2.1)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import sys, os, time\nimport pandas as pd\nimport torch\nfrom PIL import Image\nfrom transformers import VisionEncoderDecoderModel, TrOCRProcessor\n\n# Đảm bảo sys.path tới các hàm utils và metrics chung\nsys.path.append('/kaggle/working/compare_ocr_benchmark/common')\nfrom metrics import compute_metrics\nfrom utils import save_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T15:00:14.958326Z","iopub.execute_input":"2025-07-13T15:00:14.958599Z","iopub.status.idle":"2025-07-13T15:00:14.963732Z","shell.execute_reply.started":"2025-07-13T15:00:14.958572Z","shell.execute_reply":"2025-07-13T15:00:14.962897Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Đường dẫn data/model\nDATA_ROOT = '/kaggle/input/nckh-2425-crops'\nCSV_ANN = '/kaggle/input/nckh-2425-crops/crops_gt.csv'\nMODEL_PATH = '/kaggle/input/trocr_fineturning/pytorch/default/1/final_model'\n\n# Load model và processor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\nmodel = VisionEncoderDecoderModel.from_pretrained(MODEL_PATH).to(device)\nprocessor = TrOCRProcessor.from_pretrained(MODEL_PATH)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T15:00:19.268401Z","iopub.execute_input":"2025-07-13T15:00:19.269214Z","iopub.status.idle":"2025-07-13T15:00:34.281365Z","shell.execute_reply.started":"2025-07-13T15:00:19.269187Z","shell.execute_reply":"2025-07-13T15:00:34.280577Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n/usr/local/lib/python3.11/dist-packages/transformers/models/vit/feature_extraction_vit.py:30: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"VisionEncoderDecoderModel(\n  (encoder): ViTModel(\n    (embeddings): ViTEmbeddings(\n      (patch_embeddings): ViTPatchEmbeddings(\n        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): ViTEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=False)\n              (key): Linear(in_features=768, out_features=768, bias=False)\n              (value): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (pooler): ViTPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (decoder): TrOCRForCausalLM(\n    (model): TrOCRDecoderWrapper(\n      (decoder): TrOCRDecoder(\n        (embed_tokens): TrOCRScaledWordEmbedding(50265, 1024, padding_idx=1)\n        (embed_positions): TrOCRLearnedPositionalEmbedding(514, 1024)\n        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (layers): ModuleList(\n          (0-11): 12 x TrOCRDecoderLayer(\n            (self_attn): TrOCRAttention(\n              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): TrOCRAttention(\n              (k_proj): Linear(in_features=768, out_features=1024, bias=True)\n              (v_proj): Linear(in_features=768, out_features=1024, bias=True)\n              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n      )\n    )\n    (output_projection): Linear(in_features=1024, out_features=50265, bias=False)\n  )\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def load_and_correct_image(img_path):\n    image = Image.open(img_path).convert(\"RGB\")\n    try:\n        exif = image._getexif()\n        orientation_key = 274\n        if exif and orientation_key in exif:\n            orientation = exif[orientation_key]\n            if orientation == 3:\n                image = image.rotate(180, expand=True)\n            elif orientation == 6:\n                image = image.rotate(270, expand=True)\n            elif orientation == 8:\n                image = image.rotate(90, expand=True)\n    except:\n        pass\n    return image\n\ndef trocr_predict(img_path):\n    image = load_and_correct_image(img_path)\n    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n    with torch.no_grad():\n        generated_ids = model.generate(pixel_values)\n        prediction = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    return prediction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T15:00:42.413225Z","iopub.execute_input":"2025-07-13T15:00:42.413965Z","iopub.status.idle":"2025-07-13T15:00:42.422177Z","shell.execute_reply.started":"2025-07-13T15:00:42.413930Z","shell.execute_reply":"2025-07-13T15:00:42.421302Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df = pd.read_csv(CSV_ANN)\nresults = []\n\nfor idx, row in df.iterrows():\n    fname = row['filename']\n    desc_gt = row['description_gt']\n    label = row.get('label', '')\n    img_path = os.path.join(DATA_ROOT, fname)\n\n    try:\n        t1 = time.perf_counter()\n        pred = trocr_predict(img_path)\n        t2 = time.perf_counter()\n        infer_time = round(t2 - t1, 3)\n    except Exception as e:\n        pred = f\"OCR_Error: {e}\"\n        infer_time = 0.0\n\n    metrics = compute_metrics(desc_gt, pred)\n\n    results.append({\n        \"filename\": fname,\n        \"label\": label,\n        \"ground_truth\": desc_gt,\n        \"predicted_text\": pred,\n        \"cer\": metrics[\"cer\"],\n        \"wer\": metrics[\"wer\"],\n        \"lev\": metrics[\"lev\"],\n        \"acc\": metrics[\"acc\"],\n        \"time\": infer_time\n    })\n    if idx % 50 == 0:\n        print(f\"Processed {idx}/{len(df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T15:00:48.939981Z","iopub.execute_input":"2025-07-13T15:00:48.940781Z","iopub.status.idle":"2025-07-13T15:06:33.376785Z","shell.execute_reply.started":"2025-07-13T15:00:48.940745Z","shell.execute_reply":"2025-07-13T15:06:33.375847Z"}},"outputs":[{"name":"stdout","text":"Processed 0/2284\nProcessed 50/2284\nProcessed 100/2284\nProcessed 150/2284\nProcessed 200/2284\nProcessed 250/2284\nProcessed 300/2284\nProcessed 350/2284\nProcessed 400/2284\nProcessed 450/2284\nProcessed 500/2284\nProcessed 550/2284\nProcessed 600/2284\nProcessed 650/2284\nProcessed 700/2284\nProcessed 750/2284\nProcessed 800/2284\nProcessed 850/2284\nProcessed 900/2284\nProcessed 950/2284\nProcessed 1000/2284\nProcessed 1050/2284\nProcessed 1100/2284\nProcessed 1150/2284\nProcessed 1200/2284\nProcessed 1250/2284\nProcessed 1300/2284\nProcessed 1350/2284\nProcessed 1400/2284\nProcessed 1450/2284\nProcessed 1500/2284\nProcessed 1550/2284\nProcessed 1600/2284\nProcessed 1650/2284\nProcessed 1700/2284\nProcessed 1750/2284\nProcessed 1800/2284\nProcessed 1850/2284\nProcessed 1900/2284\nProcessed 1950/2284\nProcessed 2000/2284\nProcessed 2050/2284\nProcessed 2100/2284\nProcessed 2150/2284\nProcessed 2200/2284\nProcessed 2250/2284\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os\nOUT_CSV = '/kaggle/working/compare_ocr_benchmark/results/trocr_pretrain_results.csv'\nos.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\nsave_results(results, OUT_CSV)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T15:06:33.378023Z","iopub.execute_input":"2025-07-13T15:06:33.378274Z","iopub.status.idle":"2025-07-13T15:06:33.406613Z","shell.execute_reply.started":"2025-07-13T15:06:33.378246Z","shell.execute_reply":"2025-07-13T15:06:33.406019Z"}},"outputs":[{"name":"stdout","text":"Lưu thành công: /kaggle/working/compare_ocr_benchmark/results/trocr_pretrain_results.csv\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}