{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-13T10:39:53.463534Z",
     "iopub.status.busy": "2025-07-13T10:39:53.462882Z",
     "iopub.status.idle": "2025-07-13T10:39:54.126293Z",
     "shell.execute_reply": "2025-07-13T10:39:54.125357Z",
     "shell.execute_reply.started": "2025-07-13T10:39:53.463504Z"
    },
    "id": "2shp8luNQR8U",
    "outputId": "db528f5c-6e38-4c49-dc0e-a4d510970b9c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'compare_ocr_benchmark'...\n",
      "remote: Enumerating objects: 58, done.\u001b[K\n",
      "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
      "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
      "remote: Total 58 (delta 23), reused 49 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (58/58), 2.18 MiB | 25.97 MiB/s, done.\n",
      "Resolving deltas: 100% (23/23), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/htrnguyen/compare_ocr_benchmark.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-13T10:33:49.127539Z",
     "iopub.status.busy": "2025-07-13T10:33:49.127261Z",
     "iopub.status.idle": "2025-07-13T10:33:52.635867Z",
     "shell.execute_reply": "2025-07-13T10:33:52.635180Z",
     "shell.execute_reply.started": "2025-07-13T10:33:49.127501Z"
    },
    "id": "RxSoPHiWQc8Y",
    "outputId": "409485bb-0d53-4882-ba6f-824341f38b37",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.11/dist-packages (0.27.1)\n",
      "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.165)\n",
      "Requirement already satisfied: Levenshtein==0.27.1 in /usr/local/lib/python3.11/dist-packages (from python-Levenshtein) (0.27.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.13.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.2.1)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein jiwer ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T10:39:56.995642Z",
     "iopub.status.busy": "2025-07-13T10:39:56.995340Z",
     "iopub.status.idle": "2025-07-13T10:39:57.126188Z",
     "shell.execute_reply": "2025-07-13T10:39:57.125660Z",
     "shell.execute_reply.started": "2025-07-13T10:39:56.995618Z"
    },
    "id": "8X4ExihcUI07",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Đảm bảo các module custom có trong sys.path\n",
    "sys.path.append('/kaggle/working/compare_ocr_benchmark/CNN_TR_OCR_Resnet')\n",
    "\n",
    "from dataset_polygon import char2idx, idx2char\n",
    "from model_cnn_transformer import OCRModel\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Nếu dùng file chung cho tiền xử lý/metrics/utils thì thêm:\n",
    "sys.path.append('/kaggle/working/compare_ocr_benchmark/common')\n",
    "from metrics import compute_metrics\n",
    "from utils import read_annotations, save_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T10:40:43.078482Z",
     "iopub.status.busy": "2025-07-13T10:40:43.077823Z",
     "iopub.status.idle": "2025-07-13T10:40:43.082049Z",
     "shell.execute_reply": "2025-07-13T10:40:43.081414Z",
     "shell.execute_reply.started": "2025-07-13T10:40:43.078458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dữ liệu trên Kaggle:\n",
    "IMG_DIR = '/kaggle/input/nckh-2425-crops'\n",
    "CSV_ANN = '/kaggle/input/nckh-2425-crops/crops_gt.csv'\n",
    "\n",
    "# Đường dẫn model trong working dir (nên copy model vào đây trước)\n",
    "YOLO_MODEL_PATH = '/kaggle/input/cnn_tr_ocr_resnet/pytorch/default/1/best.pt'\n",
    "OCR_MODEL_PATH = '/kaggle/input/cnn_tr_ocr_resnet/pytorch/default/1/best_ocr_model.pth'\n",
    "FONT_PATH = \"/kaggle/working/compare_ocr_benchmark/CNN_TR_OCR_Resnet/Roboto-Regular.ttf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T10:40:51.483547Z",
     "iopub.status.busy": "2025-07-13T10:40:51.483169Z",
     "iopub.status.idle": "2025-07-13T10:40:57.127382Z",
     "shell.execute_reply": "2025-07-13T10:40:57.126661Z",
     "shell.execute_reply.started": "2025-07-13T10:40:51.483518Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 214MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OCRModel(\n",
       "  (encoder): CNNEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (se1): SqueezeExcitation(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=16, bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=16, out_features=256, bias=False)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (se2): SqueezeExcitation(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=32, bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=32, out_features=512, bias=False)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (se3): SqueezeExcitation(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=64, bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=64, out_features=1024, bias=False)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (se4): SqueezeExcitation(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=128, bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=128, out_features=2048, bias=False)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (lateral_convs): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (fpn_convs): ModuleList(\n",
       "        (0-3): 4 x Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_conv): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Dropout2d(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (embedding): Embedding(231, 256)\n",
       "    (pos_encoding): VietnamesePositionalEncoding(\n",
       "      (tone_attention): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (transformer_decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (output_layer): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=231, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "VOCAB_SIZE = len(char2idx)\n",
    "\n",
    "yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "ocr_model = OCRModel(vocab_size=VOCAB_SIZE).to(DEVICE)\n",
    "ocr_model.load_state_dict(torch.load(OCR_MODEL_PATH, map_location=DEVICE))\n",
    "ocr_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T10:41:07.313260Z",
     "iopub.status.busy": "2025-07-13T10:41:07.312657Z",
     "iopub.status.idle": "2025-07-13T10:41:07.318474Z",
     "shell.execute_reply": "2025-07-13T10:41:07.317672Z",
     "shell.execute_reply.started": "2025-07-13T10:41:07.313236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def preprocess_ocr_image(pil_img):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((32, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    return transform(pil_img).unsqueeze(0)\n",
    "\n",
    "def decode_sequence(indices):\n",
    "    chars = []\n",
    "    SOS_TOKEN = next((token for token in char2idx.keys() if \"SOS\" in token), None)\n",
    "    for idx in indices:\n",
    "        ch = idx2char.get(idx, \"\")\n",
    "        if ch == \"<EOS>\":\n",
    "            break\n",
    "        if ch not in (\"<PAD>\", SOS_TOKEN):\n",
    "            chars.append(ch)\n",
    "    return \"\".join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T10:41:15.360135Z",
     "iopub.status.busy": "2025-07-13T10:41:15.359098Z",
     "iopub.status.idle": "2025-07-13T10:41:15.366959Z",
     "shell.execute_reply": "2025-07-13T10:41:15.366186Z",
     "shell.execute_reply.started": "2025-07-13T10:41:15.360093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def group_text_lines(results, y_threshold=80):\n",
    "    # Nhóm bbox thành dòng, ưu tiên trái-phải nếu 2 bbox gần nhau theo y\n",
    "    bboxes_with_text = []\n",
    "    for bbox, text in results:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        y_center = (y1 + y2) / 2\n",
    "        x_left = min(x1, x2)\n",
    "        x_right = max(x1, x2)\n",
    "        bboxes_with_text.append({\n",
    "            \"bbox\": bbox,\n",
    "            \"text\": text,\n",
    "            \"y_center\": y_center,\n",
    "            \"x_left\": x_left,\n",
    "            \"x_right\": x_right,\n",
    "        })\n",
    "\n",
    "    # Sắp xếp ban đầu theo y_center (trên xuống dưới), x_left (trái-phải)\n",
    "    bboxes_with_text.sort(key=lambda x: (x[\"y_center\"], x[\"x_left\"]))\n",
    "\n",
    "    # Gộp thành các dòng\n",
    "    lines = []\n",
    "    for item in bboxes_with_text:\n",
    "        added = False\n",
    "        for line in lines:\n",
    "            # Nếu khoảng cách y gần 1 dòng, gộp vào dòng đó\n",
    "            if any(abs(item[\"y_center\"] - i[\"y_center\"]) < y_threshold for i in line):\n",
    "                line.append(item)\n",
    "                added = True\n",
    "                break\n",
    "        if not added:\n",
    "            lines.append([item])\n",
    "    # Sort từng dòng theo x_left (trái-phải)\n",
    "    for line in lines:\n",
    "        line.sort(key=lambda x: x[\"x_left\"])\n",
    "    return lines\n",
    "\n",
    "def ocr_text_from_lines(results, y_threshold=80):\n",
    "    grouped_lines = group_text_lines(results, y_threshold)\n",
    "    # Ghép các dòng lại thành 1 string (mỗi dòng 1 phần), cách nhau dấu cách\n",
    "    lines_text = [\" \".join([item[\"text\"] for item in line]) for line in grouped_lines]\n",
    "    return \" \".join(lines_text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T10:41:22.822290Z",
     "iopub.status.busy": "2025-07-13T10:41:22.821734Z",
     "iopub.status.idle": "2025-07-13T10:41:22.829719Z",
     "shell.execute_reply": "2025-07-13T10:41:22.829048Z",
     "shell.execute_reply.started": "2025-07-13T10:41:22.822267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def yolo_ocr_pipeline(image_path, conf_threshold=0.5, y_threshold=80):\n",
    "    # 1. Detection\n",
    "    results = yolo_model(image_path)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "    confs = results[0].boxes.conf.cpu().numpy()\n",
    "    filtered = [(box, conf) for box, conf in zip(boxes, confs) if conf > conf_threshold]\n",
    "    boxes = [box for box, conf in filtered]\n",
    "\n",
    "    # 2. Crop bbox và nhận diện text từng bbox\n",
    "    img_pil = Image.open(image_path).convert(\"RGB\")\n",
    "    ocr_results = []\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        crop = img_pil.crop((x1, y1, x2, y2))\n",
    "        image_tensor = preprocess_ocr_image(crop).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            memory = ocr_model.encoder(image_tensor)\n",
    "            SOS_TOKEN = next((token for token in char2idx.keys() if \"SOS\" in token), None)\n",
    "            MAX_LEN = 36\n",
    "            ys = torch.tensor([[char2idx[SOS_TOKEN]]], device=DEVICE)\n",
    "            for _ in range(MAX_LEN):\n",
    "                out = ocr_model.decoder(\n",
    "                    ys,\n",
    "                    memory,\n",
    "                    tgt_mask=ocr_model.generate_square_subsequent_mask(ys.size(1)).to(DEVICE),\n",
    "                )\n",
    "                prob = out[:, -1, :]\n",
    "                _, next_word = torch.max(prob, dim=1)\n",
    "                ys = torch.cat([ys, next_word.unsqueeze(1)], dim=1)\n",
    "                if next_word.item() == char2idx[\"<EOS>\"]:\n",
    "                    break\n",
    "            pred_text = decode_sequence(ys.squeeze(0).tolist())\n",
    "            ocr_results.append(((x1, y1, x2, y2), pred_text))\n",
    "    # 3. Ghép kết quả theo thứ tự trái qua phải, trên xuống dưới thành 1 dòng\n",
    "    return ocr_text_from_lines(ocr_results, y_threshold=y_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T10:41:33.669784Z",
     "iopub.status.busy": "2025-07-13T10:41:33.668958Z",
     "iopub.status.idle": "2025-07-13T10:48:19.978064Z",
     "shell.execute_reply": "2025-07-13T10:48:19.976350Z",
     "shell.execute_reply.started": "2025-07-13T10:41:33.669756Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/001_heo-cao-boi_F_crop_0.jpg: 288x640 3 texts, 53.8ms\n",
      "Speed: 9.5ms preprocess, 53.8ms inference, 265.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Processed: 0/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/001_heo-cao-boi_F_crop_1.jpg: 640x640 4 texts, 9.6ms\n",
      "Speed: 3.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/001_heo-cao-boi_F_crop_2.jpg: 288x640 1 text, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/001_heo-cao-boi_F_crop_3.jpg: 288x640 1 text, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/001_heo-cao-boi_F_crop_4.jpg: 544x640 2 texts, 40.0ms\n",
      "Speed: 1.6ms preprocess, 40.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/001_heo-cao-boi_F_crop_5.jpg: 512x640 2 texts, 40.6ms\n",
      "Speed: 1.5ms preprocess, 40.6ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/002_mi-ly-modern_F_crop_0.jpg: 160x640 1 text, 38.5ms\n",
      "Speed: 0.7ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/002_mi-ly-modern_F_crop_1.jpg: 256x640 3 texts, 39.0ms\n",
      "Speed: 1.3ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/003_banh-crepe-sua-tuoi_B_crop_0.jpg: 192x640 2 texts, 38.5ms\n",
      "Speed: 1.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/003_banh-crepe-sua-tuoi_B_crop_1.jpg: 160x640 4 texts, 9.8ms\n",
      "Speed: 0.9ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/003_banh-crepe-sua-tuoi_B_crop_2.jpg: 480x640 1 text, 40.3ms\n",
      "Speed: 1.6ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/003_banh-crepe-sua-tuoi_B_crop_3.jpg: 288x640 1 text, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/003_banh-crepe-sua-tuoi_B_crop_4.jpg: 256x640 2 texts, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/003_banh-crepe-sua-tuoi_F_crop_0.jpg: 160x640 2 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/003_banh-crepe-sua-tuoi_F_crop_1.jpg: 320x640 4 texts, 41.2ms\n",
      "Speed: 1.4ms preprocess, 41.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/003_che-buoi_F_crop_0.jpg: 160x640 2 texts, 9.6ms\n",
      "Speed: 0.7ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/003_che-buoi_F_crop_1.jpg: 192x640 2 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/003_che-buoi_F_crop_2.jpg: 320x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/003_che-buoi_F_crop_3.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/003_che-buoi_F_crop_4.jpg: 128x640 1 text, 38.2ms\n",
      "Speed: 0.6ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/004_cal-cheese_F_crop_0.jpg: 224x640 1 text, 38.2ms\n",
      "Speed: 0.9ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/004_cal-cheese_F_crop_1.jpg: 640x480 2 texts, 39.8ms\n",
      "Speed: 1.7ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/004_cal-cheese_F_crop_2.jpg: 640x608 2 texts, 40.6ms\n",
      "Speed: 1.8ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/004_cal-cheese_F_crop_3.jpg: 128x640 11 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/004_cal-cheese_F_crop_4.jpg: 640x160 3 texts, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/004_cal-cheese_F_crop_5.jpg: 640x160 3 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/005_nabati_F_crop_0.jpg: 352x640 2 texts, 39.6ms\n",
      "Speed: 1.5ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/006_nabati_B_crop_0.jpg: 160x640 1 text, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/006_nabati_B_crop_1.jpg: 160x640 1 text, 8.3ms\n",
      "Speed: 0.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/007_snack-nhan-dau-phong_F_crop_0.jpg: 96x640 4 texts, 44.0ms\n",
      "Speed: 0.7ms preprocess, 44.0ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/007_snack-nhan-dau-phong_F_crop_1.jpg: 288x640 1 text, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/008_sting-vang_F_crop_0.jpg: 640x384 5 texts, 41.3ms\n",
      "Speed: 1.9ms preprocess, 41.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/009_sting-vang_B_crop_0.jpg: 640x128 (no detections), 38.8ms\n",
      "Speed: 0.7ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/009_sting-vang_B_crop_1.jpg: 640x288 2 texts, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 288)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/010_sting_F_crop_0.jpg: 640x352 15 texts, 40.4ms\n",
      "Speed: 1.8ms preprocess, 40.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 352)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/011_sting_B_crop_0.jpg: 352x640 8 texts, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 3.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/011_sting_B_crop_1.jpg: 416x640 2 texts, 39.5ms\n",
      "Speed: 2.1ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/012_banh-hoa-cuc_F_crop_0.jpg: 352x640 1 text, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/012_banh-hoa-cuc_F_crop_1.jpg: 480x640 4 texts, 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/013_snack-vi-suon-nuong_F_crop_0.jpg: 416x640 1 text, 8.7ms\n",
      "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/013_snack-vi-suon-nuong_F_crop_1.jpg: 224x640 5 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/014_mentos-keo-ngam-khong-duong_F_crop_0.jpg: 96x640 4 texts, 10.1ms\n",
      "Speed: 0.6ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/014_mentos-keo-ngam-khong-duong_F_crop_1.jpg: 160x640 1 text, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/015_mentos-keo-ngam-khong-duong_B_crop_0.jpg: 128x640 4 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/015_mentos-keo-ngam-khong-duong_B_crop_1.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/015_mentos-keo-ngam-khong-duong_B_crop_2.jpg: 480x640 2 texts, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/018_himalaya-salt_F_crop_0.jpg: 288x640 2 texts, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/018_himalaya-salt_F_crop_1.jpg: 352x640 2 texts, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 3.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/019_himalaya-salt_B_crop_0.jpg: 288x640 2 texts, 8.7ms\n",
      "Speed: 1.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/019_himalaya-salt_B_crop_1.jpg: 128x640 7 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/019_himalaya-salt_B_crop_2.jpg: 512x640 2 texts, 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processed: 50/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/019_himalaya-salt_B_crop_3.jpg: 640x192 2 texts, 40.3ms\n",
      "Speed: 0.9ms preprocess, 40.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/019_himalaya-salt_B_crop_4.jpg: 640x224 3 texts, 39.8ms\n",
      "Speed: 0.9ms preprocess, 39.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/019_himalaya-salt_B_crop_5.jpg: 416x640 1 text, 8.6ms\n",
      "Speed: 2.5ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/020_marshmallows_F_crop_0.jpg: 448x640 2 texts, 39.0ms\n",
      "Speed: 2.1ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/021_marshmallows_F_crop_0.jpg: 608x640 2 texts, 46.8ms\n",
      "Speed: 2.9ms preprocess, 46.8ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/021_marshmallows_F_crop_1.jpg: 448x640 3 texts, 8.9ms\n",
      "Speed: 1.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/022_marshmallows_B_crop_0.jpg: 352x640 1 text, 9.6ms\n",
      "Speed: 1.3ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/022_marshmallows_B_crop_1.jpg: 256x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/022_marshmallows_B_crop_2.jpg: 64x640 7 texts, 36.0ms\n",
      "Speed: 0.4ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 64, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/023_lap-xuong_F_crop_0.jpg: 224x640 2 texts, 9.1ms\n",
      "Speed: 1.3ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/023_lap-xuong_F_crop_1.jpg: 320x640 1 text, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/024_lap-xuong_B_crop_0.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/024_lap-xuong_B_crop_1.jpg: 192x640 1 text, 8.4ms\n",
      "Speed: 0.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/025_rong-bien_F_crop_0.jpg: 224x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/025_rong-bien_F_crop_1.jpg: 352x640 2 texts, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/025_rong-bien_F_crop_2.jpg: 416x640 2 texts, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/026_vinamilk-sua-dinh-duong-socola_F_crop_0.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/026_vinamilk-sua-dinh-duong-socola_F_crop_1.jpg: 352x640 3 texts, 9.3ms\n",
      "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/026_vinamilk-sua-dinh-duong-socola_F_crop_2.jpg: 352x640 2 texts, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/027_vinamilk-sua-dinh-duong-socola_B_crop_0.jpg: 640x224 2 texts, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/027_vinamilk-sua-dinh-duong-socola_B_crop_1.jpg: 128x640 4 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/028_dau-an-happi-koki_F_crop_0.jpg: 480x640 2 texts, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/028_dau-an-happi-koki_F_crop_1.jpg: 256x640 4 texts, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/028_dau-an-happi-koki_F_crop_2.jpg: 640x640 2 texts, 8.7ms\n",
      "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/029_dau-an-light_F_crop_0.jpg: 544x640 2 texts, 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/030_dau-an-light_B_crop_0.jpg: 160x640 4 texts, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/030_dau-an-light_B_crop_1.jpg: 544x640 2 texts, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/031_dau-an-cai-lan_F_crop_0.jpg: 288x640 2 texts, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/031_dau-an-cai-lan_F_crop_1.jpg: 160x640 5 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/032_dau-an-cai-lan_B_crop_0.jpg: 288x640 2 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/032_dau-an-cai-lan_B_crop_1.jpg: 544x640 2 texts, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/032_dau-an-cai-lan_B_crop_2.jpg: 96x640 7 texts, 9.6ms\n",
      "Speed: 0.5ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/033_dau-an-bep-hong_F_crop_0.jpg: 384x640 2 texts, 38.9ms\n",
      "Speed: 1.7ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/033_dau-an-bep-hong_F_crop_1.jpg: 640x640 5 texts, 8.6ms\n",
      "Speed: 2.3ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/033_dau-an-bep-hong_F_crop_2.jpg: 640x608 2 texts, 8.7ms\n",
      "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/034_dau-an-orchid_F_crop_0.jpg: 320x640 1 text, 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/034_dau-an-orchid_F_crop_1.jpg: 192x640 5 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/035_dau-an-orchid_B_crop_0.jpg: 96x640 7 texts, 10.0ms\n",
      "Speed: 0.5ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/035_dau-an-orchid_B_crop_1.jpg: 384x640 2 texts, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/036_dau-an-good-meall_F_crop_0.jpg: 480x640 2 texts, 9.1ms\n",
      "Speed: 1.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/036_dau-an-good-meall_F_crop_1.jpg: 320x640 5 texts, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/036_dau-an-good-meall_F_crop_2.jpg: 640x544 3 texts, 39.5ms\n",
      "Speed: 1.8ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/037_dau-dau-nanh-simply_F_crop_0.jpg: 256x640 2 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/037_dau-dau-nanh-simply_F_crop_1.jpg: 576x640 3 texts, 40.8ms\n",
      "Speed: 2.2ms preprocess, 40.8ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/038_dau-dau-nanh-simply_B_crop_0.jpg: 416x640 2 texts, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/038_dau-dau-nanh-simply_B_crop_1.jpg: 128x640 4 texts, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/039_dau-dau-nanh-truong-an_F_crop_0.jpg: 224x640 1 text, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/039_dau-dau-nanh-truong-an_F_crop_1.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/039_dau-dau-nanh-truong-an_F_crop_2.jpg: 224x640 2 texts, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/039_dau-dau-nanh-truong-an_F_crop_3.jpg: 576x640 3 texts, 8.5ms\n",
      "Speed: 2.2ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "Processed: 100/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/040_dau-dau-nanh-truong-an_B_crop_0.jpg: 224x640 2 texts, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/040_dau-dau-nanh-truong-an_B_crop_1.jpg: 576x640 3 texts, 8.3ms\n",
      "Speed: 1.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/040_dau-dau-nanh-truong-an_B_crop_2.jpg: 384x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/041_bo-dau-phong_F_crop_0.jpg: 192x640 2 texts, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/041_bo-dau-phong_F_crop_1.jpg: 224x640 3 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/041_bo-dau-phong_F_crop_2.jpg: 544x640 2 texts, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/042_bo-dau-phong_B_crop_0.jpg: 224x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/042_bo-dau-phong_B_crop_1.jpg: 224x640 1 text, 8.1ms\n",
      "Speed: 0.8ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/043_bo-thuc-vat_F_crop_0.jpg: 192x640 2 texts, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/043_bo-thuc-vat_F_crop_1.jpg: 192x640 3 texts, 8.3ms\n",
      "Speed: 0.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/044_bo-thuc-vat_B_crop_0.jpg: 384x640 2 texts, 9.2ms\n",
      "Speed: 1.3ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/045_nui-trung_F_crop_0.jpg: 128x640 4 texts, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/045_nui-trung_F_crop_1.jpg: 192x640 1 text, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/046_nui-trung_B_crop_0.jpg: 256x640 1 text, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/046_nui-trung_B_crop_1.jpg: 256x640 1 text, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/046_nui-trung_B_crop_2.jpg: 384x640 2 texts, 9.2ms\n",
      "Speed: 1.4ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/047_nui-bon-mua_F_crop_0.jpg: 192x640 3 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/047_nui-bon-mua_F_crop_1.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/050_nui-ong-dai_F_crop_0.jpg: 352x640 2 texts, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/050_nui-ong-dai_F_crop_1.jpg: 256x640 3 texts, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/050_nui-ong-dai_F_crop_2.jpg: 384x640 2 texts, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/051_mi-trung-cao-cap_F_crop_0.jpg: 160x640 4 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/051_mi-trung-cao-cap_F_crop_1.jpg: 160x640 1 text, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/051_nui-gao-lotus_F_crop_0.jpg: 448x640 2 texts, 8.5ms\n",
      "Speed: 2.1ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/051_nui-gao-lotus_F_crop_1.jpg: 608x640 4 texts, 9.2ms\n",
      "Speed: 2.2ms preprocess, 9.2ms inference, 3.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/052_mi-trung-cao-cap_L_crop_0.jpg: 256x640 1 text, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/052_nui-chu-c_F_crop_0.jpg: 320x640 2 texts, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/052_nui-chu-c_F_crop_1.jpg: 288x640 3 texts, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/052_nui-chu-c_F_crop_2.jpg: 384x640 2 texts, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/053_tuong-ot-knorr_F_crop_0.jpg: 352x640 1 text, 9.2ms\n",
      "Speed: 1.3ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/053_tuong-ot-knorr_F_crop_1.jpg: 288x640 3 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/053_tuong-ot-knorr_F_crop_2.jpg: 384x640 5 texts, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/054_tuong-ot-knorr_B_crop_0.jpg: 384x640 1 text, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/054_tuong-ot-knorr_B_crop_1.jpg: 192x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/054_tuong-ot-knorr_B_crop_2.jpg: 192x640 1 text, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/054_tuong-ot-knorr_B_crop_3.jpg: 352x640 5 texts, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/054_tuong-ot-knorr_B_crop_4.jpg: 480x640 2 texts, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/055_tuong-ca-nam-duong_F_crop_0.jpg: 640x192 2 texts, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/055_tuong-ca-nam-duong_F_crop_1.jpg: 288x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/055_tuong-ca-nam-duong_F_crop_2.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/055_tuong-ca-nam-duong_F_crop_3.jpg: 256x640 2 texts, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/056_tuong-ca-nam-duong_B_crop_0.jpg: 640x128 2 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/056_tuong-ca-nam-duong_B_crop_1.jpg: 448x640 2 texts, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/057_tuong-ot-xanh_F_crop_0.jpg: 576x640 3 texts, 8.4ms\n",
      "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/057_tuong-ot-xanh_F_crop_1.jpg: 416x640 3 texts, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/057_tuong-ot-xanh_F_crop_2.jpg: 640x480 2 texts, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/058_tuong-ot-xanh_B_crop_0.jpg: 640x640 5 texts, 9.3ms\n",
      "Speed: 2.2ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/058_tuong-ot-xanh_B_crop_1.jpg: 608x640 2 texts, 9.2ms\n",
      "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/058_tuong-ot-xanh_B_crop_2.jpg: 320x640 4 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/059_tuong-ot-ong-cha-va_F_crop_0.jpg: 416x640 3 texts, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Processed: 150/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/059_tuong-ot-ong-cha-va_F_crop_1.jpg: 640x576 2 texts, 40.6ms\n",
      "Speed: 2.4ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/060_tuong-ot-ong-cha-va_B_crop_0.jpg: 416x640 2 texts, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/060_tuong-ot-ong-cha-va_B_crop_1.jpg: 640x160 2 texts, 12.3ms\n",
      "Speed: 0.8ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/061_tuong-ot-sieu-cay_F_crop_0.jpg: 192x640 3 texts, 11.3ms\n",
      "Speed: 0.8ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/061_tuong-ot-sieu-cay_F_crop_1.jpg: 352x640 4 texts, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/061_tuong-ot-sieu-cay_F_crop_2.jpg: 480x640 2 texts, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/062_tuong-ot-sieu-cay_B_crop_0.jpg: 224x640 1 text, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/062_tuong-ot-sieu-cay_B_crop_1.jpg: 224x640 1 text, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/062_tuong-ot-sieu-cay_B_crop_2.jpg: 480x640 3 texts, 8.8ms\n",
      "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/063_tuong-ot-sieu-cay_F_crop_0.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/063_tuong-ot-sieu-cay_F_crop_1.jpg: 352x640 4 texts, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/063_tuong-ot-sieu-cay_F_crop_2.jpg: 608x640 2 texts, 8.7ms\n",
      "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/064_tuong-ot-dellycook_F_crop_0.jpg: 320x640 1 text, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/064_tuong-ot-dellycook_F_crop_1.jpg: 448x640 6 texts, 8.3ms\n",
      "Speed: 1.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/065_tuong-ot-dellycook_B_crop_0.jpg: 352x640 2 texts, 9.5ms\n",
      "Speed: 1.3ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/066_tuong-ot-dellycook_B_crop_0.jpg: 128x640 1 text, 8.9ms\n",
      "Speed: 0.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/066_tuong-ot-dellycook_B_crop_1.jpg: 128x640 1 text, 8.8ms\n",
      "Speed: 0.6ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/067_tuong-den-pho_F_crop_0.jpg: 224x640 2 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/067_tuong-den-pho_F_crop_1.jpg: 384x640 3 texts, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/067_tuong-den-pho_F_crop_2.jpg: 352x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/067_tuong-den-pho_F_crop_3.jpg: 224x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/068_tuong-den-pho_B_crop_0.jpg: 256x640 2 texts, 9.3ms\n",
      "Speed: 0.9ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/068_tuong-den-pho_B_crop_1.jpg: 384x640 3 texts, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/068_tuong-den-pho_B_crop_2.jpg: 192x640 2 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/068_tuong-den-pho_B_crop_3.jpg: 192x640 3 texts, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/068_tuong-den-pho_B_crop_4.jpg: 320x640 2 texts, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/068_tuong-den-pho_B_crop_5.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/069_tuong-ot-chua-ngot_F_crop_0.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/069_tuong-ot-chua-ngot_F_crop_1.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.6ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/069_tuong-ot-chua-ngot_F_crop_2.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/069_tuong-ot-chua-ngot_F_crop_3.jpg: 352x640 5 texts, 8.8ms\n",
      "Speed: 1.5ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/070_tuong-ot-chua-ngot_F_crop_0.jpg: 352x640 2 texts, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/071_tuong-ot-chin-su_F_crop_0.jpg: 224x640 2 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/071_tuong-ot-chin-su_F_crop_1.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/071_tuong-ot-chin-su_F_crop_2.jpg: 320x640 2 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/072_tuong-ot-chin-su_B_crop_0.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/072_tuong-ot-chin-su_B_crop_1.jpg: 224x640 1 text, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/072_tuong-ot-chin-su_B_crop_2.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/073_xot-uop-thit-nuong_F_crop_0.jpg: 288x640 2 texts, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/073_xot-uop-thit-nuong_F_crop_1.jpg: 288x640 5 texts, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/073_xot-uop-thit-nuong_F_crop_2.jpg: 288x640 2 texts, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/074_xot-uop-thit-nuong_B_crop_0.jpg: 96x640 4 texts, 10.1ms\n",
      "Speed: 0.6ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/074_xot-uop-thit-nuong_B_crop_1.jpg: 416x640 2 texts, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/074_xot-uop-thit-nuong_B_crop_2.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/074_xot-uop-thit-nuong_B_crop_3.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/075_xot-ga-chien-nuoc-mam_F_crop_0.jpg: 224x640 1 text, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/075_xot-ga-chien-nuoc-mam_F_crop_1.jpg: 384x640 3 texts, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/075_xot-ga-chien-nuoc-mam_F_crop_2.jpg: 128x640 4 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/076_xot-ga-chien-nuoc-mam_B_crop_0.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/076_xot-ga-chien-nuoc-mam_B_crop_1.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "Processed: 200/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/076_xot-ga-chien-nuoc-mam_B_crop_2.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/076_xot-ga-chien-nuoc-mam_B_crop_3.jpg: 128x640 7 texts, 9.3ms\n",
      "Speed: 0.6ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/077_xot-ga-chien-nuoc-mam_F_crop_0.jpg: 320x640 1 text, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/077_xot-ga-chien-nuoc-mam_F_crop_1.jpg: 160x640 11 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/078_xot-ga-chien-nuoc-mam_B_crop_0.jpg: 160x640 9 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/078_xot-ga-chien-nuoc-mam_B_crop_1.jpg: 256x640 1 text, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/078_xot-ga-chien-nuoc-mam_B_crop_2.jpg: 192x640 1 text, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/078_xot-ga-chien-nuoc-mam_B_crop_3.jpg: 160x640 1 text, 9.5ms\n",
      "Speed: 0.7ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/078_xot-ga-chien-nuoc-mam_B_crop_4.jpg: 320x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/079_duong-kinh-trang_F_crop_0.jpg: 256x640 6 texts, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/079_duong-kinh-trang_F_crop_1.jpg: 352x640 2 texts, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/080_duong-kinh-trang_B_crop_0.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/080_duong-kinh-trang_B_crop_1.jpg: 192x640 1 text, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/080_duong-kinh-trang_B_crop_2.jpg: 640x128 3 texts, 9.5ms\n",
      "Speed: 0.7ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/081_sot-spaghetti_F_crop_0.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/081_sot-spaghetti_F_crop_1.jpg: 224x640 6 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/081_sot-spaghetti_F_crop_2.jpg: 320x640 1 text, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/081_sot-spaghetti_F_crop_3.jpg: 352x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/082_hu-tieu-bo-kho_F_crop_0.jpg: 224x640 2 texts, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/082_hu-tieu-bo-kho_F_crop_1.jpg: 256x640 4 texts, 9.5ms\n",
      "Speed: 1.3ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/083_hu-tieu-bo-kho_B_crop_0.jpg: 160x640 3 texts, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/083_hu-tieu-bo-kho_B_crop_1.jpg: 160x640 3 texts, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/084_chao-thit-bam_F_crop_0.jpg: 256x640 1 text, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/084_chao-thit-bam_F_crop_1.jpg: 160x640 3 texts, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/084_chao-thit-bam_F_crop_2.jpg: 512x640 1 text, 8.4ms\n",
      "Speed: 1.7ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/085_bot-suong-sao-den_F_crop_0.jpg: 96x640 4 texts, 10.1ms\n",
      "Speed: 0.6ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/085_bot-suong-sao-den_F_crop_1.jpg: 288x640 1 text, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/085_bot-suong-sao-den_F_crop_2.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/085_bot-suong-sao-den_F_crop_3.jpg: 160x640 1 text, 8.3ms\n",
      "Speed: 0.7ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/085_bot-suong-sao-den_F_crop_4.jpg: 192x640 2 texts, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/086_snack-tom-vi-muoi-ot-xanh_F_crop_0.jpg: 288x640 1 text, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/086_snack-tom-vi-muoi-ot-xanh_F_crop_1.jpg: 352x640 6 texts, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/087_tao-ninh-thuan_F_crop_0.jpg: 160x640 3 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/087_tao-ninh-thuan_F_crop_1.jpg: 320x640 2 texts, 9.2ms\n",
      "Speed: 1.3ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/087_tao-ninh-thuan_F_crop_2.jpg: 288x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/088_tao-gala-mini-phap_F_crop_0.jpg: 128x640 4 texts, 8.9ms\n",
      "Speed: 0.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/088_tao-gala-mini-phap_F_crop_1.jpg: 288x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/088_tao-gala-mini-phap_F_crop_2.jpg: 320x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/089_sapoche_F_crop_0.jpg: 160x640 1 text, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/089_sapoche_F_crop_1.jpg: 192x640 1 text, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/089_sapoche_F_crop_2.jpg: 128x640 7 texts, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/089_sapoche_F_crop_3.jpg: 320x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/090_man-an-phuoc_F_crop_0.jpg: 192x640 3 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/090_man-an-phuoc_F_crop_1.jpg: 288x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/090_man-an-phuoc_F_crop_2.jpg: 352x640 1 text, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/091_oi-nu-hoang_F_crop_0.jpg: 192x640 3 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/091_oi-nu-hoang_F_crop_1.jpg: 288x640 2 texts, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/091_oi-nu-hoang_F_crop_2.jpg: 288x640 1 text, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/092_trung-ga-tuoi_F_crop_0.jpg: 352x640 2 texts, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/092_trung-ga-tuoi_F_crop_1.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "Processed: 250/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/092_trung-ga-tuoi_F_crop_2.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/092_trung-ga-tuoi_F_crop_3.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/093_trung-ga-tuoi_F_crop_0.jpg: 160x640 2 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/093_trung-ga-tuoi_F_crop_1.jpg: 160x640 3 texts, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/093_trung-ga-tuoi_F_crop_2.jpg: 128x640 3 texts, 9.2ms\n",
      "Speed: 0.6ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/093_trung-ga-tuoi_F_crop_3.jpg: 384x640 2 texts, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/094_trung-ga-tuoi_B_crop_0.jpg: 96x640 2 texts, 10.2ms\n",
      "Speed: 0.6ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/094_trung-ga-tuoi_B_crop_1.jpg: 160x640 3 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/094_trung-ga-tuoi_B_crop_2.jpg: 256x640 2 texts, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/094_trung-ga-tuoi_B_crop_3.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/095_trung-vit-muoi_F_crop_0.jpg: 128x640 3 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/095_trung-vit-muoi_F_crop_1.jpg: 320x640 3 texts, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/095_trung-vit-muoi_F_crop_2.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/095_trung-vit-muoi_F_crop_3.jpg: 288x640 2 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/095_trung-vit-muoi_F_crop_4.jpg: 96x640 7 texts, 10.5ms\n",
      "Speed: 0.6ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/096_trung-vit-bac-thao_F_crop_0.jpg: 320x640 3 texts, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/096_trung-vit-bac-thao_F_crop_1.jpg: 192x640 4 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/096_trung-vit-bac-thao_F_crop_2.jpg: 96x640 7 texts, 10.7ms\n",
      "Speed: 0.6ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/096_trung-vit-bac-thao_F_crop_3.jpg: 352x640 2 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/096_trung-vit-bac-thao_F_crop_4.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/097_trung-cut_F_crop_0.jpg: 96x640 4 texts, 10.4ms\n",
      "Speed: 0.6ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/097_trung-cut_F_crop_1.jpg: 352x640 3 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/097_trung-cut_F_crop_2.jpg: 192x640 1 text, 17.2ms\n",
      "Speed: 1.2ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/097_trung-cut_F_crop_3.jpg: 352x640 2 texts, 15.5ms\n",
      "Speed: 1.6ms preprocess, 15.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/097_trung-cut_F_crop_4.jpg: 256x640 2 texts, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/098_trung-vit-tuoi_F_crop_0.jpg: 320x640 3 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/098_trung-vit-tuoi_F_crop_1.jpg: 128x640 3 texts, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/098_trung-vit-tuoi_F_crop_2.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/099_trung-vit-tuoi_B_crop_0.jpg: 96x640 3 texts, 10.2ms\n",
      "Speed: 0.6ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/099_trung-vit-tuoi_B_crop_1.jpg: 384x640 3 texts, 10.1ms\n",
      "Speed: 1.4ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/099_trung-vit-tuoi_B_crop_2.jpg: 96x640 7 texts, 10.7ms\n",
      "Speed: 0.6ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/099_trung-vit-tuoi_B_crop_3.jpg: 192x640 1 text, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/100_tao-do-khong-hat_F_crop_0.jpg: 128x640 4 texts, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/100_tao-do-khong-hat_F_crop_1.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/100_tao-do-khong-hat_F_crop_2.jpg: 288x640 2 texts, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/101_tao-do-khong-hat_T_crop_0.jpg: 224x640 3 texts, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/101_tao-do-khong-hat_T_crop_1.jpg: 224x640 3 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/102_dau-phong_F_crop_0.jpg: 192x640 2 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/102_dau-phong_F_crop_1.jpg: 160x640 2 texts, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/102_dau-phong_F_crop_2.jpg: 224x640 2 texts, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/102_dau-phong_F_crop_3.jpg: 224x640 3 texts, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/102_dau-phong_F_crop_4.jpg: 256x640 3 texts, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/103_pho-tai_F_crop_0.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/103_pho-tai_F_crop_1.jpg: 224x640 1 text, 9.7ms\n",
      "Speed: 0.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/103_pho-tai_F_crop_2.jpg: 192x640 5 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/103_pho-tai_F_crop_3.jpg: 416x640 2 texts, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/104_hanh-phi_F_crop_0.jpg: 192x640 2 texts, 9.8ms\n",
      "Speed: 0.9ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/104_hanh-phi_F_crop_1.jpg: 352x640 2 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/105_hanh-phi_T_crop_0.jpg: 128x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/105_hanh-phi_T_crop_1.jpg: 128x640 1 text, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "Processed: 300/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/106_dau-xanh-hat_F_crop_0.jpg: 160x640 2 texts, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/106_dau-xanh-hat_F_crop_1.jpg: 128x640 3 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/106_dau-xanh-hat_F_crop_2.jpg: 192x640 2 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/107_nam-dong-co_F_crop_0.jpg: 128x640 3 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/107_nam-dong-co_F_crop_1.jpg: 192x640 1 text, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/107_nam-dong-co_F_crop_2.jpg: 384x640 2 texts, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/108_hat-sen_F_crop_0.jpg: 224x640 2 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/108_hat-sen_F_crop_1.jpg: 224x640 2 texts, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/108_hat-sen_F_crop_2.jpg: 384x640 2 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/109_hat-sen_T_crop_0.jpg: 224x640 1 text, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/109_hat-sen_T_crop_1.jpg: 224x640 1 text, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/110_me-trang_F_crop_0.jpg: 224x640 2 texts, 8.2ms\n",
      "Speed: 0.8ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/110_me-trang_F_crop_1.jpg: 192x640 2 texts, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/110_me-trang_F_crop_2.jpg: 224x640 3 texts, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/110_me-trang_F_crop_3.jpg: 224x640 3 texts, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/111_dau-xanh-khong-vo_F_crop_0.jpg: 128x640 4 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/111_dau-xanh-khong-vo_F_crop_1.jpg: 192x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/111_dau-xanh-khong-vo_F_crop_2.jpg: 192x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/111_dau-xanh-khong-vo_F_crop_3.jpg: 192x640 1 text, 8.3ms\n",
      "Speed: 0.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/111_dau-xanh-khong-vo_F_crop_4.jpg: 320x640 2 texts, 9.6ms\n",
      "Speed: 1.1ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/112_dau-den_F_crop_0.jpg: 256x640 1 text, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/112_dau-den_F_crop_1.jpg: 192x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/112_dau-den_F_crop_2.jpg: 352x640 2 texts, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/113_dau-do_F_crop_0.jpg: 256x640 2 texts, 16.2ms\n",
      "Speed: 1.1ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/113_dau-do_F_crop_1.jpg: 256x640 2 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/113_dau-do_F_crop_2.jpg: 416x640 2 texts, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/114_toi-phi_F_crop_0.jpg: 256x640 3 texts, 13.3ms\n",
      "Speed: 1.1ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/114_toi-phi_F_crop_1.jpg: 224x640 2 texts, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/114_toi-phi_F_crop_2.jpg: 256x640 2 texts, 12.4ms\n",
      "Speed: 1.6ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/114_toi-phi_F_crop_3.jpg: 384x640 2 texts, 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/115_kho-heo-say-toi_F_crop_0.jpg: 512x640 4 texts, 9.0ms\n",
      "Speed: 2.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/115_kho-heo-say-toi_F_crop_1.jpg: 544x640 2 texts, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/115_kho-heo-say-toi_F_crop_2.jpg: 352x640 1 text, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/116_kho-heo-say-toi_B_crop_0.jpg: 160x640 4 texts, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/116_kho-heo-say-toi_B_crop_1.jpg: 160x640 3 texts, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/116_kho-heo-say-toi_B_crop_2.jpg: 160x640 3 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/116_kho-heo-say-toi_B_crop_3.jpg: 160x640 3 texts, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/117_dau-nanh-say-gion_F_crop_0.jpg: 320x640 4 texts, 9.2ms\n",
      "Speed: 1.4ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/117_dau-nanh-say-gion_F_crop_1.jpg: 288x640 2 texts, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/117_dau-nanh-say-gion_F_crop_2.jpg: 608x640 1 text, 8.9ms\n",
      "Speed: 2.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/118_dau-nanh-say-gion_B_crop_0.jpg: 128x640 4 texts, 9.3ms\n",
      "Speed: 0.6ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/118_dau-nanh-say-gion_B_crop_1.jpg: 192x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/118_dau-nanh-say-gion_B_crop_2.jpg: 192x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/118_dau-nanh-say-gion_B_crop_3.jpg: 128x640 5 texts, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/118_dau-nanh-say-gion_B_crop_4.jpg: 576x640 1 text, 8.7ms\n",
      "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/119_xoai-say-deo_F_crop_0.jpg: 160x640 3 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/119_xoai-say-deo_F_crop_1.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/119_xoai-say-deo_F_crop_2.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.6ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/119_xoai-say-deo_F_crop_3.jpg: 288x640 2 texts, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/119_xoai-say-deo_F_crop_4.jpg: 608x640 1 text, 8.6ms\n",
      "Speed: 1.9ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n",
      "Processed: 350/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/120_cha-bong-ga_F_crop_0.jpg: 512x640 3 texts, 8.3ms\n",
      "Speed: 2.1ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/120_cha-bong-ga_F_crop_1.jpg: 512x640 2 texts, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/120_cha-bong-ga_F_crop_2.jpg: 352x640 1 text, 9.3ms\n",
      "Speed: 1.3ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/121_cha-bong-ga_B_crop_0.jpg: 128x640 3 texts, 9.5ms\n",
      "Speed: 0.7ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/121_cha-bong-ga_B_crop_1.jpg: 192x640 3 texts, 9.5ms\n",
      "Speed: 0.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/121_cha-bong-ga_B_crop_2.jpg: 192x640 3 texts, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/121_cha-bong-ga_B_crop_3.jpg: 192x640 3 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/122_nescafe-ca-phe-den-da_F_crop_0.jpg: 224x640 1 text, 9.5ms\n",
      "Speed: 1.2ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/122_nescafe-ca-phe-den-da_F_crop_1.jpg: 192x640 4 texts, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/123_nescafe-ca-phe-den-da_B_crop_0.jpg: 320x640 2 texts, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/123_nescafe-ca-phe-den-da_B_crop_1.jpg: 96x640 2 texts, 10.0ms\n",
      "Speed: 0.5ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/123_nescafe-ca-phe-den-da_B_crop_2.jpg: 96x640 6 texts, 9.5ms\n",
      "Speed: 0.6ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/124_hat-nem-aji-ngon_F_crop_0.jpg: 224x640 1 text, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/124_hat-nem-aji-ngon_F_crop_1.jpg: 192x640 2 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/124_hat-nem-aji-ngon_F_crop_2.jpg: 320x640 2 texts, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/125_hat-nem-aji-ngon_F_crop_0.jpg: 160x640 2 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/125_hat-nem-aji-ngon_F_crop_1.jpg: 352x640 2 texts, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/126_hat-nem-aji-ngon_F_crop_0.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/126_hat-nem-aji-ngon_F_crop_1.jpg: 160x640 2 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/126_hat-nem-aji-ngon_F_crop_2.jpg: 256x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/127_xot-gia-vi-thit-nuong-ngu-vi_F_crop_0.jpg: 320x640 1 text, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/127_xot-gia-vi-thit-nuong-ngu-vi_F_crop_1.jpg: 192x640 10 texts, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/128_xot-gia-vi-thit-nuong-ngu-vi_B_crop_0.jpg: 352x640 1 text, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/128_xot-gia-vi-thit-nuong-ngu-vi_B_crop_1.jpg: 192x640 9 texts, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/128_xot-gia-vi-thit-nuong-ngu-vi_B_crop_2.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/128_xot-gia-vi-thit-nuong-ngu-vi_B_crop_3.jpg: 160x640 1 text, 8.3ms\n",
      "Speed: 0.7ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/128_xot-gia-vi-thit-nuong-ngu-vi_B_crop_4.jpg: 224x640 2 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/129_xot-gia-vi-nuong-bbq_F_crop_0.jpg: 288x640 1 text, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/129_xot-gia-vi-nuong-bbq_F_crop_1.jpg: 192x640 9 texts, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/130_xot-gia-vi-nuong-bbq_B_crop_0.jpg: 256x640 1 text, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/130_xot-gia-vi-nuong-bbq_B_crop_1.jpg: 224x640 7 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/130_xot-gia-vi-nuong-bbq_B_crop_2.jpg: 160x640 2 texts, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/130_xot-gia-vi-nuong-bbq_B_crop_3.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/130_xot-gia-vi-nuong-bbq_B_crop_4.jpg: 320x640 2 texts, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/131_xot-gia-vi-canh-chua_F_crop_0.jpg: 352x640 1 text, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/131_xot-gia-vi-canh-chua_F_crop_1.jpg: 192x640 9 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/131_xot-gia-vi-canh-chua_F_crop_2.jpg: 352x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/132_xot-gia-vi-canh-chua_B_crop_0.jpg: 256x640 1 text, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/132_xot-gia-vi-canh-chua_B_crop_1.jpg: 192x640 7 texts, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/132_xot-gia-vi-canh-chua_B_crop_2.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/132_xot-gia-vi-canh-chua_B_crop_3.jpg: 160x640 1 text, 12.1ms\n",
      "Speed: 0.8ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/133_gia-vi-ca-kho_F_crop_0.jpg: 160x640 1 text, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/133_gia-vi-ca-kho_F_crop_1.jpg: 160x640 4 texts, 8.3ms\n",
      "Speed: 0.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/133_gia-vi-ca-kho_F_crop_2.jpg: 224x640 1 text, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/133_gia-vi-ca-kho_F_crop_3.jpg: 256x640 2 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/134_gia-vi-canh-chua_F_crop_0.jpg: 256x640 3 texts, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/134_gia-vi-canh-chua_F_crop_1.jpg: 384x640 6 texts, 9.1ms\n",
      "Speed: 1.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/135_gia-vi-canh-chua_B_crop_0.jpg: 192x640 1 text, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/135_gia-vi-canh-chua_B_crop_1.jpg: 192x640 1 text, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/135_gia-vi-canh-chua_B_crop_2.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Processed: 400/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/136_gia-vi-ca-kho_F_crop_0.jpg: 224x640 3 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/136_gia-vi-ca-kho_F_crop_1.jpg: 384x640 6 texts, 9.0ms\n",
      "Speed: 1.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/137_gia-vi-ca-kho_B_crop_0.jpg: 128x640 1 text, 8.7ms\n",
      "Speed: 0.6ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/137_gia-vi-ca-kho_B_crop_1.jpg: 128x640 1 text, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/137_gia-vi-ca-kho_B_crop_2.jpg: 320x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/138_gia-vi-thit-kho_F_crop_0.jpg: 256x640 3 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/138_gia-vi-thit-kho_F_crop_1.jpg: 384x640 6 texts, 9.1ms\n",
      "Speed: 1.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/139_gia-vi-thit-kho_B_crop_0.jpg: 128x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/139_gia-vi-thit-kho_B_crop_1.jpg: 128x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/139_gia-vi-thit-kho_B_crop_2.jpg: 352x640 2 texts, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/140_cot-pho-bo_F_crop_0.jpg: 352x640 3 texts, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/140_cot-pho-bo_F_crop_1.jpg: 352x640 3 texts, 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/140_cot-pho-bo_F_crop_2.jpg: 448x640 2 texts, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/141_cot-pho-bo_B_crop_0.jpg: 288x640 5 texts, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/141_cot-pho-bo_B_crop_1.jpg: 384x640 3 texts, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/141_cot-pho-bo_B_crop_2.jpg: 640x128 3 texts, 9.1ms\n",
      "Speed: 0.6ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/141_cot-pho-bo_B_crop_3.jpg: 640x160 4 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/142_gia-vi-nem-lau-thai_F_crop_0.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/142_gia-vi-nem-lau-thai_F_crop_1.jpg: 160x640 4 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/142_gia-vi-nem-lau-thai_F_crop_2.jpg: 192x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/143_gia-vi-bo-kho_F_crop_0.jpg: 416x640 5 texts, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/143_gia-vi-bo-kho_F_crop_1.jpg: 576x640 2 texts, 8.8ms\n",
      "Speed: 1.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/144_gia-vi-bo-kho_B_crop_0.jpg: 192x640 5 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/144_gia-vi-bo-kho_B_crop_1.jpg: 640x96 (no detections), 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 96)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/144_gia-vi-bo-kho_B_crop_2.jpg: 640x128 (no detections), 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/145_xot-uop-thit-nuong_F_crop_0.jpg: 352x640 6 texts, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/145_xot-uop-thit-nuong_F_crop_1.jpg: 608x640 2 texts, 8.8ms\n",
      "Speed: 1.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/145_xot-uop-thit-nuong_F_crop_2.jpg: 352x640 1 text, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/146_xot-uop-thit-nuong_B_crop_0.jpg: 160x640 1 text, 10.0ms\n",
      "Speed: 0.6ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/146_xot-uop-thit-nuong_B_crop_1.jpg: 96x640 7 texts, 10.2ms\n",
      "Speed: 0.5ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/147_bot-ngu-vi-huong_F_crop_0.jpg: 224x640 7 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/147_bot-ngu-vi-huong_F_crop_1.jpg: 640x128 (no detections), 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/147_bot-ngu-vi-huong_F_crop_2.jpg: 640x128 (no detections), 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/147_bot-ngu-vi-huong_F_crop_3.jpg: 384x640 2 texts, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/148_bot-ngu-vi-huong_F_crop_0.jpg: 640x576 13 texts, 8.5ms\n",
      "Speed: 2.6ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/148_bot-ngu-vi-huong_F_crop_1.jpg: 352x640 2 texts, 9.5ms\n",
      "Speed: 1.3ms preprocess, 9.5ms inference, 2.9ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/149_bot-ngu-vi-huong_F_crop_0.jpg: 448x640 3 texts, 8.8ms\n",
      "Speed: 2.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/149_bot-ngu-vi-huong_F_crop_1.jpg: 352x640 3 texts, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/150_bot-ngu-vi-huong_B_crop_0.jpg: 288x640 1 text, 10.0ms\n",
      "Speed: 1.2ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/150_bot-ngu-vi-huong_B_crop_1.jpg: 384x640 2 texts, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/150_bot-ngu-vi-huong_B_crop_2.jpg: 416x640 2 texts, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/151_bot-cary_F_crop_0.jpg: 320x640 1 text, 9.5ms\n",
      "Speed: 1.3ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/151_bot-cary_F_crop_1.jpg: 160x640 2 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/151_bot-cary_F_crop_2.jpg: 192x640 3 texts, 9.3ms\n",
      "Speed: 0.9ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/152_bot-cary_B_crop_0.jpg: 160x640 2 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/152_bot-cary_B_crop_1.jpg: 640x128 3 texts, 8.9ms\n",
      "Speed: 0.6ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/152_bot-cary_B_crop_2.jpg: 640x96 2 texts, 9.7ms\n",
      "Speed: 0.6ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 96)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/152_bot-cary_B_crop_3.jpg: 512x640 2 texts, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/153_bot-cary_F_crop_0.jpg: 320x640 4 texts, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/153_bot-cary_F_crop_1.jpg: 448x640 2 texts, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed: 450/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/154_bot-cary_B_crop_0.jpg: 352x640 4 texts, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/154_bot-cary_B_crop_1.jpg: 96x640 7 texts, 9.8ms\n",
      "Speed: 0.5ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/154_bot-cary_B_crop_2.jpg: 640x128 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/154_bot-cary_B_crop_3.jpg: 640x160 2 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/155_bot-cary_F_crop_0.jpg: 416x640 2 texts, 9.0ms\n",
      "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/155_bot-cary_F_crop_1.jpg: 480x640 2 texts, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/156_tieu-den-xay_F_crop_0.jpg: 576x640 2 texts, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/156_tieu-den-xay_F_crop_1.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/157_tieu-den-xay_B_crop_0.jpg: 576x640 2 texts, 9.1ms\n",
      "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/158_tieu-den-xay_T_crop_0.jpg: 224x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/158_tieu-den-xay_T_crop_1.jpg: 224x640 1 text, 8.3ms\n",
      "Speed: 0.9ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/159_ot-bot_F_crop_0.jpg: 544x640 2 texts, 8.8ms\n",
      "Speed: 2.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/159_ot-bot_F_crop_1.jpg: 320x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/160_ot-bot_T_crop_0.jpg: 224x640 1 text, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/160_ot-bot_T_crop_1.jpg: 256x640 1 text, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/161_tieu-den-xay_F_crop_0.jpg: 480x640 1 text, 8.4ms\n",
      "Speed: 1.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/161_tieu-den-xay_F_crop_1.jpg: 160x640 3 texts, 9.6ms\n",
      "Speed: 0.9ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/161_tieu-den-xay_F_crop_2.jpg: 384x640 2 texts, 9.4ms\n",
      "Speed: 1.3ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/162_tieu-den-xay_B_crop_0.jpg: 128x640 1 text, 9.3ms\n",
      "Speed: 0.6ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/162_tieu-den-xay_B_crop_1.jpg: 96x640 1 text, 10.0ms\n",
      "Speed: 0.6ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/163_ca-chua-co-dac_F_crop_0.jpg: 544x640 4 texts, 8.2ms\n",
      "Speed: 2.3ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/163_ca-chua-co-dac_F_crop_1.jpg: 512x640 3 texts, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/163_ca-chua-co-dac_F_crop_2.jpg: 512x640 2 texts, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/164_ca-chua-codac_D_crop_0.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/164_ca-chua-codac_D_crop_1.jpg: 160x640 1 text, 8.2ms\n",
      "Speed: 0.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/165_nuoc-cot-dua-tuoi_F_crop_0.jpg: 224x640 3 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/165_nuoc-cot-dua-tuoi_F_crop_1.jpg: 256x640 4 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/165_nuoc-cot-dua-tuoi_F_crop_2.jpg: 352x640 2 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/166_nuoc-cot-dua-tuoi_D_crop_0.jpg: 288x640 1 text, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/166_nuoc-cot-dua-tuoi_D_crop_1.jpg: 256x640 1 text, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/167_muoi-tom_F_crop_0.jpg: 256x640 2 texts, 9.7ms\n",
      "Speed: 1.1ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/167_muoi-tom_F_crop_1.jpg: 544x640 2 texts, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/168_muoi-tom_T_crop_0.jpg: 224x640 1 text, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/168_muoi-tom_T_crop_1.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/169_muoi-tom_F_crop_0.jpg: 96x640 4 texts, 9.9ms\n",
      "Speed: 0.6ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/169_muoi-tom_F_crop_1.jpg: 192x640 4 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/169_muoi-tom_F_crop_2.jpg: 384x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/170_muoi-cham-hao-hao_F_crop_0.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/170_muoi-cham-hao-hao_F_crop_1.jpg: 480x640 4 texts, 8.3ms\n",
      "Speed: 2.0ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/170_muoi-cham-hao-hao_F_crop_2.jpg: 448x640 2 texts, 8.8ms\n",
      "Speed: 1.5ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/171_muoi-chamhao-hao_D_crop_0.jpg: 320x640 1 text, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/171_muoi-chamhao-hao_D_crop_1.jpg: 288x640 1 text, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/172_xot-salad-me-rang_F_crop_0.jpg: 160x640 2 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/172_xot-salad-me-rang_F_crop_1.jpg: 160x640 4 texts, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/172_xot-salad-me-rang_F_crop_2.jpg: 256x640 2 texts, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/173_xot-salad-me-rang_B_crop_0.jpg: 256x640 1 text, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/173_xot-salad-me-rang_B_crop_1.jpg: 256x640 1 text, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/173_xot-salad-me-rang_B_crop_2.jpg: 160x640 2 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/174_xot-salad-me-rang_F_crop_0.jpg: 192x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/174_xot-salad-me-rang_F_crop_1.jpg: 256x640 5 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Processed: 500/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/175_xot-salad-me-rang_B_crop_0.jpg: 224x640 2 texts, 9.9ms\n",
      "Speed: 1.0ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/175_xot-salad-me-rang_B_crop_1.jpg: 224x640 1 text, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/175_xot-salad-me-rang_B_crop_2.jpg: 224x640 1 text, 10.1ms\n",
      "Speed: 1.2ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/176_nuoc-cham-me-rang_F_crop_0.jpg: 256x640 1 text, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/176_nuoc-cham-me-rang_F_crop_1.jpg: 352x640 4 texts, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/177_nuoc-cham-me-rang_B_crop_0.jpg: 288x640 2 texts, 9.1ms\n",
      "Speed: 1.3ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/178_nuoc-cham-me-rang_B_crop_0.jpg: 352x640 1 text, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/178_nuoc-cham-me-rang_B_crop_1.jpg: 320x640 1 text, 9.2ms\n",
      "Speed: 1.3ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/179_sot-cham-thit-nuong_F_crop_0.jpg: 352x640 1 text, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/179_sot-cham-thit-nuong_F_crop_1.jpg: 416x640 6 texts, 8.3ms\n",
      "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/179_sot-cham-thit-nuong_F_crop_2.jpg: 256x640 2 texts, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/180_sot-cham-thit-nuong_B_crop_0.jpg: 352x640 1 text, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/180_sot-cham-thit-nuong_B_crop_1.jpg: 192x640 5 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/180_sot-cham-thit-nuong_B_crop_2.jpg: 256x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/181_muc-kho-xe-soi-vi-bo_F_crop_0.jpg: 224x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/181_muc-kho-xe-soi-vi-bo_F_crop_1.jpg: 640x640 6 texts, 8.8ms\n",
      "Speed: 2.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/181_muc-kho-xe-soi-vi-bo_F_crop_2.jpg: 576x640 2 texts, 8.8ms\n",
      "Speed: 2.0ms preprocess, 8.8ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/182_muc-kho-xe-soi-vi-bo_B_crop_0.jpg: 288x640 2 texts, 8.5ms\n",
      "Speed: 1.3ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/182_muc-kho-xe-soi-vi-bo_B_crop_1.jpg: 224x640 1 text, 9.3ms\n",
      "Speed: 0.9ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/182_muc-kho-xe-soi-vi-bo_B_crop_2.jpg: 192x640 1 text, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/182_muc-kho-xe-soi-vi-bo_B_crop_3.jpg: 320x640 7 texts, 8.8ms\n",
      "Speed: 1.5ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/183_kho-bo_F_crop_0.jpg: 192x640 2 texts, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/183_kho-bo_F_crop_1.jpg: 224x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/184_kho-bo_B_crop_0.jpg: 192x640 2 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/184_kho-bo_B_crop_1.jpg: 352x640 1 text, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/184_kho-bo_B_crop_2.jpg: 288x640 2 texts, 9.5ms\n",
      "Speed: 1.1ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/185_muc-rim-me_F_crop_0.jpg: 128x640 1 text, 9.4ms\n",
      "Speed: 0.7ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/185_muc-rim-me_F_crop_1.jpg: 448x640 3 texts, 9.1ms\n",
      "Speed: 1.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/185_muc-rim-me_F_crop_2.jpg: 512x640 2 texts, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/186_muc-rim-me_B_crop_0.jpg: 160x640 1 text, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/186_muc-rim-me_B_crop_1.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/186_muc-rim-me_B_crop_2.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/187_ca-du-chay-toi_F_crop_0.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/187_ca-du-chay-toi_F_crop_1.jpg: 480x640 4 texts, 8.4ms\n",
      "Speed: 2.2ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/187_ca-du-chay-toi_F_crop_2.jpg: 576x640 2 texts, 8.7ms\n",
      "Speed: 1.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/188_tep-say-gion_F_crop_0.jpg: 128x640 1 text, 8.6ms\n",
      "Speed: 0.6ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/188_tep-say-gion_F_crop_1.jpg: 320x640 3 texts, 9.2ms\n",
      "Speed: 1.4ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/188_tep-say-gion_F_crop_2.jpg: 576x640 2 texts, 9.0ms\n",
      "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/189_tep-say-gion_B_crop_0.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/189_tep-say-gion_B_crop_1.jpg: 192x640 1 text, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/189_tep-say-gion_B_crop_2.jpg: 128x640 3 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/190_khoai-mon-say_F_crop_0.jpg: 224x640 1 text, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/190_khoai-mon-say_F_crop_1.jpg: 160x640 3 texts, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/190_khoai-mon-say_F_crop_2.jpg: 640x128 4 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/190_khoai-mon-say_F_crop_3.jpg: 640x128 3 texts, 8.2ms\n",
      "Speed: 0.6ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/191_khoai-mon-say_F_crop_0.jpg: 128x640 3 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/191_khoai-mon-say_F_crop_1.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/191_khoai-mon-say_F_crop_2.jpg: 640x224 1 text, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/191_khoai-mon-say_F_crop_3.jpg: 640x192 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/191_khoai-mon-say_F_crop_4.jpg: 320x640 2 texts, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Processed: 550/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/192_khoai-lang-say_F_crop_0.jpg: 128x640 1 text, 8.7ms\n",
      "Speed: 0.6ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/192_khoai-lang-say_F_crop_1.jpg: 352x640 4 texts, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/192_khoai-lang-say_F_crop_2.jpg: 640x224 3 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/192_khoai-lang-say_F_crop_3.jpg: 640x256 2 texts, 45.9ms\n",
      "Speed: 1.0ms preprocess, 45.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/192_khoai-lang-say_F_crop_4.jpg: 288x640 2 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/193_khoai-lang-say_F_crop_0.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/193_khoai-lang-say_F_crop_1.jpg: 384x640 4 texts, 9.1ms\n",
      "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/193_khoai-lang-say_F_crop_2.jpg: 640x160 6 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/193_khoai-lang-say_F_crop_3.jpg: 640x128 2 texts, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/193_khoai-lang-say_F_crop_4.jpg: 288x640 2 texts, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/194_chuoi-say_F_crop_0.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/194_chuoi-say_F_crop_1.jpg: 160x640 3 texts, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/194_chuoi-say_F_crop_2.jpg: 640x160 3 texts, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/194_chuoi-say_F_crop_3.jpg: 640x192 2 texts, 9.7ms\n",
      "Speed: 0.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 192)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/194_chuoi-say_F_crop_4.jpg: 320x640 2 texts, 9.6ms\n",
      "Speed: 1.1ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/195_socola-sua-cadbury-dairy-milk_F_crop_0.jpg: 96x640 5 texts, 14.3ms\n",
      "Speed: 0.8ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/195_socola-sua-cadbury-dairy-milk_F_crop_1.jpg: 512x640 2 texts, 9.9ms\n",
      "Speed: 1.6ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/195_socola-sua-cadbury-dairy-milk_F_crop_2.jpg: 192x640 4 texts, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/196_banh-trang-ot_F_crop_0.jpg: 128x640 1 text, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/196_banh-trang-ot_F_crop_1.jpg: 128x640 2 texts, 8.4ms\n",
      "Speed: 0.6ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/196_banh-trang-ot_F_crop_2.jpg: 128x640 3 texts, 8.1ms\n",
      "Speed: 0.8ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/196_banh-trang-ot_F_crop_3.jpg: 320x640 2 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/197_banh-trang-ot_F_crop_0.jpg: 128x640 1 text, 8.6ms\n",
      "Speed: 0.6ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/197_banh-trang-ot_F_crop_1.jpg: 128x640 1 text, 8.4ms\n",
      "Speed: 0.6ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/197_banh-trang-ot_F_crop_2.jpg: 160x640 1 text, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/197_banh-trang-ot_F_crop_3.jpg: 128x640 2 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/197_banh-trang-ot_F_crop_4.jpg: 192x640 3 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/198_mi-trung_F_crop_0.jpg: 256x640 1 text, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 3.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/198_mi-trung_F_crop_1.jpg: 224x640 2 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/199_mi-trung_B_crop_0.jpg: 224x640 4 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/199_mi-trung_B_crop_1.jpg: 256x640 1 text, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/199_mi-trung_B_crop_2.jpg: 192x640 1 text, 9.5ms\n",
      "Speed: 0.7ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/199_mi-trung_B_crop_3.jpg: 192x640 1 text, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/199_mi-trung_B_crop_4.jpg: 352x640 2 texts, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/200_banh-trang_F_crop_0.jpg: 192x640 2 texts, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/200_banh-trang_F_crop_1.jpg: 192x640 2 texts, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/200_banh-trang_F_crop_2.jpg: 352x640 2 texts, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/201_banh-trang_F_crop_0.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/201_banh-trang_F_crop_1.jpg: 128x640 1 text, 8.6ms\n",
      "Speed: 0.6ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/201_banh-trang_F_crop_2.jpg: 96x640 1 text, 9.7ms\n",
      "Speed: 0.5ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/201_banh-trang_F_crop_3.jpg: 160x640 2 texts, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/201_banh-trang_F_crop_4.jpg: 160x640 2 texts, 8.3ms\n",
      "Speed: 0.7ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/201_banh-trang_F_crop_5.jpg: 352x640 2 texts, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/202_banh-trang-thanh-long_F_crop_0.jpg: 448x640 2 texts, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/202_banh-trang-thanh-long_F_crop_1.jpg: 224x640 4 texts, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/202_banh-trang-thanh-long_F_crop_2.jpg: 448x640 2 texts, 9.4ms\n",
      "Speed: 1.7ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/203_banh-trang-thanh-long_B_crop_0.jpg: 192x640 1 text, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/203_banh-trang-thanh-long_B_crop_1.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/204_mi-cai-bo-xoi_F_crop_0.jpg: 320x640 2 texts, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/204_mi-cai-bo-xoi_F_crop_1.jpg: 192x640 4 texts, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "Processed: 600/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/204_mi-cai-bo-xoi_F_crop_2.jpg: 320x640 2 texts, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/205_mi-cai-bo-xoi_B_crop_0.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/205_mi-cai-bo-xoi_B_crop_1.jpg: 160x640 1 text, 8.3ms\n",
      "Speed: 0.7ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/206_mi-cu-cai-do-va-cu-den_F_crop_0.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/206_mi-cu-cai-do-va-cu-den_F_crop_1.jpg: 128x640 7 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/206_mi-cu-cai-do-va-cu-den_F_crop_2.jpg: 320x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/207_mi-cu-cai-do-va-cu-den_B_crop_0.jpg: 64x640 6 texts, 9.7ms\n",
      "Speed: 0.4ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 64, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/207_mi-cu-cai-do-va-cu-den_B_crop_1.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/207_mi-cu-cai-do-va-cu-den_B_crop_2.jpg: 160x640 1 text, 9.4ms\n",
      "Speed: 0.7ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/208_mi-rau-cai-bo-xoi_F_crop_0.jpg: 224x640 1 text, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/208_mi-rau-cai-bo-xoi_F_crop_1.jpg: 160x640 5 texts, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/208_mi-rau-cai-bo-xoi_F_crop_2.jpg: 352x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/209_mi-rau-cai-bo-xoi_B_crop_0.jpg: 96x640 6 texts, 10.3ms\n",
      "Speed: 0.6ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/209_mi-rau-cai-bo-xoi_B_crop_1.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/209_mi-rau-cai-bo-xoi_B_crop_2.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/210_thit-oc-mong-tay_F_crop_0.jpg: 128x640 4 texts, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/210_thit-oc-mong-tay_F_crop_1.jpg: 352x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/210_thit-oc-mong-tay_F_crop_2.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/210_thit-oc-mong-tay_F_crop_3.jpg: 192x640 1 text, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/210_thit-oc-mong-tay_F_crop_4.jpg: 192x640 1 text, 8.3ms\n",
      "Speed: 0.7ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/211_coi-so-diep_F_crop_0.jpg: 160x640 4 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/211_coi-so-diep_F_crop_1.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/211_coi-so-diep_F_crop_2.jpg: 352x640 2 texts, 9.6ms\n",
      "Speed: 1.2ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/212_tep-rong_F_crop_0.jpg: 192x640 2 texts, 9.9ms\n",
      "Speed: 0.8ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/212_tep-rong_F_crop_1.jpg: 320x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/212_tep-rong_F_crop_2.jpg: 256x640 2 texts, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/212_tep-rong_F_crop_3.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/212_tep-rong_F_crop_4.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/213_tom-lot_F_crop_0.jpg: 224x640 2 texts, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/213_tom-lot_F_crop_1.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/213_tom-lot_F_crop_2.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/213_tom-lot_F_crop_3.jpg: 192x640 1 text, 8.3ms\n",
      "Speed: 0.7ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/213_tom-lot_F_crop_4.jpg: 384x640 2 texts, 10.3ms\n",
      "Speed: 1.4ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/214_cot-let_F_crop_0.jpg: 192x640 2 texts, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/214_cot-let_F_crop_1.jpg: 128x640 2 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/214_cot-let_F_crop_2.jpg: 128x640 2 texts, 8.5ms\n",
      "Speed: 0.6ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/214_cot-let_F_crop_3.jpg: 192x640 2 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/214_cot-let_F_crop_4.jpg: 256x640 2 texts, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/214_cot-let_F_crop_5.jpg: 384x640 2 texts, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/214_cot-let_F_crop_6.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.6ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/214_cot-let_F_crop_7.jpg: 160x640 2 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/215_banh-xop-kem-vi-dau_F_crop_0.jpg: 288x640 3 texts, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/215_banh-xop-kem-vi-dau_F_crop_1.jpg: 640x640 10 texts, 9.3ms\n",
      "Speed: 2.4ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/215_banh-xop-kem-vi-dau_F_crop_2.jpg: 416x640 2 texts, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/215_banh-xop-kem-vi-dau_F_crop_3.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/215_banh-xop-kem-vi-dau_F_crop_4.jpg: 160x640 1 text, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/216_banh-xop-kem-vi-dua_F_crop_0.jpg: 288x640 3 texts, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/216_banh-xop-kem-vi-dua_F_crop_1.jpg: 192x640 1 text, 9.5ms\n",
      "Speed: 0.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/216_banh-xop-kem-vi-dua_F_crop_2.jpg: 160x640 1 text, 10.2ms\n",
      "Speed: 0.9ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/216_banh-xop-kem-vi-dua_F_crop_3.jpg: 608x640 10 texts, 8.8ms\n",
      "Speed: 2.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "Processed: 650/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/216_banh-xop-kem-vi-dua_F_crop_4.jpg: 352x640 2 texts, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/217_banh-phong-tom_F_crop_0.jpg: 256x640 3 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/217_banh-phong-tom_F_crop_1.jpg: 128x640 3 texts, 9.5ms\n",
      "Speed: 0.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/218_banh-phong-tom_F_crop_0.jpg: 128x640 3 texts, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/218_banh-phong-tom_F_crop_1.jpg: 384x640 3 texts, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/218_banh-phong-tom_F_crop_2.jpg: 384x640 3 texts, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/218_banh-phong-tom_F_crop_3.jpg: 384x640 2 texts, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/219_bo-thuc-vat_F_crop_0.jpg: 192x640 3 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/219_bo-thuc-vat_F_crop_1.jpg: 320x640 1 text, 9.5ms\n",
      "Speed: 1.1ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/219_bo-thuc-vat_F_crop_2.jpg: 384x640 2 texts, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/220_bo-dau-phong_F_crop_0.jpg: 192x640 2 texts, 8.4ms\n",
      "Speed: 0.7ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/220_bo-dau-phong_F_crop_1.jpg: 192x640 3 texts, 8.3ms\n",
      "Speed: 0.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/220_bo-dau-phong_F_crop_2.jpg: 480x640 2 texts, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/221_bo-dau-phong_F_crop_0.jpg: 192x640 2 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/221_bo-dau-phong_F_crop_1.jpg: 416x640 2 texts, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/222_pork_F_crop_0.jpg: 160x640 1 text, 9.5ms\n",
      "Speed: 0.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/222_pork_F_crop_1.jpg: 288x640 5 texts, 9.2ms\n",
      "Speed: 1.3ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/222_pork_F_crop_2.jpg: 256x640 2 texts, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/223_duong-kinh-trang_F_crop_0.jpg: 128x640 1 text, 9.5ms\n",
      "Speed: 0.7ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/223_duong-kinh-trang_F_crop_1.jpg: 288x640 6 texts, 9.3ms\n",
      "Speed: 1.4ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/224_duong-kinh-trang_B_crop_0.jpg: 192x640 1 text, 10.6ms\n",
      "Speed: 0.9ms preprocess, 10.6ms inference, 3.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/224_duong-kinh-trang_B_crop_1.jpg: 224x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/225_nuoc-cot-dua-xim_F_crop_0.jpg: 512x640 2 texts, 8.7ms\n",
      "Speed: 3.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/225_nuoc-cot-dua-xim_F_crop_1.jpg: 320x640 4 texts, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/225_nuoc-cot-dua-xim_F_crop_2.jpg: 288x640 2 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/226_nuoc-cot-dua-xim_T_crop_0.jpg: 224x640 1 text, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/226_nuoc-cot-dua-xim_T_crop_1.jpg: 224x640 1 text, 8.3ms\n",
      "Speed: 0.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/227_danisa_F_crop_0.jpg: 384x640 1 text, 8.8ms\n",
      "Speed: 1.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/227_danisa_F_crop_1.jpg: 608x640 2 texts, 8.8ms\n",
      "Speed: 2.0ms preprocess, 8.8ms inference, 2.9ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/228_danisa_B_crop_0.jpg: 352x640 1 text, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/228_danisa_B_crop_1.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/228_danisa_B_crop_2.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/229_hat-huong-duong_F_crop_0.jpg: 256x640 2 texts, 9.5ms\n",
      "Speed: 1.1ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/229_hat-huong-duong_F_crop_1.jpg: 640x608 3 texts, 8.7ms\n",
      "Speed: 2.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/229_hat-huong-duong_F_crop_2.jpg: 640x544 2 texts, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/230_hat-huong-duong_B_crop_0.jpg: 192x640 4 texts, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/230_hat-huong-duong_B_crop_1.jpg: 160x640 1 text, 12.8ms\n",
      "Speed: 0.7ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/230_hat-huong-duong_B_crop_2.jpg: 128x640 1 text, 14.1ms\n",
      "Speed: 1.0ms preprocess, 14.1ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/230_hat-huong-duong_B_crop_3.jpg: 160x640 1 text, 13.6ms\n",
      "Speed: 1.1ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/231_ot-hiem_F_crop_0.jpg: 288x640 2 texts, 9.5ms\n",
      "Speed: 1.2ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/231_ot-hiem_F_crop_1.jpg: 256x640 1 text, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/231_ot-hiem_F_crop_2.jpg: 160x640 7 texts, 12.2ms\n",
      "Speed: 1.1ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/231_ot-hiem_F_crop_3.jpg: 448x640 2 texts, 12.0ms\n",
      "Speed: 1.8ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/232_bun-tuoi_F_crop_0.jpg: 192x640 2 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/232_bun-tuoi_F_crop_1.jpg: 256x640 2 texts, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/232_bun-tuoi_F_crop_2.jpg: 224x640 2 texts, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/232_bun-tuoi_F_crop_3.jpg: 256x640 1 text, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/232_bun-tuoi_F_crop_4.jpg: 256x640 1 text, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/233_suon-non-heo_F_crop_0.jpg: 224x640 4 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/233_suon-non-heo_F_crop_1.jpg: 352x640 1 text, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Processed: 700/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/233_suon-non-heo_F_crop_2.jpg: 352x640 1 text, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/233_suon-non-heo_F_crop_3.jpg: 512x640 1 text, 8.8ms\n",
      "Speed: 1.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/233_suon-non-heo_F_crop_4.jpg: 352x640 2 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/234_mam-ruoc-hue_F_crop_0.jpg: 128x640 3 texts, 9.5ms\n",
      "Speed: 0.7ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/234_mam-ruoc-hue_F_crop_1.jpg: 256x640 3 texts, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/235_mam-ruoc-hue_B_crop_0.jpg: 160x640 5 texts, 10.2ms\n",
      "Speed: 0.8ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/235_mam-ruoc-hue_B_crop_1.jpg: 224x640 1 text, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/235_mam-ruoc-hue_B_crop_2.jpg: 416x640 2 texts, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/236_ot-trai-ngam-chua-ngot_B_crop_0.jpg: 128x640 5 texts, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/236_ot-trai-ngam-chua-ngot_B_crop_1.jpg: 192x640 1 text, 9.3ms\n",
      "Speed: 0.9ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/236_ot-trai-ngam-chua-ngot_B_crop_2.jpg: 416x640 2 texts, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/236_ot-trai-ngam-chua-ngot_B_crop_3.jpg: 416x640 2 texts, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/237_ot-trai-ngam-chua-ngot_B_crop_0.jpg: 128x640 3 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/237_ot-trai-ngam-chua-ngot_B_crop_1.jpg: 128x640 3 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/237_ot-trai-ngam-chua-ngot_B_crop_2.jpg: 320x640 5 texts, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/238_cu-cai-muoi-xa-bau_F_crop_0.jpg: 256x640 3 texts, 9.5ms\n",
      "Speed: 1.1ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/238_cu-cai-muoi-xa-bau_F_crop_1.jpg: 416x640 5 texts, 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/238_cu-cai-muoi-xa-bau_F_crop_2.jpg: 320x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/239_cu-cai-muoi-xa-bau_B_crop_0.jpg: 128x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/239_cu-cai-muoi-xa-bau_B_crop_1.jpg: 96x640 1 text, 10.0ms\n",
      "Speed: 0.6ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/240_xot-gia-vi-kho-mia_F_crop_0.jpg: 640x544 6 texts, 8.6ms\n",
      "Speed: 2.3ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/240_xot-gia-vi-kho-mia_F_crop_1.jpg: 480x640 2 texts, 8.9ms\n",
      "Speed: 1.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/241_organic-oat-creamy_F_crop_0.jpg: 384x640 2 texts, 8.9ms\n",
      "Speed: 1.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/241_organic-oat-creamy_F_crop_1.jpg: 448x640 3 texts, 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/241_organic-oat-creamy_F_crop_2.jpg: 576x640 3 texts, 8.7ms\n",
      "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/242_organic-oat-creamy_T_crop_0.jpg: 384x640 2 texts, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/242_organic-oat-creamy_T_crop_1.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/242_organic-oat-creamy_T_crop_2.jpg: 192x640 1 text, 8.4ms\n",
      "Speed: 0.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/242_organic-oat-creamy_T_crop_3.jpg: 256x640 3 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/243_organic-oat-original_F_crop_0.jpg: 352x640 2 texts, 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/243_organic-oat-original_F_crop_1.jpg: 384x640 3 texts, 9.3ms\n",
      "Speed: 1.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/243_organic-oat-original_F_crop_2.jpg: 576x640 3 texts, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/244_organic-oat-original_T_crop_0.jpg: 352x640 2 texts, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/244_organic-oat-original_T_crop_1.jpg: 160x640 1 text, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/244_organic-oat-original_T_crop_2.jpg: 128x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/244_organic-oat-original_T_crop_3.jpg: 224x640 3 texts, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/245_organic-oat-unsweetened_F_crop_0.jpg: 384x640 2 texts, 9.1ms\n",
      "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/245_organic-oat-unsweetened_F_crop_1.jpg: 448x640 3 texts, 9.2ms\n",
      "Speed: 2.0ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/245_organic-oat-unsweetened_F_crop_2.jpg: 544x640 2 texts, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/246_organic-oat-unsweetened_T_crop_0.jpg: 384x640 2 texts, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/246_organic-oat-unsweetened_T_crop_1.jpg: 128x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/246_organic-oat-unsweetened_T_crop_2.jpg: 96x640 1 text, 9.9ms\n",
      "Speed: 0.6ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/246_organic-oat-unsweetened_T_crop_3.jpg: 192x640 3 texts, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/247_organic-oat-unsweetened_F_crop_0.jpg: 352x640 2 texts, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/247_organic-oat-unsweetened_F_crop_1.jpg: 480x640 3 texts, 8.9ms\n",
      "Speed: 2.3ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/247_organic-oat-unsweetened_F_crop_2.jpg: 512x640 3 texts, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/248_coconut-cookies_F_crop_0.jpg: 320x640 1 text, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/248_coconut-cookies_F_crop_1.jpg: 320x640 2 texts, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/248_coconut-cookies_F_crop_2.jpg: 352x640 2 texts, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/248_coconut-cookies_F_crop_3.jpg: 160x640 3 texts, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "Processed: 750/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/248_coconut-cookies_F_crop_4.jpg: 160x640 3 texts, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/249_chocolate-cookies_F_crop_0.jpg: 288x640 1 text, 9.1ms\n",
      "Speed: 1.3ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/249_chocolate-cookies_F_crop_1.jpg: 320x640 2 texts, 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/249_chocolate-cookies_F_crop_2.jpg: 416x640 2 texts, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/250_chocolate-cookies_B_crop_0.jpg: 352x640 1 text, 8.8ms\n",
      "Speed: 1.5ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/250_chocolate-cookies_B_crop_1.jpg: 160x640 3 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/250_chocolate-cookies_B_crop_2.jpg: 160x640 3 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/250_chocolate-cookies_B_crop_3.jpg: 320x640 3 texts, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/250_chocolate-cookies_B_crop_4.jpg: 384x640 2 texts, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/251_nam-bung-de_F_crop_0.jpg: 576x640 3 texts, 8.5ms\n",
      "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/251_nam-bung-de_F_crop_1.jpg: 384x640 3 texts, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/252_nam-bung-de_B_crop_0.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/252_nam-bung-de_B_crop_1.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/252_nam-bung-de_B_crop_2.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/252_nam-bung-de_B_crop_3.jpg: 512x640 2 texts, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/253_nam-huong_B_crop_0.jpg: 224x640 2 texts, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/253_nam-huong_B_crop_1.jpg: 224x640 1 text, 8.3ms\n",
      "Speed: 0.9ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/253_nam-huong_B_crop_2.jpg: 192x640 1 text, 9.8ms\n",
      "Speed: 0.8ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/253_nam-huong_B_crop_3.jpg: 416x640 2 texts, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/254_nam-huong_F_crop_0.jpg: 544x640 3 texts, 8.9ms\n",
      "Speed: 1.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/254_nam-huong_F_crop_1.jpg: 320x640 2 texts, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/255_nam-thai-duong_F_crop_0.jpg: 608x640 3 texts, 8.9ms\n",
      "Speed: 2.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/255_nam-thai-duong_F_crop_1.jpg: 640x640 3 texts, 8.6ms\n",
      "Speed: 2.5ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/256_nam-thai-duong_B_crop_0.jpg: 192x640 3 texts, 9.6ms\n",
      "Speed: 1.1ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/256_nam-thai-duong_B_crop_1.jpg: 640x224 2 texts, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/256_nam-thai-duong_B_crop_2.jpg: 640x224 3 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/256_nam-thai-duong_B_crop_3.jpg: 416x640 2 texts, 8.4ms\n",
      "Speed: 1.3ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/257_moc-nhi-bao-tu_F_crop_0.jpg: 544x640 3 texts, 8.8ms\n",
      "Speed: 1.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/257_moc-nhi-bao-tu_F_crop_1.jpg: 320x640 4 texts, 9.6ms\n",
      "Speed: 1.3ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/258_moc-nhi-bao-tu_B_crop_0.jpg: 128x640 4 texts, 10.4ms\n",
      "Speed: 0.8ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/258_moc-nhi-bao-tu_B_crop_1.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/258_moc-nhi-bao-tu_B_crop_2.jpg: 192x640 1 text, 8.4ms\n",
      "Speed: 0.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/258_moc-nhi-bao-tu_B_crop_3.jpg: 544x640 2 texts, 8.8ms\n",
      "Speed: 1.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/259_nam-dong-co-kho_F_crop_0.jpg: 256x640 2 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/259_nam-dong-co-kho_F_crop_1.jpg: 352x640 4 texts, 8.8ms\n",
      "Speed: 1.5ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/259_nam-dong-co-kho_F_crop_2.jpg: 640x160 6 texts, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/259_nam-dong-co-kho_F_crop_3.jpg: 96x640 9 texts, 10.1ms\n",
      "Speed: 0.5ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/259_nam-dong-co-kho_F_crop_4.jpg: 384x640 2 texts, 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/260_goi-canh-dong-trung-ha-thao_F_crop_0.jpg: 416x640 10 texts, 8.6ms\n",
      "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/261_goi-canh-dong-trung-ha-thao_T_crop_0.jpg: 224x640 3 texts, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/261_goi-canh-dong-trung-ha-thao_T_crop_1.jpg: 192x640 3 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/262_ghe-sua-tam-me-say-gion_F_crop_0.jpg: 640x480 2 texts, 8.8ms\n",
      "Speed: 2.2ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/262_ghe-sua-tam-me-say-gion_F_crop_1.jpg: 288x640 6 texts, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/262_ghe-sua-tam-me-say-gion_F_crop_2.jpg: 320x640 2 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/263_ghe-sua-tam-me-say-gion_B_crop_0.jpg: 640x256 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/263_ghe-sua-tam-me-say-gion_B_crop_1.jpg: 160x640 1 text, 9.7ms\n",
      "Speed: 0.7ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/263_ghe-sua-tam-me-say-gion_B_crop_2.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/263_ghe-sua-tam-me-say-gion_B_crop_3.jpg: 640x544 2 texts, 8.7ms\n",
      "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/264_bun-rieu-chay_T_crop_0.jpg: 192x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/264_bun-rieu-chay_T_crop_1.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "Processed: 800/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/265_bun-rieu-chay_F_crop_0.jpg: 416x640 3 texts, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/265_bun-rieu-chay_F_crop_1.jpg: 384x640 4 texts, 9.8ms\n",
      "Speed: 1.9ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/265_bun-rieu-chay_F_crop_2.jpg: 352x640 2 texts, 9.5ms\n",
      "Speed: 1.2ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/266_ruoc-tam-gia-vi-say-gion_F_crop_0.jpg: 640x480 2 texts, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/266_ruoc-tam-gia-vi-say-gion_F_crop_1.jpg: 288x640 6 texts, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/266_ruoc-tam-gia-vi-say-gion_F_crop_2.jpg: 416x640 2 texts, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/267_ruoc-tam-gia-vi-say-gion_B_crop_0.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/267_ruoc-tam-gia-vi-say-gion_B_crop_1.jpg: 128x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/267_ruoc-tam-gia-vi-say-gion_B_crop_2.jpg: 640x480 2 texts, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/267_ruoc-tam-gia-vi-say-gion_B_crop_3.jpg: 640x224 2 texts, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/268_kho-muc-xe-tam-gia-vi_F_crop_0.jpg: 640x480 2 texts, 9.0ms\n",
      "Speed: 1.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/268_kho-muc-xe-tam-gia-vi_F_crop_1.jpg: 288x640 6 texts, 9.1ms\n",
      "Speed: 1.3ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/268_kho-muc-xe-tam-gia-vi_F_crop_2.jpg: 288x640 2 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/269_kho-muc-xe-tam-gia-vi_B_crop_0.jpg: 640x192 2 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/269_kho-muc-xe-tam-gia-vi_B_crop_1.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/269_kho-muc-xe-tam-gia-vi_B_crop_2.jpg: 128x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/269_kho-muc-xe-tam-gia-vi_B_crop_3.jpg: 640x384 2 texts, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/270_hu-tieu-chay_F_crop_0.jpg: 512x640 3 texts, 8.1ms\n",
      "Speed: 2.0ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/270_hu-tieu-chay_F_crop_1.jpg: 416x640 4 texts, 8.2ms\n",
      "Speed: 2.0ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/270_hu-tieu-chay_F_crop_2.jpg: 352x640 2 texts, 10.6ms\n",
      "Speed: 1.2ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/271_hu-tieu-chay_T_crop_0.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/271_hu-tieu-chay_T_crop_1.jpg: 128x640 4 texts, 8.9ms\n",
      "Speed: 0.5ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/272_kho-ca-bong-cat-soi_F_crop_0.jpg: 640x544 2 texts, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/272_kho-ca-bong-cat-soi_F_crop_1.jpg: 288x640 5 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/272_kho-ca-bong-cat-soi_F_crop_2.jpg: 384x640 2 texts, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/273_kho-ca-bong-cat-soi_B_crop_0.jpg: 640x224 2 texts, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/273_kho-ca-bong-cat-soi_B_crop_1.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/273_kho-ca-bong-cat-soi_B_crop_2.jpg: 128x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/273_kho-ca-bong-cat-soi_B_crop_3.jpg: 640x576 2 texts, 8.4ms\n",
      "Speed: 1.8ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/274_muc-rim-me_T_crop_0.jpg: 224x640 3 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/274_muc-rim-me_T_crop_1.jpg: 192x640 1 text, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/274_muc-rim-me_T_crop_2.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/275_muc-rim-me_F_crop_0.jpg: 640x512 2 texts, 39.5ms\n",
      "Speed: 1.7ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/275_muc-rim-me_F_crop_1.jpg: 352x640 3 texts, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/275_muc-rim-me_F_crop_2.jpg: 352x640 2 texts, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/276_kho-bo-xe-cay_F_crop_0.jpg: 640x480 2 texts, 8.9ms\n",
      "Speed: 1.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/276_kho-bo-xe-cay_F_crop_1.jpg: 448x640 4 texts, 8.9ms\n",
      "Speed: 1.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/276_kho-bo-xe-cay_F_crop_2.jpg: 448x640 2 texts, 8.3ms\n",
      "Speed: 2.0ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/276_kho-bo-xe-cay_F_crop_3.jpg: 448x640 1 text, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/277_kho-bo-xe-cay_F_crop_0.jpg: 640x352 2 texts, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 352)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/277_kho-bo-xe-cay_F_crop_1.jpg: 384x640 2 texts, 9.3ms\n",
      "Speed: 1.3ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/277_kho-bo-xe-cay_F_crop_2.jpg: 256x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/278_xot-spaghetti_F_crop_0.jpg: 256x640 5 texts, 8.3ms\n",
      "Speed: 1.3ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/278_xot-spaghetti_F_crop_1.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/278_xot-spaghetti_F_crop_2.jpg: 384x640 2 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/279_xot-spaghetti_B_crop_0.jpg: 160x640 1 text, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/279_xot-spaghetti_B_crop_1.jpg: 160x640 1 text, 9.8ms\n",
      "Speed: 1.1ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/279_xot-spaghetti_B_crop_2.jpg: 256x640 5 texts, 9.5ms\n",
      "Speed: 1.3ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/279_xot-spaghetti_B_crop_3.jpg: 320x640 1 text, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/280_banh-hoi_F_crop_0.jpg: 256x640 2 texts, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Processed: 850/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/280_banh-hoi_F_crop_1.jpg: 352x640 2 texts, 9.4ms\n",
      "Speed: 1.7ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/280_banh-hoi_F_crop_2.jpg: 192x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/281_banh-hoi_B_crop_0.jpg: 128x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/281_banh-hoi_B_crop_1.jpg: 128x640 1 text, 8.4ms\n",
      "Speed: 0.6ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/282_rong-nho-tach-nuoc_F_crop_0.jpg: 640x512 2 texts, 8.6ms\n",
      "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/282_rong-nho-tach-nuoc_F_crop_1.jpg: 128x640 4 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/282_rong-nho-tach-nuoc_F_crop_2.jpg: 320x640 2 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/283_rong-nho-tach-nuoc_D_crop_0.jpg: 192x640 1 text, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/284_rong-bien-gion-tron-gia-vi_F_crop_0.jpg: 352x640 1 text, 9.1ms\n",
      "Speed: 1.3ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/284_rong-bien-gion-tron-gia-vi_F_crop_1.jpg: 256x640 8 texts, 9.5ms\n",
      "Speed: 1.3ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/284_rong-bien-gion-tron-gia-vi_F_crop_2.jpg: 576x640 2 texts, 9.0ms\n",
      "Speed: 1.7ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/284_rong-bien-gion-tron-gia-vi_F_crop_3.jpg: 128x640 1 text, 9.4ms\n",
      "Speed: 0.5ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/284_rong-bien-gion-tron-gia-vi_F_crop_4.jpg: 128x640 1 text, 8.3ms\n",
      "Speed: 0.5ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/285_rong-bien-gion-tron-gia-vi_F_crop_0.jpg: 448x640 1 text, 9.3ms\n",
      "Speed: 1.5ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/285_rong-bien-gion-tron-gia-vi_F_crop_1.jpg: 384x640 6 texts, 9.6ms\n",
      "Speed: 1.9ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/285_rong-bien-gion-tron-gia-vi_F_crop_2.jpg: 416x640 2 texts, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 3.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/285_rong-bien-gion-tron-gia-vi_F_crop_3.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/285_rong-bien-gion-tron-gia-vi_F_crop_4.jpg: 192x640 1 text, 8.2ms\n",
      "Speed: 0.7ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/286_banh-phong_F_crop_0.jpg: 512x640 2 texts, 9.1ms\n",
      "Speed: 2.8ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/286_banh-phong_F_crop_1.jpg: 544x640 4 texts, 9.0ms\n",
      "Speed: 3.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/286_banh-phong_F_crop_2.jpg: 224x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/286_banh-phong_F_crop_3.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/287_banh-phong_D_crop_0.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.6ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/287_banh-phong_D_crop_1.jpg: 160x640 1 text, 8.3ms\n",
      "Speed: 0.7ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/288_banh-phong-tom_F_crop_0.jpg: 640x512 2 texts, 8.3ms\n",
      "Speed: 1.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/288_banh-phong-tom_F_crop_1.jpg: 160x640 3 texts, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/288_banh-phong-tom_F_crop_2.jpg: 384x640 2 texts, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/289_banh-phong-tom_B_crop_0.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/289_banh-phong-tom_B_crop_1.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/290_rong-bien_F_crop_0.jpg: 224x640 1 text, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/290_rong-bien_F_crop_1.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/290_rong-bien_F_crop_2.jpg: 128x640 2 texts, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/290_rong-bien_F_crop_3.jpg: 480x640 2 texts, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/291_banh-phong-gao-lut_F_crop_0.jpg: 256x640 1 text, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/291_banh-phong-gao-lut_F_crop_1.jpg: 224x640 3 texts, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/291_banh-phong-gao-lut_F_crop_2.jpg: 128x640 4 texts, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/291_banh-phong-gao-lut_F_crop_3.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/292_banh-phong-gao-lut_B_crop_0.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/292_banh-phong-gao-lut_B_crop_1.jpg: 128x640 1 text, 9.4ms\n",
      "Speed: 0.7ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/293_banh-trang-gao_F_crop_0.jpg: 320x640 1 text, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/293_banh-trang-gao_F_crop_1.jpg: 192x640 6 texts, 9.6ms\n",
      "Speed: 1.1ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/293_banh-trang-gao_F_crop_2.jpg: 128x640 1 text, 9.2ms\n",
      "Speed: 0.6ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/293_banh-trang-gao_F_crop_3.jpg: 128x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/293_banh-trang-gao_F_crop_4.jpg: 128x640 1 text, 9.8ms\n",
      "Speed: 0.7ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/293_banh-trang-gao_F_crop_5.jpg: 288x640 2 texts, 10.6ms\n",
      "Speed: 1.2ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/293_banh-trang-gao_F_crop_6.jpg: 96x640 7 texts, 11.3ms\n",
      "Speed: 0.5ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/294_banh-trang-gao_B_crop_0.jpg: 320x640 1 text, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/294_banh-trang-gao_B_crop_1.jpg: 224x640 6 texts, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/294_banh-trang-gao_B_crop_2.jpg: 288x640 2 texts, 11.1ms\n",
      "Speed: 1.0ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/294_banh-trang-gao_B_crop_3.jpg: 128x640 1 text, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "Processed: 900/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/294_banh-trang-gao_B_crop_4.jpg: 128x640 1 text, 8.5ms\n",
      "Speed: 0.6ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/294_banh-trang-gao_B_crop_5.jpg: 128x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/295_banh-da-me-vang-dua-soi_F_crop_0.jpg: 640x480 2 texts, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/295_banh-da-me-vang-dua-soi_F_crop_1.jpg: 96x640 6 texts, 9.9ms\n",
      "Speed: 0.6ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/295_banh-da-me-vang-dua-soi_F_crop_2.jpg: 224x640 2 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/296_banh-da-me-vang-dua-soi_B_crop_0.jpg: 224x640 6 texts, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/296_banh-da-me-vang-dua-soi_B_crop_1.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/296_banh-da-me-vang-dua-soi_B_crop_2.jpg: 192x640 1 text, 8.4ms\n",
      "Speed: 0.8ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/296_banh-da-me-vang-dua-soi_B_crop_3.jpg: 192x640 1 text, 9.9ms\n",
      "Speed: 0.8ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/297_banh-trang_F_crop_0.jpg: 160x640 2 texts, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/297_banh-trang_F_crop_1.jpg: 352x640 2 texts, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/297_banh-trang_F_crop_2.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/297_banh-trang_F_crop_3.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/297_banh-trang_F_crop_4.jpg: 160x640 2 texts, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/298_banh-trang-khong-nhung-nuoc_F_crop_0.jpg: 640x544 2 texts, 9.6ms\n",
      "Speed: 2.0ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/298_banh-trang-khong-nhung-nuoc_F_crop_1.jpg: 96x640 5 texts, 9.9ms\n",
      "Speed: 0.6ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/298_banh-trang-khong-nhung-nuoc_F_crop_2.jpg: 256x640 2 texts, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/299_banh-trang-khong-nhung-nuoc_B_crop_0.jpg: 224x640 5 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/299_banh-trang-khong-nhung-nuoc_B_crop_1.jpg: 192x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/299_banh-trang-khong-nhung-nuoc_B_crop_2.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/299_banh-trang-khong-nhung-nuoc_B_crop_3.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/300_banh-trang-nuong_F_crop_0.jpg: 288x640 1 text, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/300_banh-trang-nuong_F_crop_1.jpg: 160x640 3 texts, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/301_banh-trang_F_crop_0.jpg: 192x640 2 texts, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/301_banh-trang_F_crop_1.jpg: 384x640 4 texts, 8.8ms\n",
      "Speed: 1.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/301_banh-trang_F_crop_2.jpg: 608x640 2 texts, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/302_banh-trang_B_crop_0.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/302_banh-trang_B_crop_1.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/303_banh-phong-gao-lut_F_crop_0.jpg: 288x640 4 texts, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/303_banh-phong-gao-lut_F_crop_1.jpg: 224x640 1 text, 9.4ms\n",
      "Speed: 1.0ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/303_banh-phong-gao-lut_F_crop_2.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/303_banh-phong-gao-lut_F_crop_3.jpg: 288x640 2 texts, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/304_gia-vi-rac-com_F_crop_0.jpg: 288x640 1 text, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/304_gia-vi-rac-com_F_crop_1.jpg: 320x640 4 texts, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/304_gia-vi-rac-com_F_crop_2.jpg: 384x640 2 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/305_gia-vi-rac-com_B_crop_0.jpg: 96x640 1 text, 9.9ms\n",
      "Speed: 0.6ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/305_gia-vi-rac-com_B_crop_1.jpg: 96x640 1 text, 9.4ms\n",
      "Speed: 0.6ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/305_gia-vi-rac-com_B_crop_2.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/306_kho-bo-uc_F_crop_0.jpg: 160x640 1 text, 9.7ms\n",
      "Speed: 0.8ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/306_kho-bo-uc_F_crop_1.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/306_kho-bo-uc_F_crop_2.jpg: 160x640 3 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/306_kho-bo-uc_F_crop_3.jpg: 288x640 5 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/306_kho-bo-uc_F_crop_4.jpg: 288x640 2 texts, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/307_thi-bo-kho_F_crop_0.jpg: 320x640 4 texts, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/307_thi-bo-kho_F_crop_1.jpg: 192x640 3 texts, 9.3ms\n",
      "Speed: 0.9ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/307_thi-bo-kho_F_crop_2.jpg: 256x640 2 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/307_thi-bo-kho_F_crop_3.jpg: 256x640 1 text, 8.4ms\n",
      "Speed: 0.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/307_thi-bo-kho_F_crop_4.jpg: 256x640 1 text, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/307_thi-bo-kho_F_crop_5.jpg: 448x640 2 texts, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/308_muc-nuong_F_crop_0.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "Processed: 950/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/308_muc-nuong_F_crop_1.jpg: 224x640 6 texts, 10.2ms\n",
      "Speed: 1.1ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/309_muc-nuong-can-duoi-tam-ot_B_crop_0.jpg: 192x640 6 texts, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/309_muc-nuong-can-duoi-tam-ot_B_crop_1.jpg: 160x640 3 texts, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/309_muc-nuong-can-duoi-tam-ot_B_crop_2.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/309_muc-nuong-can-duoi-tam-ot_B_crop_3.jpg: 128x640 1 text, 8.4ms\n",
      "Speed: 0.6ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/309_muc-nuong-can-duoi-tam-ot_B_crop_4.jpg: 352x640 2 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/310_bento_B_crop_0.jpg: 160x640 1 text, 10.9ms\n",
      "Speed: 1.0ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/310_bento_B_crop_1.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/311_bento_F_crop_0.jpg: 256x640 1 text, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/312_thit-bo-kho_F_crop_0.jpg: 256x640 1 text, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/312_thit-bo-kho_F_crop_1.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/312_thit-bo-kho_F_crop_2.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/312_thit-bo-kho_F_crop_3.jpg: 192x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/312_thit-bo-kho_F_crop_4.jpg: 576x640 3 texts, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/313_thit-bo-kho_F_crop_0.jpg: 256x640 1 text, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/313_thit-bo-kho_F_crop_1.jpg: 256x640 1 text, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/313_thit-bo-kho_F_crop_2.jpg: 320x640 4 texts, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/313_thit-bo-kho_F_crop_3.jpg: 288x640 5 texts, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/313_thit-bo-kho_F_crop_4.jpg: 448x640 2 texts, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/314_nui-no_F_crop_0.jpg: 480x640 2 texts, 8.7ms\n",
      "Speed: 1.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/314_nui-no_F_crop_1.jpg: 256x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/314_nui-no_F_crop_2.jpg: 320x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/315_nui-no_F_crop_0.jpg: 256x640 2 texts, 9.7ms\n",
      "Speed: 1.1ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/315_nui-no_F_crop_1.jpg: 160x640 1 text, 9.5ms\n",
      "Speed: 0.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/315_nui-no_F_crop_2.jpg: 160x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/316_lap-xuong_F_crop_0.jpg: 384x640 1 text, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/316_lap-xuong_F_crop_1.jpg: 224x640 5 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/316_lap-xuong_F_crop_2.jpg: 224x640 2 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/317_lap-xuong_B_crop_0.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/317_lap-xuong_B_crop_1.jpg: 160x640 1 text, 8.4ms\n",
      "Speed: 0.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/318_dates-dried-fruit_F_crop_0.jpg: 160x640 1 text, 8.1ms\n",
      "Speed: 0.8ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/318_dates-dried-fruit_F_crop_1.jpg: 256x640 3 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/318_dates-dried-fruit_F_crop_2.jpg: 288x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/319_dates-dried-fruit_T_crop_0.jpg: 224x640 1 text, 10.7ms\n",
      "Speed: 1.1ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/319_dates-dried-fruit_T_crop_1.jpg: 224x640 1 text, 9.8ms\n",
      "Speed: 1.1ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/319_dates-dried-fruit_T_crop_2.jpg: 192x640 1 text, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/320_banh-quy-lua-mi_D_crop_0.jpg: 128x640 6 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/320_banh-quy-lua-mi_D_crop_1.jpg: 128x640 3 texts, 8.3ms\n",
      "Speed: 0.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/320_banh-quy-lua-mi_D_crop_2.jpg: 96x640 1 text, 9.8ms\n",
      "Speed: 0.7ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/320_banh-quy-lua-mi_D_crop_3.jpg: 96x640 1 text, 9.3ms\n",
      "Speed: 0.6ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/320_banh-quy-lua-mi_D_crop_4.jpg: 320x640 2 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/321_banh-yen-mach-sua_F_crop_0.jpg: 416x640 1 text, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/321_banh-yen-mach-sua_F_crop_1.jpg: 160x640 4 texts, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/321_banh-yen-mach-sua_F_crop_2.jpg: 192x640 3 texts, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/321_banh-yen-mach-sua_F_crop_3.jpg: 192x640 3 texts, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/322_snack-que-nhan-sua_F_crop_0.jpg: 544x640 1 text, 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/322_snack-que-nhan-sua_F_crop_1.jpg: 128x640 4 texts, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/323_socola-phu-dua_B_crop_0.jpg: 128x640 5 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/323_socola-phu-dua_B_crop_1.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/323_socola-phu-dua_B_crop_2.jpg: 96x640 7 texts, 10.1ms\n",
      "Speed: 0.5ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "Processed: 1000/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/324_socola-sua-ritter-sport_B_crop_0.jpg: 160x640 11 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/324_socola-sua-ritter-sport_B_crop_1.jpg: 448x640 2 texts, 9.8ms\n",
      "Speed: 1.4ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/324_socola-sua-ritter-sport_B_crop_2.jpg: 160x640 1 text, 9.9ms\n",
      "Speed: 0.6ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/324_socola-sua-ritter-sport_B_crop_3.jpg: 128x640 1 text, 8.7ms\n",
      "Speed: 0.6ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/325_socola-nhan-kem-ca-phe_F_crop_0.jpg: 288x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/325_socola-nhan-kem-ca-phe_F_crop_1.jpg: 320x640 7 texts, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/326_socola-nhan-kem-ca-phe_B_crop_0.jpg: 352x640 2 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/326_socola-nhan-kem-ca-phe_B_crop_1.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/326_socola-nhan-kem-ca-phe_B_crop_2.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/327_socola-sua-nhan-hat-sen_F_crop_0.jpg: 320x640 3 texts, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/327_socola-sua-nhan-hat-sen_F_crop_1.jpg: 128x640 7 texts, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/327_socola-sua-nhan-hat-sen_F_crop_2.jpg: 256x640 2 texts, 9.1ms\n",
      "Speed: 1.3ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/328_socola-sua-nhan-hat-sen_B_crop_0.jpg: 320x640 2 texts, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/328_socola-sua-nhan-hat-sen_B_crop_1.jpg: 224x640 1 text, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/328_socola-sua-nhan-hat-sen_B_crop_2.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/329_socola-sua_F_crop_0.jpg: 224x640 1 text, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/329_socola-sua_F_crop_1.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/329_socola-sua_F_crop_2.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/330_socola-sua_B_crop_0.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/330_socola-sua_B_crop_1.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/330_socola-sua_B_crop_2.jpg: 128x640 1 text, 8.8ms\n",
      "Speed: 0.6ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/331_socola-den_F_crop_0.jpg: 288x640 1 text, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/331_socola-den_F_crop_1.jpg: 256x640 4 texts, 10.1ms\n",
      "Speed: 1.1ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/331_socola-den_F_crop_2.jpg: 448x640 2 texts, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/332_socola-trang-voi-banh-quy_F_crop_0.jpg: 288x640 5 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/332_socola-trang-voi-banh-quy_F_crop_1.jpg: 256x640 1 text, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/332_socola-trang-voi-banh-quy_F_crop_2.jpg: 352x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/333_socola-trang-voi-banh-quy_F_crop_0.jpg: 256x640 5 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/333_socola-trang-voi-banh-quy_F_crop_1.jpg: 640x128 4 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/333_socola-trang-voi-banh-quy_F_crop_2.jpg: 640x128 5 texts, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/334_banh-xop-phu-socola-sua_F_crop_0.jpg: 480x640 1 text, 13.2ms\n",
      "Speed: 2.1ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/334_banh-xop-phu-socola-sua_F_crop_1.jpg: 64x640 9 texts, 14.3ms\n",
      "Speed: 0.7ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 64, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/334_banh-xop-phu-socola-sua_F_crop_2.jpg: 288x640 2 texts, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/334_banh-xop-phu-socola-sua_F_crop_3.jpg: 544x640 3 texts, 8.6ms\n",
      "Speed: 2.1ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/335_banh-xop-phu-socola-sua_F_crop_0.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/335_banh-xop-phu-socola-sua_F_crop_1.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/336_socola-dieu_F_crop_0.jpg: 384x640 2 texts, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/336_socola-dieu_F_crop_1.jpg: 448x640 6 texts, 8.7ms\n",
      "Speed: 1.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/336_socola-dieu_F_crop_2.jpg: 640x448 2 texts, 39.2ms\n",
      "Speed: 1.4ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/337_socola-dieu_D_crop_0.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/337_socola-dieu_D_crop_1.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/338_socola-hanh-nhan_F_crop_0.jpg: 288x640 1 text, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/338_socola-hanh-nhan_F_crop_1.jpg: 96x640 3 texts, 9.9ms\n",
      "Speed: 0.6ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/338_socola-hanh-nhan_F_crop_2.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/339_socola-hanh-nhan_B_crop_0.jpg: 192x640 1 text, 8.1ms\n",
      "Speed: 0.9ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/339_socola-hanh-nhan_B_crop_1.jpg: 96x640 9 texts, 10.1ms\n",
      "Speed: 0.6ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/339_socola-hanh-nhan_B_crop_2.jpg: 320x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/339_socola-hanh-nhan_B_crop_3.jpg: 224x640 1 text, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/339_socola-hanh-nhan_B_crop_4.jpg: 224x640 1 text, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/340_splendeur-assortment_F_crop_0.jpg: 288x640 1 text, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Processed: 1050/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/340_splendeur-assortment_F_crop_1.jpg: 224x640 2 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/340_splendeur-assortment_F_crop_2.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/340_splendeur-assortment_F_crop_3.jpg: 128x640 1 text, 8.7ms\n",
      "Speed: 0.6ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/341_coconut-wafers_F_crop_0.jpg: 160x640 5 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/341_coconut-wafers_F_crop_1.jpg: 288x640 2 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/341_coconut-wafers_F_crop_2.jpg: 256x640 2 texts, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/342_coconut-wafers_T_crop_0.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/342_coconut-wafers_T_crop_1.jpg: 160x640 1 text, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/343_nabati_F_crop_0.jpg: 96x640 5 texts, 10.7ms\n",
      "Speed: 0.6ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/343_nabati_F_crop_1.jpg: 256x640 1 text, 9.2ms\n",
      "Speed: 1.3ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/343_nabati_F_crop_2.jpg: 416x640 2 texts, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/344_nabati_B_crop_0.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/344_nabati_B_crop_1.jpg: 160x640 1 text, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/345_dream-cake_F_crop_0.jpg: 192x640 1 text, 9.6ms\n",
      "Speed: 0.9ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/345_dream-cake_F_crop_1.jpg: 320x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/346_dream-cake_T_crop_0.jpg: 160x640 1 text, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/346_dream-cake_T_crop_1.jpg: 160x640 1 text, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/346_dream-cake_T_crop_2.jpg: 224x640 1 text, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/347_chocolate-sua_F_crop_0.jpg: 384x640 1 text, 9.7ms\n",
      "Speed: 1.7ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/347_chocolate-sua_F_crop_1.jpg: 128x640 2 texts, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/347_chocolate-sua_F_crop_2.jpg: 128x640 3 texts, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/347_chocolate-sua_F_crop_3.jpg: 352x640 2 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/348_hocolate-sua_D_crop_0.jpg: 128x640 1 text, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/348_hocolate-sua_D_crop_1.jpg: 128x640 1 text, 8.3ms\n",
      "Speed: 0.6ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/349_bot-hoa-tan-atiso_F_crop_0.jpg: 224x640 2 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/349_bot-hoa-tan-atiso_F_crop_1.jpg: 256x640 4 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/349_bot-hoa-tan-atiso_F_crop_2.jpg: 288x640 2 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/350_bot-hoa-tan-atiso_B_crop_0.jpg: 128x640 4 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/350_bot-hoa-tan-atiso_B_crop_1.jpg: 128x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/351_duong-tinh-luyen_F_crop_0.jpg: 384x640 2 texts, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/351_duong-tinh-luyen_F_crop_1.jpg: 640x640 3 texts, 8.7ms\n",
      "Speed: 2.4ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/351_duong-tinh-luyen_F_crop_2.jpg: 512x640 2 texts, 9.2ms\n",
      "Speed: 1.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/352_sen-tuoi-say_F_crop_0.jpg: 256x640 1 text, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/352_sen-tuoi-say_F_crop_1.jpg: 608x640 3 texts, 9.1ms\n",
      "Speed: 2.3ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/352_sen-tuoi-say_F_crop_2.jpg: 352x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/353_sen-tuoi-say_D_crop_0.jpg: 256x640 1 text, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/353_sen-tuoi-say_D_crop_1.jpg: 640x128 2 texts, 9.4ms\n",
      "Speed: 0.6ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/353_sen-tuoi-say_D_crop_2.jpg: 640x128 4 texts, 7.8ms\n",
      "Speed: 0.6ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/354_hat-huong-duong-vi-dua_F_crop_0.jpg: 128x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/354_hat-huong-duong-vi-dua_F_crop_1.jpg: 640x192 5 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/354_hat-huong-duong-vi-dua_F_crop_2.jpg: 416x640 2 texts, 9.2ms\n",
      "Speed: 1.4ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/355_hat-huong-duong-vi-dua_B_crop_0.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/355_hat-huong-duong-vi-dua_B_crop_1.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/355_hat-huong-duong-vi-dua_B_crop_2.jpg: 640x64 (no detections), 36.7ms\n",
      "Speed: 0.5ms preprocess, 36.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 64)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/355_hat-huong-duong-vi-dua_B_crop_3.jpg: 640x64 (no detections), 9.4ms\n",
      "Speed: 0.5ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 64)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/356_hat-huong-duong-vi-ngu-vi-huong_F_crop_0.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/356_hat-huong-duong-vi-ngu-vi-huong_F_crop_1.jpg: 640x192 8 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/356_hat-huong-duong-vi-ngu-vi-huong_F_crop_2.jpg: 384x640 2 texts, 9.3ms\n",
      "Speed: 1.3ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/357_hat-huong-duong-vi-ngu-vi-huong_B_crop_0.jpg: 288x640 3 texts, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/357_hat-huong-duong-vi-ngu-vi-huong_B_crop_1.jpg: 96x640 5 texts, 10.1ms\n",
      "Speed: 0.5ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "Processed: 1100/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/357_hat-huong-duong-vi-ngu-vi-huong_B_crop_2.jpg: 64x640 5 texts, 10.1ms\n",
      "Speed: 0.5ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 64, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/358_hat-huong-duong_F_crop_0.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/358_hat-huong-duong_F_crop_1.jpg: 640x192 5 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/358_hat-huong-duong_F_crop_2.jpg: 480x640 2 texts, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/359_hat-huong-duong_B_crop_0.jpg: 64x640 5 texts, 10.3ms\n",
      "Speed: 0.5ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 64, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/359_hat-huong-duong_B_crop_1.jpg: 64x640 5 texts, 9.6ms\n",
      "Speed: 0.5ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 64, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/360_hat-chia_F_crop_0.jpg: 352x640 2 texts, 9.3ms\n",
      "Speed: 2.4ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/360_hat-chia_F_crop_1.jpg: 512x640 2 texts, 8.5ms\n",
      "Speed: 2.8ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/360_hat-chia_F_crop_2.jpg: 416x640 2 texts, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/361_hat-chia_D_crop_0.jpg: 192x640 3 texts, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/361_hat-chia_D_crop_1.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/362_ca-phe-phin-giay_F_crop_0.jpg: 320x640 4 texts, 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/362_ca-phe-phin-giay_F_crop_1.jpg: 224x640 4 texts, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/362_ca-phe-phin-giay_F_crop_2.jpg: 288x640 4 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/362_ca-phe-phin-giay_F_crop_3.jpg: 320x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/363_ca-phe-pin-giay_D_crop_0.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/363_ca-phe-pin-giay_D_crop_1.jpg: 160x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/364_ca-phe-rang-xay_F_crop_0.jpg: 128x640 4 texts, 8.5ms\n",
      "Speed: 0.6ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/364_ca-phe-rang-xay_F_crop_1.jpg: 256x640 4 texts, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/364_ca-phe-rang-xay_F_crop_2.jpg: 480x640 3 texts, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/364_ca-phe-rang-xay_F_crop_3.jpg: 320x640 2 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/365_ca-phe-rangxay_D_crop_0.jpg: 160x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/365_ca-phe-rangxay_D_crop_1.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/366_tra-trai-cay-hat-chia_F_crop_0.jpg: 96x640 5 texts, 9.8ms\n",
      "Speed: 0.6ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/366_tra-trai-cay-hat-chia_F_crop_1.jpg: 256x640 7 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/366_tra-trai-cay-hat-chia_F_crop_2.jpg: 320x640 2 texts, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/367_tra-trai-cay-hat-chia_L_crop_0.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/367_tra-trai-cay-hat-chia_L_crop_1.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/368_ngoi-sao-phuong-nam_F_crop_0.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/368_ngoi-sao-phuong-nam_F_crop_1.jpg: 224x640 4 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/368_ngoi-sao-phuong-nam_F_crop_2.jpg: 512x640 2 texts, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/369_banh-dua-nuong_F_crop_0.jpg: 640x448 2 texts, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/369_banh-dua-nuong_F_crop_1.jpg: 224x640 11 texts, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/369_banh-dua-nuong_F_crop_2.jpg: 416x640 2 texts, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/370_banh-dua-uong_D_crop_0.jpg: 288x640 3 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/370_banh-dua-uong_D_crop_1.jpg: 256x640 3 texts, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/371_trung-ga-omega-3_F_crop_0.jpg: 224x640 2 texts, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/371_trung-ga-omega-3_F_crop_1.jpg: 256x640 2 texts, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/371_trung-ga-omega-3_F_crop_2.jpg: 128x640 1 text, 8.9ms\n",
      "Speed: 0.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/371_trung-ga-omega-3_F_crop_3.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/372_ca-mo-lam-sach_F_crop_0.jpg: 160x640 4 texts, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/372_ca-mo-lam-sach_F_crop_1.jpg: 128x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/372_ca-mo-lam-sach_F_crop_2.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/372_ca-mo-lam-sach_F_crop_3.jpg: 320x640 2 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/373_dau-hu-ta_F_crop_0.jpg: 288x640 1 text, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/373_dau-hu-ta_F_crop_1.jpg: 256x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/373_dau-hu-ta_F_crop_2.jpg: 416x640 5 texts, 8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/373_dau-hu-ta_F_crop_3.jpg: 352x640 2 texts, 9.3ms\n",
      "Speed: 1.3ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/374_tori-canh-toi_F_crop_0.jpg: 192x640 2 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/374_tori-canh-toi_F_crop_1.jpg: 352x640 1 text, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Processed: 1150/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/374_tori-canh-toi_F_crop_2.jpg: 256x640 1 text, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/374_tori-canh-toi_F_crop_3.jpg: 256x640 1 text, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/374_tori-canh-toi_F_crop_4.jpg: 224x640 1 text, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/375_dalat-milk_F_crop_0.jpg: 256x640 3 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/375_dalat-milk_F_crop_1.jpg: 288x640 3 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/375_dalat-milk_F_crop_2.jpg: 128x640 4 texts, 9.1ms\n",
      "Speed: 0.6ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/375_dalat-milk_F_crop_3.jpg: 256x640 2 texts, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/376_dalat-milk_F_crop_0.jpg: 256x640 3 texts, 8.2ms\n",
      "Speed: 1.0ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/376_dalat-milk_F_crop_1.jpg: 288x640 3 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/376_dalat-milk_F_crop_2.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/377_thit-co-bo-my-va-ba-roi-ba-my_F_crop_0.jpg: 192x640 10 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/377_thit-co-bo-my-va-ba-roi-ba-my_F_crop_1.jpg: 128x640 1 text, 9.4ms\n",
      "Speed: 0.7ms preprocess, 9.4ms inference, 3.5ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/377_thit-co-bo-my-va-ba-roi-ba-my_F_crop_2.jpg: 96x640 1 text, 10.2ms\n",
      "Speed: 0.6ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/377_thit-co-bo-my-va-ba-roi-ba-my_F_crop_3.jpg: 96x640 1 text, 9.7ms\n",
      "Speed: 0.6ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/377_thit-co-bo-my-va-ba-roi-ba-my_F_crop_4.jpg: 384x640 2 texts, 9.3ms\n",
      "Speed: 1.9ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/378_ha-cao-tom_F_crop_0.jpg: 128x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/378_ha-cao-tom_F_crop_1.jpg: 128x640 1 text, 8.2ms\n",
      "Speed: 0.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/378_ha-cao-tom_F_crop_2.jpg: 160x640 3 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/379_nac-heo-xay_L_crop_0.jpg: 192x640 4 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/379_nac-heo-xay_L_crop_1.jpg: 320x640 2 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/379_nac-heo-xay_L_crop_2.jpg: 288x640 1 text, 10.3ms\n",
      "Speed: 1.0ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/379_nac-heo-xay_L_crop_3.jpg: 256x640 1 text, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/379_nac-heo-xay_L_crop_4.jpg: 512x640 1 text, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/380_nac-heo-xay_R_crop_0.jpg: 192x640 4 texts, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/380_nac-heo-xay_R_crop_1.jpg: 288x640 1 text, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/380_nac-heo-xay_R_crop_2.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/380_nac-heo-xay_R_crop_3.jpg: 352x640 2 texts, 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/381_ba-roi-heo_F_crop_0.jpg: 256x640 4 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/381_ba-roi-heo_F_crop_1.jpg: 288x640 2 texts, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/381_ba-roi-heo_F_crop_2.jpg: 288x640 1 text, 11.2ms\n",
      "Speed: 1.1ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/381_ba-roi-heo_F_crop_3.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/381_ba-roi-heo_F_crop_4.jpg: 480x640 1 text, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/382_hit-hop_D_crop_0.jpg: 128x640 6 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/382_hit-hop_D_crop_1.jpg: 224x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/382_hit-hop_D_crop_2.jpg: 224x640 1 text, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/382_hit-hop_D_crop_3.jpg: 416x640 2 texts, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/383_so-than-bo_F_crop_0.jpg: 128x640 2 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/383_so-than-bo_F_crop_1.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/383_so-than-bo_F_crop_2.jpg: 192x640 1 text, 9.6ms\n",
      "Speed: 0.8ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/383_so-than-bo_F_crop_3.jpg: 256x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/384_so-vun-ca-hoi-nauy_F_crop_0.jpg: 96x640 4 texts, 9.8ms\n",
      "Speed: 0.6ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/384_so-vun-ca-hoi-nauy_F_crop_1.jpg: 128x640 1 text, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/384_so-vun-ca-hoi-nauy_F_crop_2.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/384_so-vun-ca-hoi-nauy_F_crop_3.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/385_sot-uop-thit-han-quoc_F_crop_0.jpg: 256x640 1 text, 9.6ms\n",
      "Speed: 1.2ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/385_sot-uop-thit-han-quoc_F_crop_1.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/385_sot-uop-thit-han-quoc_F_crop_2.jpg: 352x640 8 texts, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/386_pho-mai-xong-khoi_F_crop_0.jpg: 224x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/386_pho-mai-xong-khoi_F_crop_1.jpg: 320x640 8 texts, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/386_pho-mai-xong-khoi_F_crop_2.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Processed: 1200/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/386_pho-mai-xong-khoi_F_crop_3.jpg: 224x640 1 text, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/387_sua-dau-nanh_F_crop_0.jpg: 192x640 3 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/387_sua-dau-nanh_F_crop_1.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/387_sua-dau-nanh_F_crop_2.jpg: 256x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/387_sua-dau-nanh_F_crop_3.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/388_muc-mot-nang-sot-nuoc-mam_F_crop_0.jpg: 96x640 6 texts, 11.2ms\n",
      "Speed: 0.6ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/388_muc-mot-nang-sot-nuoc-mam_F_crop_1.jpg: 160x640 1 text, 10.1ms\n",
      "Speed: 0.8ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/388_muc-mot-nang-sot-nuoc-mam_F_crop_2.jpg: 192x640 1 text, 10.0ms\n",
      "Speed: 1.3ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/388_muc-mot-nang-sot-nuoc-mam_F_crop_3.jpg: 288x640 1 text, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/389_ma-dui-ga_F_crop_0.jpg: 224x640 3 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/389_ma-dui-ga_F_crop_1.jpg: 480x640 2 texts, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/389_ma-dui-ga_F_crop_2.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/389_ma-dui-ga_F_crop_3.jpg: 160x640 1 text, 8.2ms\n",
      "Speed: 0.7ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/390_dui-toi-tuoi_F_crop_0.jpg: 160x640 3 texts, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/390_dui-toi-tuoi_F_crop_1.jpg: 352x640 2 texts, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/390_dui-toi-tuoi_F_crop_2.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/390_dui-toi-tuoi_F_crop_3.jpg: 160x640 1 text, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/390_dui-toi-tuoi_F_crop_4.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/390_dui-toi-tuoi_F_crop_5.jpg: 416x640 1 text, 8.4ms\n",
      "Speed: 1.3ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/391_phi-le-ga-khong-da_F_crop_0.jpg: 224x640 7 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/391_phi-le-ga-khong-da_F_crop_1.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/391_phi-le-ga-khong-da_F_crop_2.jpg: 128x640 3 texts, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/391_phi-le-ga-khong-da_F_crop_3.jpg: 128x640 3 texts, 8.3ms\n",
      "Speed: 0.7ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/392_phi-le-ga-khong-da_F_crop_0.jpg: 128x640 5 texts, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/392_phi-le-ga-khong-da_F_crop_1.jpg: 512x640 2 texts, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/392_phi-le-ga-khong-da_F_crop_2.jpg: 192x640 1 text, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/392_phi-le-ga-khong-da_F_crop_3.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/393_gio-song_F_crop_0.jpg: 192x640 7 texts, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/393_gio-song_F_crop_1.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/393_gio-song_F_crop_2.jpg: 192x640 1 text, 8.3ms\n",
      "Speed: 0.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/394_phi-le-ga-khong-da_F_crop_0.jpg: 224x640 7 texts, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/394_phi-le-ga-khong-da_F_crop_1.jpg: 128x640 3 texts, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/394_phi-le-ga-khong-da_F_crop_2.jpg: 128x640 3 texts, 8.4ms\n",
      "Speed: 0.7ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/394_phi-le-ga-khong-da_F_crop_3.jpg: 288x640 2 texts, 16.8ms\n",
      "Speed: 1.1ms preprocess, 16.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/395_hat-dua_F_crop_0.jpg: 224x640 2 texts, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/395_hat-dua_F_crop_1.jpg: 384x640 1 text, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/395_hat-dua_F_crop_2.jpg: 160x640 1 text, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/395_hat-dua_F_crop_3.jpg: 224x640 1 text, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/395_hat-dua_F_crop_4.jpg: 352x640 2 texts, 9.1ms\n",
      "Speed: 1.3ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/395_hat-dua_F_crop_5.jpg: 160x640 5 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/396_la-mo-tuoi_F_crop_0.jpg: 128x640 2 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/396_la-mo-tuoi_F_crop_1.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/396_la-mo-tuoi_F_crop_2.jpg: 352x640 2 texts, 9.1ms\n",
      "Speed: 1.3ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/397_xa-lach_F_crop_0.jpg: 160x640 3 texts, 9.8ms\n",
      "Speed: 0.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/397_xa-lach_F_crop_1.jpg: 160x640 1 text, 10.0ms\n",
      "Speed: 0.8ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/398_dua-leo_F_crop_0.jpg: 192x640 2 texts, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/398_dua-leo_F_crop_1.jpg: 224x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/398_dua-leo_F_crop_2.jpg: 224x640 1 text, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/399_tuong-ot_F_crop_0.jpg: 160x640 2 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/399_tuong-ot_F_crop_1.jpg: 192x640 1 text, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "Processed: 1250/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/399_tuong-ot_F_crop_2.jpg: 160x640 1 text, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/399_tuong-ot_F_crop_3.jpg: 416x640 2 texts, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/400_bot-ngu-vi-huong_B_crop_0.jpg: 96x640 4 texts, 10.1ms\n",
      "Speed: 0.6ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/400_bot-ngu-vi-huong_B_crop_1.jpg: 640x160 3 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/400_bot-ngu-vi-huong_B_crop_2.jpg: 640x160 5 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/400_bot-ngu-vi-huong_B_crop_3.jpg: 512x640 2 texts, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/401_bot-ngu-vi-huong_B_crop_0.jpg: 128x640 1 text, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/401_bot-ngu-vi-huong_B_crop_1.jpg: 128x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/402_uc-fillet-tuoi_F_crop_0.jpg: 160x640 3 texts, 9.5ms\n",
      "Speed: 0.6ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/402_uc-fillet-tuoi_F_crop_1.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/402_uc-fillet-tuoi_F_crop_2.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/402_uc-fillet-tuoi_F_crop_3.jpg: 160x640 1 text, 9.4ms\n",
      "Speed: 0.7ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/402_uc-fillet-tuoi_F_crop_4.jpg: 288x640 2 texts, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/403_ma-dui-ga-cat-san_F_crop_0.jpg: 192x640 5 texts, 9.3ms\n",
      "Speed: 0.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/403_ma-dui-ga-cat-san_F_crop_1.jpg: 288x640 1 text, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/403_ma-dui-ga-cat-san_F_crop_2.jpg: 288x640 1 text, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/403_ma-dui-ga-cat-san_F_crop_3.jpg: 288x640 2 texts, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/404_thit-xay_F_crop_0.jpg: 224x640 3 texts, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/404_thit-xay_F_crop_1.jpg: 224x640 1 text, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/404_thit-xay_F_crop_2.jpg: 256x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/404_thit-xay_F_crop_3.jpg: 256x640 2 texts, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/405_nac-dam-heo_F_crop_0.jpg: 256x640 4 texts, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/405_nac-dam-heo_F_crop_1.jpg: 320x640 1 text, 9.7ms\n",
      "Speed: 1.2ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/405_nac-dam-heo_F_crop_2.jpg: 320x640 1 text, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/405_nac-dam-heo_F_crop_3.jpg: 448x640 2 texts, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/406_dui-goc-tu_F_crop_0.jpg: 128x640 4 texts, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/406_dui-goc-tu_F_crop_1.jpg: 352x640 2 texts, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/406_dui-goc-tu_F_crop_2.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/406_dui-goc-tu_F_crop_3.jpg: 160x640 1 text, 9.9ms\n",
      "Speed: 0.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/406_dui-goc-tu_F_crop_4.jpg: 352x640 2 texts, 9.2ms\n",
      "Speed: 1.3ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/407_banh-gau-sua_F_crop_0.jpg: 384x640 3 texts, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/407_banh-gau-sua_F_crop_1.jpg: 480x640 2 texts, 9.3ms\n",
      "Speed: 1.5ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/407_banh-gau-sua_F_crop_2.jpg: 256x640 3 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/407_banh-gau-sua_F_crop_3.jpg: 224x640 3 texts, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/407_banh-gau-sua_F_crop_4.jpg: 224x640 3 texts, 8.4ms\n",
      "Speed: 0.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/408_bot-toi_F_crop_0.jpg: 224x640 2 texts, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/408_bot-toi_F_crop_1.jpg: 160x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/408_bot-toi_F_crop_2.jpg: 128x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/409_chao_F_crop_0.jpg: 192x640 2 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/409_chao_F_crop_1.jpg: 96x640 1 text, 9.8ms\n",
      "Speed: 0.6ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/409_chao_F_crop_2.jpg: 128x640 1 text, 8.9ms\n",
      "Speed: 0.6ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/409_chao_F_crop_3.jpg: 512x640 2 texts, 8.8ms\n",
      "Speed: 1.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/410_com-chay-hat-sen_F_crop_0.jpg: 320x640 4 texts, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/410_com-chay-hat-sen_F_crop_1.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 4.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/411_tom-kho_B_crop_0.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/411_tom-kho_B_crop_1.jpg: 96x640 7 texts, 9.9ms\n",
      "Speed: 0.5ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/411_tom-kho_B_crop_2.jpg: 416x640 2 texts, 8.7ms\n",
      "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/412_hat-oc-cho_F_crop_0.jpg: 224x640 3 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/412_hat-oc-cho_F_crop_1.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/412_hat-oc-cho_F_crop_2.jpg: 192x640 2 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "Processed: 1300/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/413_xoai-say-deo_F_crop_0.jpg: 352x640 3 texts, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/413_xoai-say-deo_F_crop_1.jpg: 192x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/413_xoai-say-deo_F_crop_2.jpg: 192x640 1 text, 8.3ms\n",
      "Speed: 0.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/414_fillet-ca-hoi-con-da_F_crop_0.jpg: 128x640 5 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/414_fillet-ca-hoi-con-da_F_crop_1.jpg: 192x640 1 text, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/414_fillet-ca-hoi-con-da_F_crop_2.jpg: 224x640 1 text, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/414_fillet-ca-hoi-con-da_F_crop_3.jpg: 416x640 1 text, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/415_tom-su-tuoi_F_crop_0.jpg: 160x640 3 texts, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/415_tom-su-tuoi_F_crop_1.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/415_tom-su-tuoi_F_crop_2.jpg: 192x640 1 text, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/415_tom-su-tuoi_F_crop_3.jpg: 448x640 1 text, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/416_canh-ga_F_crop_0.jpg: 384x640 4 texts, 9.6ms\n",
      "Speed: 1.9ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/416_canh-ga_F_crop_1.jpg: 96x640 3 texts, 10.3ms\n",
      "Speed: 0.7ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/416_canh-ga_F_crop_2.jpg: 96x640 3 texts, 9.5ms\n",
      "Speed: 0.6ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/417_thit-heo_F_crop_0.jpg: 192x640 2 texts, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/417_thit-heo_F_crop_1.jpg: 256x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/417_thit-heo_F_crop_2.jpg: 224x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/418_phi-le-uc_F_crop_0.jpg: 256x640 1 text, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/418_phi-le-uc_F_crop_1.jpg: 224x640 3 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/418_phi-le-uc_F_crop_2.jpg: 288x640 1 text, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/418_phi-le-uc_F_crop_3.jpg: 288x640 1 text, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/418_phi-le-uc_F_crop_4.jpg: 288x640 1 text, 9.7ms\n",
      "Speed: 1.2ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/419_nac-dam-heo_F_crop_0.jpg: 160x640 3 texts, 9.5ms\n",
      "Speed: 0.7ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/419_nac-dam-heo_F_crop_1.jpg: 288x640 2 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/419_nac-dam-heo_F_crop_2.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/419_nac-dam-heo_F_crop_3.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/420_hat-hanh-nhan-va-bap-nuong_F_crop_0.jpg: 96x640 6 texts, 10.0ms\n",
      "Speed: 0.6ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/420_hat-hanh-nhan-va-bap-nuong_F_crop_1.jpg: 576x640 2 texts, 8.5ms\n",
      "Speed: 1.8ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/420_hat-hanh-nhan-va-bap-nuong_F_crop_2.jpg: 192x640 3 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/420_hat-hanh-nhan-va-bap-nuong_F_crop_3.jpg: 96x640 4 texts, 9.8ms\n",
      "Speed: 0.5ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/421_bo-ngot-baby_F_crop_0.jpg: 256x640 3 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/421_bo-ngot-baby_F_crop_1.jpg: 352x640 2 texts, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/421_bo-ngot-baby_F_crop_2.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/421_bo-ngot-baby_F_crop_3.jpg: 192x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/422_cai-ngot-baby_F_crop_0.jpg: 160x640 3 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/422_cai-ngot-baby_F_crop_1.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/422_cai-ngot-baby_F_crop_2.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/422_cai-ngot-baby_F_crop_3.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/423_ngon-kho-qua-rung_F_crop_0.jpg: 160x640 4 texts, 8.4ms\n",
      "Speed: 0.7ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/423_ngon-kho-qua-rung_F_crop_1.jpg: 288x640 2 texts, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/423_ngon-kho-qua-rung_F_crop_2.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/424_dui-ga-thao-khop_F_crop_0.jpg: 96x640 4 texts, 10.2ms\n",
      "Speed: 0.6ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/424_dui-ga-thao-khop_F_crop_1.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/424_dui-ga-thao-khop_F_crop_2.jpg: 128x640 1 text, 9.3ms\n",
      "Speed: 0.6ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/424_dui-ga-thao-khop_F_crop_3.jpg: 288x640 2 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/425_ma-dui-ga-khong-xuong_F_crop_0.jpg: 128x640 5 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/425_ma-dui-ga-khong-xuong_F_crop_1.jpg: 384x640 2 texts, 9.2ms\n",
      "Speed: 1.4ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/425_ma-dui-ga-khong-xuong_F_crop_2.jpg: 128x640 1 text, 9.3ms\n",
      "Speed: 0.6ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/425_ma-dui-ga-khong-xuong_F_crop_3.jpg: 160x640 1 text, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/426_cai-bo-xoi_F_crop_0.jpg: 256x640 3 texts, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Processed: 1350/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/426_cai-bo-xoi_F_crop_1.jpg: 352x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/426_cai-bo-xoi_F_crop_2.jpg: 352x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/426_cai-bo-xoi_F_crop_3.jpg: 224x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/426_cai-bo-xoi_F_crop_4.jpg: 160x640 7 texts, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/427_hung-lui_F_crop_0.jpg: 192x640 2 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/427_hung-lui_F_crop_1.jpg: 256x640 1 text, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/427_hung-lui_F_crop_2.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/427_hung-lui_F_crop_3.jpg: 96x640 7 texts, 10.5ms\n",
      "Speed: 0.6ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/427_hung-lui_F_crop_4.jpg: 352x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/428_hanh-la_F_crop_0.jpg: 192x640 2 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/428_hanh-la_F_crop_1.jpg: 384x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/428_hanh-la_F_crop_2.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/428_hanh-la_F_crop_3.jpg: 160x640 7 texts, 9.5ms\n",
      "Speed: 0.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/429_ca-chi-vang-chay-toi_F_crop_0.jpg: 192x640 5 texts, 9.4ms\n",
      "Speed: 1.0ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/429_ca-chi-vang-chay-toi_F_crop_1.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/429_ca-chi-vang-chay-toi_F_crop_2.jpg: 192x640 1 text, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/430_nho-vang_F_crop_0.jpg: 224x640 2 texts, 9.4ms\n",
      "Speed: 1.0ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/430_nho-vang_F_crop_1.jpg: 480x640 1 text, 8.4ms\n",
      "Speed: 1.7ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/430_nho-vang_F_crop_2.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/430_nho-vang_F_crop_3.jpg: 192x640 1 text, 8.4ms\n",
      "Speed: 0.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/430_nho-vang_F_crop_4.jpg: 160x640 1 text, 9.5ms\n",
      "Speed: 0.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/430_nho-vang_F_crop_5.jpg: 288x640 2 texts, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/431_hat-bi-nguyen-vo_F_crop_0.jpg: 448x640 1 text, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/431_hat-bi-nguyen-vo_F_crop_1.jpg: 320x640 7 texts, 9.4ms\n",
      "Speed: 1.3ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/431_hat-bi-nguyen-vo_F_crop_2.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/431_hat-bi-nguyen-vo_F_crop_3.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/431_hat-bi-nguyen-vo_F_crop_4.jpg: 320x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/432_trail-mix-vi-so-co-la_F_crop_0.jpg: 416x640 1 text, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/432_trail-mix-vi-so-co-la_F_crop_1.jpg: 384x640 4 texts, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/432_trail-mix-vi-so-co-la_F_crop_2.jpg: 288x640 1 text, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/432_trail-mix-vi-so-co-la_F_crop_3.jpg: 256x640 1 text, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/432_trail-mix-vi-so-co-la_F_crop_4.jpg: 416x640 2 texts, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/433_mat-ong-hoa-vai-thieu_F_crop_0.jpg: 288x640 5 texts, 10.1ms\n",
      "Speed: 1.3ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/433_mat-ong-hoa-vai-thieu_F_crop_1.jpg: 256x640 1 text, 10.8ms\n",
      "Speed: 1.0ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/433_mat-ong-hoa-vai-thieu_F_crop_2.jpg: 160x640 1 text, 9.7ms\n",
      "Speed: 0.8ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/433_mat-ong-hoa-vai-thieu_F_crop_3.jpg: 128x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/434_trai-cay-say-thap-cam_F_crop_0.jpg: 288x640 5 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/434_trai-cay-say-thap-cam_F_crop_1.jpg: 224x640 1 text, 9.3ms\n",
      "Speed: 0.9ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/434_trai-cay-say-thap-cam_F_crop_2.jpg: 192x640 1 text, 9.5ms\n",
      "Speed: 0.9ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/434_trai-cay-say-thap-cam_F_crop_3.jpg: 288x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/435_keo-huong-dau-tay_D_crop_0.jpg: 384x640 2 texts, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/435_keo-huong-dau-tay_D_crop_1.jpg: 128x640 5 texts, 9.4ms\n",
      "Speed: 0.6ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/435_keo-huong-dau-tay_D_crop_2.jpg: 192x640 1 text, 9.7ms\n",
      "Speed: 1.0ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/435_keo-huong-dau-tay_D_crop_3.jpg: 160x640 1 text, 14.0ms\n",
      "Speed: 0.9ms preprocess, 14.0ms inference, 2.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/435_keo-huong-dau-tay_D_crop_4.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/436_man-say-deo_F_crop_0.jpg: 288x640 7 texts, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/436_man-say-deo_F_crop_1.jpg: 160x640 3 texts, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/436_man-say-deo_F_crop_2.jpg: 128x640 3 texts, 9.6ms\n",
      "Speed: 0.6ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/437_thom-say-deo_F_crop_0.jpg: 320x640 7 texts, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/437_thom-say-deo_F_crop_1.jpg: 192x640 3 texts, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "Processed: 1400/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/437_thom-say-deo_F_crop_2.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/438_thanh-long-say-deo_F_crop_0.jpg: 288x640 9 texts, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/438_thanh-long-say-deo_F_crop_1.jpg: 160x640 3 texts, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/438_thanh-long-say-deo_F_crop_2.jpg: 160x640 3 texts, 9.7ms\n",
      "Speed: 0.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/439_ca-phe-den-da_F_crop_0.jpg: 640x128 3 texts, 8.7ms\n",
      "Speed: 0.6ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/439_ca-phe-den-da_F_crop_1.jpg: 640x128 3 texts, 8.5ms\n",
      "Speed: 0.6ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/439_ca-phe-den-da_F_crop_2.jpg: 416x640 4 texts, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/440_tuogn-cham-thit-nuong_F_crop_0.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/440_tuogn-cham-thit-nuong_F_crop_1.jpg: 128x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/440_tuogn-cham-thit-nuong_F_crop_2.jpg: 96x640 4 texts, 10.5ms\n",
      "Speed: 0.5ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/440_tuogn-cham-thit-nuong_F_crop_3.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/441_bot-khuc-bach_F_crop_0.jpg: 160x640 1 text, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/441_bot-khuc-bach_F_crop_1.jpg: 320x640 3 texts, 9.3ms\n",
      "Speed: 1.4ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/441_bot-khuc-bach_F_crop_2.jpg: 128x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/441_bot-khuc-bach_F_crop_3.jpg: 96x640 1 text, 10.0ms\n",
      "Speed: 0.5ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/442_bun-tuoi-kho_F_crop_0.jpg: 256x640 2 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/442_bun-tuoi-kho_F_crop_1.jpg: 224x640 3 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/442_bun-tuoi-kho_F_crop_2.jpg: 256x640 2 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/443_nescafe_F_crop_0.jpg: 192x640 1 text, 9.5ms\n",
      "Speed: 0.9ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/444_nescafe-nuoc-cot-ca-phe_F_crop_0.jpg: 192x640 1 text, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/444_nescafe-nuoc-cot-ca-phe_F_crop_1.jpg: 448x640 4 texts, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/445_banh-bong-la-huong-com-dua_F_crop_0.jpg: 192x640 3 texts, 9.3ms\n",
      "Speed: 0.9ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/445_banh-bong-la-huong-com-dua_F_crop_1.jpg: 320x640 2 texts, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/445_banh-bong-la-huong-com-dua_F_crop_2.jpg: 64x640 7 texts, 11.7ms\n",
      "Speed: 0.5ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 64, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/446_sua-dinh-duong-vinamilk_F_crop_0.jpg: 160x640 1 text, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/446_sua-dinh-duong-vinamilk_F_crop_1.jpg: 352x640 3 texts, 10.1ms\n",
      "Speed: 1.5ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/446_sua-dinh-duong-vinamilk_F_crop_2.jpg: 224x640 3 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/447_banh-trang_F_crop_0.jpg: 224x640 2 texts, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/447_banh-trang_F_crop_1.jpg: 128x640 2 texts, 9.5ms\n",
      "Speed: 0.7ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/447_banh-trang_F_crop_2.jpg: 352x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/448_lap-xuong_F_crop_0.jpg: 192x640 1 text, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/448_lap-xuong_F_crop_1.jpg: 352x640 2 texts, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/449_tra-sua-matcha_F_crop_0.jpg: 320x640 1 text, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/449_tra-sua-matcha_F_crop_1.jpg: 352x640 3 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/449_tra-sua-matcha_F_crop_2.jpg: 384x640 2 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/450_lipton_F_crop_0.jpg: 256x640 1 text, 9.3ms\n",
      "Speed: 0.9ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/450_lipton_F_crop_1.jpg: 192x640 3 texts, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/450_lipton_F_crop_2.jpg: 320x640 2 texts, 9.9ms\n",
      "Speed: 1.1ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/451_ca-phe-sua-vinacafe_F_crop_0.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/451_ca-phe-sua-vinacafe_F_crop_1.jpg: 128x640 6 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/451_ca-phe-sua-vinacafe_F_crop_2.jpg: 320x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/452_banh-trang-goi-cuon_F_crop_0.jpg: 224x640 4 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/452_banh-trang-goi-cuon_F_crop_1.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/453_banh-trang-dua-nuong_F_crop_0.jpg: 128x640 3 texts, 9.1ms\n",
      "Speed: 0.5ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/453_banh-trang-dua-nuong_F_crop_1.jpg: 128x640 4 texts, 8.2ms\n",
      "Speed: 0.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/453_banh-trang-dua-nuong_F_crop_2.jpg: 160x640 2 texts, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/453_banh-trang-dua-nuong_F_crop_3.jpg: 480x640 2 texts, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/454_ca-phe-sua-da-ong-bau_F_crop_0.jpg: 288x640 8 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/454_ca-phe-sua-da-ong-bau_F_crop_1.jpg: 448x640 6 texts, 8.7ms\n",
      "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/455_ca-phe-sua-da-ong-bau_L_crop_0.jpg: 224x640 1 text, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Processed: 1450/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/455_ca-phe-sua-da-ong-bau_L_crop_1.jpg: 224x640 1 text, 8.2ms\n",
      "Speed: 0.9ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/456_tra-vi-vai-va-huong-hoa-lai_F_crop_0.jpg: 96x640 7 texts, 9.9ms\n",
      "Speed: 0.5ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/456_tra-vi-vai-va-huong-hoa-lai_F_crop_1.jpg: 288x640 1 text, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/456_tra-vi-vai-va-huong-hoa-lai_F_crop_2.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/457_bot-ngot_F_crop_0.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/457_bot-ngot_F_crop_1.jpg: 288x640 2 texts, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/457_bot-ngot_F_crop_2.jpg: 352x640 2 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/458_mentos_F_crop_0.jpg: 640x192 2 texts, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/458_mentos_F_crop_1.jpg: 640x384 2 texts, 8.4ms\n",
      "Speed: 1.1ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/459_snack-va-dau-thap-cam_F_crop_0.jpg: 256x640 3 texts, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/459_snack-va-dau-thap-cam_F_crop_1.jpg: 256x640 5 texts, 8.0ms\n",
      "Speed: 0.8ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/460_pocky_F_crop_0.jpg: 352x640 1 text, 9.3ms\n",
      "Speed: 1.5ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/460_pocky_F_crop_1.jpg: 96x640 7 texts, 10.4ms\n",
      "Speed: 0.6ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/460_pocky_F_crop_2.jpg: 384x640 2 texts, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/461_lap-xuong_B_crop_0.jpg: 160x640 1 text, 10.6ms\n",
      "Speed: 0.7ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/461_lap-xuong_B_crop_1.jpg: 160x640 1 text, 9.7ms\n",
      "Speed: 0.7ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/461_lap-xuong_B_crop_2.jpg: 320x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/462_tra-sua-matcha_L_crop_0.jpg: 160x640 1 text, 9.7ms\n",
      "Speed: 0.7ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/462_tra-sua-matcha_L_crop_1.jpg: 128x640 1 text, 8.7ms\n",
      "Speed: 0.6ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/463_tra-sua-tran-chau_F_crop_0.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/463_tra-sua-tran-chau_F_crop_1.jpg: 384x640 4 texts, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/463_tra-sua-tran-chau_F_crop_2.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/464_nuoc-yen-cho-tre-em_F_crop_0.jpg: 416x640 2 texts, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/464_nuoc-yen-cho-tre-em_F_crop_1.jpg: 320x640 4 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/464_nuoc-yen-cho-tre-em_F_crop_2.jpg: 288x640 5 texts, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/465_nuoc-ep-cam_F_crop_0.jpg: 192x640 1 text, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/465_nuoc-ep-cam_F_crop_1.jpg: 160x640 2 texts, 8.7ms\n",
      "Speed: 0.6ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/465_nuoc-ep-cam_F_crop_2.jpg: 576x640 3 texts, 9.4ms\n",
      "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/466_banh-trang-cuon-me-den_F_crop_0.jpg: 160x640 5 texts, 9.5ms\n",
      "Speed: 0.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/466_banh-trang-cuon-me-den_F_crop_1.jpg: 128x640 2 texts, 9.5ms\n",
      "Speed: 0.7ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/466_banh-trang-cuon-me-den_F_crop_2.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/467_lap-xuong_F_crop_0.jpg: 160x640 2 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/468_ca-phe-sua-da-ong-bau_D_crop_0.jpg: 192x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/468_ca-phe-sua-da-ong-bau_D_crop_1.jpg: 128x640 1 text, 9.2ms\n",
      "Speed: 0.6ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/469_lipton_F_crop_0.jpg: 256x640 1 text, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/469_lipton_F_crop_1.jpg: 224x640 3 texts, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/469_lipton_F_crop_2.jpg: 352x640 3 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/470_nuoc-yen-cho-tre-em_B_crop_0.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/470_nuoc-yen-cho-tre-em_B_crop_1.jpg: 160x640 1 text, 8.4ms\n",
      "Speed: 0.6ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/471_dau-phong-da-ca-cot-dua_F_crop_0.jpg: 544x640 2 texts, 8.7ms\n",
      "Speed: 1.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/471_dau-phong-da-ca-cot-dua_F_crop_1.jpg: 288x640 6 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/471_dau-phong-da-ca-cot-dua_F_crop_2.jpg: 384x640 2 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/472_bun-tuoi-kho_F_crop_0.jpg: 288x640 2 texts, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/472_bun-tuoi-kho_F_crop_1.jpg: 224x640 3 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/472_bun-tuoi-kho_F_crop_2.jpg: 224x640 2 texts, 7.8ms\n",
      "Speed: 0.7ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/473_banh-afc_F_crop_0.jpg: 224x640 2 texts, 8.4ms\n",
      "Speed: 0.7ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/473_banh-afc_F_crop_1.jpg: 416x640 1 text, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/473_banh-afc_F_crop_2.jpg: 416x640 4 texts, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/473_banh-afc_F_crop_3.jpg: 256x640 1 text, 9.7ms\n",
      "Speed: 0.9ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/473_banh-afc_F_crop_4.jpg: 384x640 2 texts, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed: 1500/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/474_tra-sua-tran-chau_L_crop_0.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/474_tra-sua-tran-chau_L_crop_1.jpg: 224x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/474_tra-sua-tran-chau_L_crop_2.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/475_tra-dao-huong-cam-sa_F_crop_0.jpg: 192x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/475_tra-dao-huong-cam-sa_F_crop_1.jpg: 448x640 5 texts, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/475_tra-dao-huong-cam-sa_F_crop_2.jpg: 256x640 1 text, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/475_tra-dao-huong-cam-sa_F_crop_3.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/476_tra-vi-chanh_F_crop_0.jpg: 192x640 3 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/476_tra-vi-chanh_F_crop_1.jpg: 288x640 1 text, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/476_tra-vi-chanh_F_crop_2.jpg: 352x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/477_mien_F_crop_0.jpg: 256x640 1 text, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/477_mien_F_crop_1.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/478_tra-dao_F_crop_0.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/478_tra-dao_F_crop_1.jpg: 192x640 3 texts, 8.2ms\n",
      "Speed: 0.8ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/478_tra-dao_F_crop_2.jpg: 608x640 3 texts, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/479_banh-chocopie-vi-cacao_F_crop_0.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/479_banh-chocopie-vi-cacao_F_crop_1.jpg: 96x640 4 texts, 10.4ms\n",
      "Speed: 0.5ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/479_banh-chocopie-vi-cacao_F_crop_2.jpg: 320x640 2 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/480_rong-bien-cuon-com_F_crop_0.jpg: 128x640 1 text, 9.1ms\n",
      "Speed: 0.6ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/480_rong-bien-cuon-com_F_crop_1.jpg: 128x640 4 texts, 9.7ms\n",
      "Speed: 0.7ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/480_rong-bien-cuon-com_F_crop_2.jpg: 640x160 (no detections), 8.9ms\n",
      "Speed: 0.6ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/480_rong-bien-cuon-com_F_crop_3.jpg: 640x128 (no detections), 8.5ms\n",
      "Speed: 0.6ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/480_rong-bien-cuon-com_F_crop_4.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/481_tra-vai-huong-hoa-hong_F_crop_0.jpg: 192x640 1 text, 8.0ms\n",
      "Speed: 0.7ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/481_tra-vai-huong-hoa-hong_F_crop_1.jpg: 256x640 1 text, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/481_tra-vai-huong-hoa-hong_F_crop_2.jpg: 480x640 5 texts, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/481_tra-vai-huong-hoa-hong_F_crop_3.jpg: 384x640 2 texts, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/482_ca-phe-hoa-tan_F_crop_0.jpg: 64x640 6 texts, 9.9ms\n",
      "Speed: 0.5ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 64, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/482_ca-phe-hoa-tan_F_crop_1.jpg: 448x640 2 texts, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/482_ca-phe-hoa-tan_F_crop_2.jpg: 128x640 5 texts, 9.3ms\n",
      "Speed: 0.6ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/482_ca-phe-hoa-tan_F_crop_3.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/483_banh-trang-dua-nuong_F_crop_0.jpg: 128x640 2 texts, 8.8ms\n",
      "Speed: 0.5ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/483_banh-trang-dua-nuong_F_crop_1.jpg: 96x640 4 texts, 11.0ms\n",
      "Speed: 0.6ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/483_banh-trang-dua-nuong_F_crop_2.jpg: 96x640 2 texts, 9.6ms\n",
      "Speed: 0.6ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/484_bun-tuoikho_B_crop_0.jpg: 128x640 1 text, 9.6ms\n",
      "Speed: 0.6ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/484_bun-tuoikho_B_crop_1.jpg: 128x640 1 text, 8.3ms\n",
      "Speed: 0.6ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/484_bun-tuoikho_B_crop_2.jpg: 320x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/485_ca-phe-sua-da-ong-bau_R_crop_0.jpg: 288x640 6 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/485_ca-phe-sua-da-ong-bau_R_crop_1.jpg: 416x640 6 texts, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/485_ca-phe-sua-da-ong-bau_R_crop_2.jpg: 320x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/486_vinamilk-sua-dinh-duong-co-duong_F_crop_0.jpg: 192x640 1 text, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/486_vinamilk-sua-dinh-duong-co-duong_F_crop_1.jpg: 128x640 7 texts, 8.9ms\n",
      "Speed: 0.5ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/486_vinamilk-sua-dinh-duong-co-duong_F_crop_2.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/487_banh-chocopie-vi-cacao_T_crop_0.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/487_banh-chocopie-vi-cacao_T_crop_1.jpg: 128x640 5 texts, 8.9ms\n",
      "Speed: 0.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/487_banh-chocopie-vi-cacao_T_crop_2.jpg: 224x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/487_banh-chocopie-vi-cacao_T_crop_3.jpg: 96x640 7 texts, 9.8ms\n",
      "Speed: 0.5ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/488_tra-sua-truyen-thong_F_crop_0.jpg: 256x640 4 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/488_tra-sua-truyen-thong_F_crop_1.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/489_granola_F_crop_0.jpg: 640x512 4 texts, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: 1550/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/489_granola_F_crop_1.jpg: 640x512 1 text, 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/490_bot-can-tay_F_crop_0.jpg: 352x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/490_bot-can-tay_F_crop_1.jpg: 224x640 3 texts, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/490_bot-can-tay_F_crop_2.jpg: 224x640 1 text, 8.4ms\n",
      "Speed: 0.8ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/491_xoai-say-deo_F_crop_0.jpg: 384x640 2 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/491_xoai-say-deo_F_crop_1.jpg: 224x640 3 texts, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/491_xoai-say-deo_F_crop_2.jpg: 384x640 2 texts, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/491_xoai-say-deo_F_crop_3.jpg: 320x640 1 text, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/491_xoai-say-deo_F_crop_4.jpg: 320x640 1 text, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/492_th-true-milk_F_crop_0.jpg: 640x640 3 texts, 8.9ms\n",
      "Speed: 2.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/492_th-true-milk_F_crop_1.jpg: 192x640 6 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/492_th-true-milk_F_crop_2.jpg: 224x640 3 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/493_khoai-lang-vang-say-gion_F_crop_0.jpg: 224x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/493_khoai-lang-vang-say-gion_F_crop_1.jpg: 320x640 5 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/493_khoai-lang-vang-say-gion_F_crop_2.jpg: 512x640 2 texts, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/494_bot-matcha_F_crop_0.jpg: 288x640 1 text, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/494_bot-matcha_F_crop_1.jpg: 640x640 2 texts, 8.5ms\n",
      "Speed: 2.2ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/494_bot-matcha_F_crop_2.jpg: 384x640 2 texts, 9.3ms\n",
      "Speed: 1.3ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/495_oatside_F_crop_0.jpg: 640x160 3 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/495_oatside_F_crop_1.jpg: 576x640 2 texts, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/496_xoai-say-deo_F_crop_0.jpg: 352x640 2 texts, 9.7ms\n",
      "Speed: 1.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/496_xoai-say-deo_F_crop_1.jpg: 160x640 3 texts, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/496_xoai-say-deo_F_crop_2.jpg: 288x640 2 texts, 9.4ms\n",
      "Speed: 1.0ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/497_banh-sua-socola_F_crop_0.jpg: 384x640 3 texts, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/497_banh-sua-socola_F_crop_1.jpg: 256x640 3 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/498_dao-tuoi_F_crop_0.jpg: 192x640 2 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/498_dao-tuoi_F_crop_1.jpg: 320x640 3 texts, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/499_banh-phong-sua_F_crop_0.jpg: 160x640 3 texts, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/499_banh-phong-sua_F_crop_1.jpg: 160x640 2 texts, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/499_banh-phong-sua_F_crop_2.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/500_dong-trung-ha-thao-kho_F_crop_0.jpg: 192x640 5 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/500_dong-trung-ha-thao-kho_F_crop_1.jpg: 288x640 3 texts, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/501_tra-atiso-hoa-cuc_F_crop_0.jpg: 384x640 6 texts, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/501_tra-atiso-hoa-cuc_F_crop_1.jpg: 224x640 3 texts, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/502_tra-hoa-cuc-chi_F_crop_0.jpg: 128x640 4 texts, 10.1ms\n",
      "Speed: 0.6ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/502_tra-hoa-cuc-chi_F_crop_1.jpg: 288x640 3 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/503_sua-chua-thanh-trung_F_crop_0.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.6ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/503_sua-chua-thanh-trung_F_crop_1.jpg: 288x640 3 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/503_sua-chua-thanh-trung_F_crop_2.jpg: 352x640 5 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/504_kho-heo-chay-toi_F_crop_0.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/504_kho-heo-chay-toi_F_crop_1.jpg: 352x640 4 texts, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/504_kho-heo-chay-toi_F_crop_2.jpg: 224x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/504_kho-heo-chay-toi_F_crop_3.jpg: 256x640 1 text, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/506_hanh-nhan-rang-moc_F_crop_0.jpg: 96x640 4 texts, 10.8ms\n",
      "Speed: 0.5ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/506_hanh-nhan-rang-moc_F_crop_1.jpg: 320x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/506_hanh-nhan-rang-moc_F_crop_2.jpg: 352x640 3 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/507_tra-trai-nhau_F_crop_0.jpg: 128x640 2 texts, 8.8ms\n",
      "Speed: 0.6ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/507_tra-trai-nhau_F_crop_1.jpg: 224x640 3 texts, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/507_tra-trai-nhau_F_crop_2.jpg: 480x640 2 texts, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/508_tra-trai-nhau_B_crop_0.jpg: 96x640 5 texts, 10.4ms\n",
      "Speed: 0.6ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "Processed: 1600/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/508_tra-trai-nhau_B_crop_1.jpg: 160x640 1 text, 9.6ms\n",
      "Speed: 0.7ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/508_tra-trai-nhau_B_crop_2.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/509_tra-trai-cay-nhiet-doi_F_crop_0.jpg: 544x640 2 texts, 9.0ms\n",
      "Speed: 1.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/509_tra-trai-cay-nhiet-doi_F_crop_1.jpg: 288x640 5 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/509_tra-trai-cay-nhiet-doi_F_crop_2.jpg: 320x640 2 texts, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/509_tra-vi-chanh_F_crop_0.jpg: 384x640 3 texts, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/509_tra-vi-chanh_F_crop_1.jpg: 256x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/510_tra-trai-cay-nhiet-doi_B_crop_0.jpg: 512x640 2 texts, 8.4ms\n",
      "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/510_tra-trai-cay-nhiet-doi_B_crop_1.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.6ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/510_tra-trai-cay-nhiet-doi_B_crop_2.jpg: 128x640 1 text, 8.6ms\n",
      "Speed: 0.6ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/511_cafe-pho_F_crop_0.jpg: 256x640 3 texts, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/511_cafe-pho_F_crop_1.jpg: 320x640 4 texts, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/511_cafe-pho_F_crop_2.jpg: 160x640 5 texts, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/511_cafe-pho_F_crop_3.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/512_cafe-pho_R_crop_0.jpg: 256x640 3 texts, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/512_cafe-pho_R_crop_1.jpg: 288x640 4 texts, 9.1ms\n",
      "Speed: 1.3ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/512_cafe-pho_R_crop_2.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/512_cafe-pho_R_crop_3.jpg: 128x640 4 texts, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/513_so-co-la-trang_F_crop_0.jpg: 224x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/513_so-co-la-trang_F_crop_1.jpg: 192x640 6 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/513_so-co-la-trang_F_crop_2.jpg: 448x640 3 texts, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/514_nuoc-cot-bun-rieu_F_crop_0.jpg: 288x640 4 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/514_nuoc-cot-bun-rieu_F_crop_1.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/515_so-co-la-trang_B_crop_0.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/515_so-co-la-trang_B_crop_1.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/515_so-co-la-trang_B_crop_2.jpg: 160x640 1 text, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/516_cappuccino-sau-rieng_F_crop_0.jpg: 384x640 1 text, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/516_cappuccino-sau-rieng_F_crop_1.jpg: 160x640 3 texts, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/516_cappuccino-sau-rieng_F_crop_2.jpg: 416x640 2 texts, 8.3ms\n",
      "Speed: 1.3ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/517_gia-vi-tiem-ga_F_crop_0.jpg: 352x640 4 texts, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/517_gia-vi-tiem-ga_F_crop_1.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/518_gia-vi-tiem-ga-hat-sen_F_crop_0.jpg: 224x640 6 texts, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/518_gia-vi-tiem-ga-hat-sen_F_crop_1.jpg: 256x640 2 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/519_so-co-la-den_F_crop_0.jpg: 192x640 3 texts, 15.3ms\n",
      "Speed: 1.6ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/519_so-co-la-den_F_crop_1.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/519_so-co-la-den_F_crop_2.jpg: 384x640 2 texts, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/520_banh-dua-nuong_F_crop_0.jpg: 640x512 2 texts, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/520_banh-dua-nuong_F_crop_1.jpg: 192x640 3 texts, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/520_banh-dua-nuong_F_crop_2.jpg: 384x640 2 texts, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/521_vit-tiem_F_crop_0.jpg: 448x640 3 texts, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/521_vit-tiem_F_crop_1.jpg: 352x640 2 texts, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/521_vit-tiem_F_crop_2.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/522_nuoc-cot-bun-mam_F_crop_0.jpg: 320x640 4 texts, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/522_nuoc-cot-bun-mam_F_crop_1.jpg: 256x640 2 texts, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/523_bot-banh-quay_F_crop_0.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/523_bot-banh-quay_F_crop_1.jpg: 256x640 3 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/523_bot-banh-quay_F_crop_2.jpg: 256x640 2 texts, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/524_bot-khuc-bach_F_crop_0.jpg: 192x640 3 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/524_bot-khuc-bach_F_crop_1.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/524_bot-khuc-bach_F_crop_2.jpg: 288x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Processed: 1650/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/525_keo-dua_F_crop_0.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/525_keo-dua_F_crop_1.jpg: 384x640 2 texts, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/525_keo-dua_F_crop_2.jpg: 192x640 2 texts, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/525_keo-dua_F_crop_3.jpg: 352x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/526_chuoi-say_F_crop_0.jpg: 640x480 2 texts, 8.8ms\n",
      "Speed: 1.5ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/526_chuoi-say_F_crop_1.jpg: 352x640 2 texts, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/526_chuoi-say_F_crop_2.jpg: 256x640 2 texts, 9.5ms\n",
      "Speed: 0.9ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/527_keo-dua_B_crop_0.jpg: 128x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/527_keo-dua_B_crop_1.jpg: 128x640 1 text, 8.2ms\n",
      "Speed: 0.6ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/528_banh-dau-xanh-rong-vang-hoang-gia_B_crop_0.jpg: 96x640 7 texts, 11.0ms\n",
      "Speed: 0.7ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/528_banh-dau-xanh-rong-vang-hoang-gia_B_crop_1.jpg: 352x640 2 texts, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/528_banh-dau-xanh-rong-vang-hoang-gia_B_crop_2.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/529_banh-dau-xanh-rong-vang-hoang-gia_R_crop_0.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/529_banh-dau-xanh-rong-vang-hoang-gia_R_crop_1.jpg: 160x640 1 text, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/529_banh-dau-xanh-rong-vang-hoang-gia_R_crop_2.jpg: 288x640 2 texts, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/530_banh-dau-xanh-huong-vi-dua_F_crop_0.jpg: 640x288 6 texts, 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/531_banh-dau-xanh_F_crop_0.jpg: 160x640 3 texts, 9.5ms\n",
      "Speed: 0.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/531_banh-dau-xanh_F_crop_1.jpg: 160x640 2 texts, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/531_banh-dau-xanh_F_crop_2.jpg: 128x640 2 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/532_banh-dau-xanh_F_crop_0.jpg: 192x640 3 texts, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/532_banh-dau-xanh_F_crop_1.jpg: 128x640 2 texts, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/533_keo-thap-cam_F_crop_0.jpg: 416x640 2 texts, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/533_keo-thap-cam_F_crop_1.jpg: 256x640 3 texts, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/533_keo-thap-cam_F_crop_2.jpg: 384x640 2 texts, 9.4ms\n",
      "Speed: 1.3ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/534_keo-huong-dau-tay_B_crop_0.jpg: 416x640 2 texts, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/534_keo-huong-dau-tay_B_crop_1.jpg: 128x640 4 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/534_keo-huong-dau-tay_B_crop_2.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/534_keo-huong-dau-tay_B_crop_3.jpg: 128x640 1 text, 9.2ms\n",
      "Speed: 0.6ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/534_keo-huong-dau-tay_B_crop_4.jpg: 128x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/535_banh-dau-xanh_R_crop_0.jpg: 640x320 6 texts, 39.5ms\n",
      "Speed: 1.5ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/535_banh-dau-xanh_R_crop_1.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/536_keo-huong-dau-tay_F_crop_0.jpg: 384x640 2 texts, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/536_keo-huong-dau-tay_F_crop_1.jpg: 160x640 4 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/536_keo-huong-dau-tay_F_crop_2.jpg: 320x640 2 texts, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/537_keo-huong-dau-tam_F_crop_0.jpg: 128x640 3 texts, 8.7ms\n",
      "Speed: 0.6ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/537_keo-huong-dau-tam_F_crop_1.jpg: 288x640 2 texts, 10.2ms\n",
      "Speed: 1.3ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/537_keo-huong-dau-tam_F_crop_2.jpg: 384x640 2 texts, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/538_bot-gia-vi-ngu-vi-huong_F_crop_0.jpg: 512x640 2 texts, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/538_bot-gia-vi-ngu-vi-huong_F_crop_1.jpg: 96x640 6 texts, 9.7ms\n",
      "Speed: 0.6ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/539_bot-gia-vi-ngu-vi-huong_B_crop_0.jpg: 608x640 2 texts, 8.3ms\n",
      "Speed: 2.0ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/539_bot-gia-vi-ngu-vi-huong_B_crop_1.jpg: 224x640 3 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/539_bot-gia-vi-ngu-vi-huong_B_crop_2.jpg: 224x640 3 texts, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/539_bot-gia-vi-ngu-vi-huong_B_crop_3.jpg: 352x640 2 texts, 9.5ms\n",
      "Speed: 1.3ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/540_soda_F_crop_0.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/540_soda_F_crop_1.jpg: 320x640 4 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/540_soda_F_crop_2.jpg: 480x640 2 texts, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/541_soda_D_crop_0.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/541_soda_D_crop_1.jpg: 224x640 1 text, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/542_gia-vi-uop-thit-mac-mat_F_crop_0.jpg: 544x640 2 texts, 8.9ms\n",
      "Speed: 1.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/542_gia-vi-uop-thit-mac-mat_F_crop_1.jpg: 128x640 6 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "Processed: 1700/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/543_gia-vi-uop-thi-mac-mat_B_crop_0.jpg: 480x640 2 texts, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/543_gia-vi-uop-thi-mac-mat_B_crop_1.jpg: 96x640 4 texts, 9.9ms\n",
      "Speed: 0.7ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/543_gia-vi-uop-thi-mac-mat_B_crop_2.jpg: 192x640 3 texts, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/543_gia-vi-uop-thi-mac-mat_B_crop_3.jpg: 160x640 3 texts, 9.6ms\n",
      "Speed: 0.7ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/543_gia-vi-uop-thi-mac-mat_B_crop_4.jpg: 320x640 2 texts, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/544_gia-vi-uop-thit-nuong_F_crop_0.jpg: 608x640 2 texts, 8.3ms\n",
      "Speed: 2.0ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/544_gia-vi-uop-thit-nuong_F_crop_1.jpg: 96x640 5 texts, 9.9ms\n",
      "Speed: 0.6ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/545_xot-uop-xa-xiu_F_crop_0.jpg: 256x640 2 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/545_xot-uop-xa-xiu_F_crop_1.jpg: 352x640 6 texts, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/545_xot-uop-xa-xiu_F_crop_2.jpg: 384x640 2 texts, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/546_so-co-la-phu-dua_F_crop_0.jpg: 288x640 5 texts, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/546_so-co-la-phu-dua_F_crop_1.jpg: 96x640 7 texts, 10.3ms\n",
      "Speed: 0.6ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/546_so-co-la-phu-dua_F_crop_2.jpg: 256x640 1 text, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/546_so-co-la-phu-dua_F_crop_3.jpg: 512x640 2 texts, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/547_banh-dua-nuong_F_crop_0.jpg: 640x480 2 texts, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/547_banh-dua-nuong_F_crop_1.jpg: 352x640 4 texts, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/547_banh-dua-nuong_F_crop_2.jpg: 416x640 2 texts, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/548_so-co-la-nhan-kem-ca-phe_F_crop_0.jpg: 416x640 2 texts, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/548_so-co-la-nhan-kem-ca-phe_F_crop_1.jpg: 512x640 8 texts, 8.4ms\n",
      "Speed: 2.1ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/549_socola-hat-sen_B_crop_0.jpg: 96x640 6 texts, 9.9ms\n",
      "Speed: 0.6ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/549_socola-hat-sen_B_crop_1.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/549_socola-hat-sen_B_crop_2.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/549_socola-hat-sen_B_crop_3.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/550_socola-den_B_crop_0.jpg: 160x640 2 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/550_socola-den_B_crop_1.jpg: 352x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/550_socola-den_B_crop_2.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/550_socola-den_B_crop_3.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/551_so-co-la-phu-xoai_F_crop_0.jpg: 320x640 5 texts, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/551_so-co-la-phu-xoai_F_crop_1.jpg: 256x640 1 text, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/551_so-co-la-phu-xoai_F_crop_2.jpg: 448x640 2 texts, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/551_so-co-la-phu-xoai_F_crop_3.jpg: 96x640 7 texts, 10.1ms\n",
      "Speed: 0.5ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/552_so-co-la-den-boc-hat-mac-ca_F_crop_0.jpg: 640x608 8 texts, 8.6ms\n",
      "Speed: 2.3ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/553_ca-phe-hoa-tan_F_crop_0.jpg: 576x640 2 texts, 9.0ms\n",
      "Speed: 2.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/553_ca-phe-hoa-tan_F_crop_1.jpg: 128x640 4 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/553_ca-phe-hoa-tan_F_crop_2.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/554_ca-phe-hoa-tan_T_crop_0.jpg: 128x640 1 text, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/554_ca-phe-hoa-tan_T_crop_1.jpg: 128x640 1 text, 8.3ms\n",
      "Speed: 0.6ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/555_keo-thap-cam_D_crop_0.jpg: 384x640 2 texts, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/555_keo-thap-cam_D_crop_1.jpg: 160x640 3 texts, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/555_keo-thap-cam_D_crop_2.jpg: 128x640 1 text, 14.3ms\n",
      "Speed: 0.6ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/555_keo-thap-cam_D_crop_3.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/556_keo-huong-dau-tam_B_crop_0.jpg: 416x640 2 texts, 10.4ms\n",
      "Speed: 1.5ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/556_keo-huong-dau-tam_B_crop_1.jpg: 96x640 4 texts, 10.6ms\n",
      "Speed: 0.5ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/556_keo-huong-dau-tam_B_crop_2.jpg: 128x640 1 text, 9.6ms\n",
      "Speed: 0.7ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/556_keo-huong-dau-tam_B_crop_3.jpg: 128x640 1 text, 11.7ms\n",
      "Speed: 0.8ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/556_keo-huong-dau-tam_B_crop_4.jpg: 128x640 1 text, 8.7ms\n",
      "Speed: 0.6ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/557_unknow_T_crop_0.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/557_unknow_T_crop_1.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/558_unknow_T_crop_0.jpg: 352x640 2 texts, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/558_unknow_T_crop_1.jpg: 128x640 1 text, 9.3ms\n",
      "Speed: 0.6ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "Processed: 1750/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/558_unknow_T_crop_2.jpg: 128x640 1 text, 8.1ms\n",
      "Speed: 0.6ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/559_duong-la-han-qua_F_crop_0.jpg: 288x640 6 texts, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/559_duong-la-han-qua_F_crop_1.jpg: 640x640 4 texts, 8.7ms\n",
      "Speed: 2.5ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/559_duong-la-han-qua_F_crop_2.jpg: 320x640 2 texts, 9.6ms\n",
      "Speed: 1.1ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/560_lau-kim-chi_F_crop_0.jpg: 224x640 1 text, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/560_lau-kim-chi_F_crop_1.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/560_lau-kim-chi_F_crop_2.jpg: 256x640 7 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/560_lau-kim-chi_F_crop_3.jpg: 224x640 3 texts, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/561_unknow_F_crop_0.jpg: 224x640 1 text, 8.2ms\n",
      "Speed: 0.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/561_unknow_F_crop_1.jpg: 192x640 1 text, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/562_giao-lut-hon-hop_T_crop_0.jpg: 160x640 3 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/562_giao-lut-hon-hop_T_crop_1.jpg: 160x640 3 texts, 8.0ms\n",
      "Speed: 0.7ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/562_giao-lut-hon-hop_T_crop_2.jpg: 320x640 7 texts, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/562_giao-lut-hon-hop_T_crop_3.jpg: 384x640 2 texts, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/563_sinh-to-viet-quoc_F_crop_0.jpg: 640x480 2 texts, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/563_sinh-to-viet-quoc_F_crop_1.jpg: 416x640 4 texts, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/563_sinh-to-viet-quoc_F_crop_2.jpg: 320x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/564_tuong-ot-sieu-cay_F_crop_0.jpg: 224x640 2 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/564_tuong-ot-sieu-cay_F_crop_1.jpg: 512x640 5 texts, 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/564_tuong-ot-sieu-cay_F_crop_2.jpg: 576x640 2 texts, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/565_sinh-to-xoai_F_crop_0.jpg: 640x448 2 texts, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/565_sinh-to-xoai_F_crop_1.jpg: 448x640 3 texts, 8.7ms\n",
      "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/565_sinh-to-xoai_F_crop_2.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/566_sinh-to-mang-cau_F_crop_0.jpg: 160x640 2 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/566_sinh-to-mang-cau_F_crop_1.jpg: 160x640 4 texts, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/566_sinh-to-mang-cau_F_crop_2.jpg: 320x640 2 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/567_gia-vi-rac-com_F_crop_0.jpg: 352x640 1 text, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/567_gia-vi-rac-com_F_crop_1.jpg: 320x640 4 texts, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/567_gia-vi-rac-com_F_crop_2.jpg: 416x640 2 texts, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/568_gao-lua-tom-nang-huong_F_crop_0.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/568_gao-lua-tom-nang-huong_F_crop_1.jpg: 256x640 5 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/568_gao-lua-tom-nang-huong_F_crop_2.jpg: 320x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/569_tuong-den_F_crop_0.jpg: 640x512 2 texts, 8.7ms\n",
      "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/569_tuong-den_F_crop_1.jpg: 192x640 2 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/569_tuong-den_F_crop_2.jpg: 320x640 2 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/570_hat-va-trai-cay-say_F_crop_0.jpg: 640x480 2 texts, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/570_hat-va-trai-cay-say_F_crop_1.jpg: 128x640 5 texts, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/570_hat-va-trai-cay-say_F_crop_2.jpg: 320x640 2 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/571_nho-chile-vang_F_crop_0.jpg: 640x480 3 texts, 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/571_nho-chile-vang_F_crop_1.jpg: 128x640 3 texts, 9.5ms\n",
      "Speed: 0.7ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/571_nho-chile-vang_F_crop_2.jpg: 288x640 2 texts, 9.4ms\n",
      "Speed: 1.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/572_gao-huu-co-ecoba-huyet-rong_F_crop_0.jpg: 384x640 1 text, 9.4ms\n",
      "Speed: 1.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/572_gao-huu-co-ecoba-huyet-rong_F_crop_1.jpg: 128x640 6 texts, 9.6ms\n",
      "Speed: 0.7ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/572_gao-huu-co-ecoba-huyet-rong_F_crop_2.jpg: 480x640 2 texts, 9.3ms\n",
      "Speed: 1.7ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/573_gao-huu-co-ecoba-ngoc-me_F_crop_0.jpg: 384x640 1 text, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/573_gao-huu-co-ecoba-ngoc-me_F_crop_1.jpg: 128x640 6 texts, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/573_gao-huu-co-ecoba-ngoc-me_F_crop_2.jpg: 448x640 2 texts, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/574_ca-chai-nuong_B_crop_0.jpg: 128x640 3 texts, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/574_ca-chai-nuong_B_crop_1.jpg: 96x640 7 texts, 12.1ms\n",
      "Speed: 0.8ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/574_ca-chai-nuong_B_crop_2.jpg: 352x640 3 texts, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Processed: 1800/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/575_nep-sap_F_crop_0.jpg: 640x416 1 text, 39.6ms\n",
      "Speed: 1.4ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/575_nep-sap_F_crop_1.jpg: 640x480 2 texts, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/575_nep-sap_F_crop_2.jpg: 256x640 1 text, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/575_nep-sap_F_crop_3.jpg: 224x640 2 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/575_nep-sap_F_crop_4.jpg: 320x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/576_nep-sap_T_crop_0.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/576_nep-sap_T_crop_1.jpg: 192x640 1 text, 8.3ms\n",
      "Speed: 0.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/577_me-trang_F_crop_0.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/577_me-trang_F_crop_1.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/577_me-trang_F_crop_2.jpg: 384x640 1 text, 9.4ms\n",
      "Speed: 1.3ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/577_me-trang_F_crop_3.jpg: 192x640 2 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/577_me-trang_F_crop_4.jpg: 256x640 2 texts, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/578_bun-tuoi_F_crop_0.jpg: 416x640 1 text, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/578_bun-tuoi_F_crop_1.jpg: 352x640 4 texts, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/578_bun-tuoi_F_crop_2.jpg: 256x640 2 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/579_che-hat-sen-thap-sen_F_crop_0.jpg: 128x640 5 texts, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/579_che-hat-sen-thap-sen_F_crop_1.jpg: 128x640 3 texts, 8.8ms\n",
      "Speed: 0.6ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/579_che-hat-sen-thap-sen_F_crop_2.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/580_me-trang-khong-vo_F_crop_0.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/580_me-trang-khong-vo_F_crop_1.jpg: 192x640 1 text, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/580_me-trang-khong-vo_F_crop_2.jpg: 448x640 1 text, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/580_me-trang-khong-vo_F_crop_3.jpg: 160x640 4 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/580_me-trang-khong-vo_F_crop_4.jpg: 288x640 2 texts, 10.4ms\n",
      "Speed: 0.9ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/581_mi-quang-kho_F_crop_0.jpg: 128x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/581_mi-quang-kho_F_crop_1.jpg: 128x640 1 text, 8.1ms\n",
      "Speed: 0.6ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/581_mi-quang-kho_F_crop_2.jpg: 160x640 3 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/582_mi-quang-kho_F_crop_0.jpg: 160x640 3 texts, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/582_mi-quang-kho_F_crop_1.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/583_mi-rau-cu-tuoi_F_crop_0.jpg: 640x480 2 texts, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/583_mi-rau-cu-tuoi_F_crop_1.jpg: 160x640 4 texts, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/583_mi-rau-cu-tuoi_F_crop_2.jpg: 288x640 2 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/584_mi-rau-cu-tuoi_R_crop_0.jpg: 128x640 1 text, 8.6ms\n",
      "Speed: 0.6ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/584_mi-rau-cu-tuoi_R_crop_1.jpg: 96x640 1 text, 9.7ms\n",
      "Speed: 0.5ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/585_ca-chai-nuong_F_crop_0.jpg: 320x640 3 texts, 8.8ms\n",
      "Speed: 1.5ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/586_ca-trich_F_crop_0.jpg: 640x512 2 texts, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/586_ca-trich_F_crop_1.jpg: 320x640 5 texts, 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/587_ca-chai-nuong_D_crop_0.jpg: 224x640 1 text, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/587_ca-chai-nuong_D_crop_1.jpg: 192x640 1 text, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/588_bun-tuoi_B_crop_0.jpg: 224x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/588_bun-tuoi_B_crop_1.jpg: 256x640 1 text, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/588_bun-tuoi_B_crop_2.jpg: 384x640 1 text, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/589_bun-tuoi_F_crop_0.jpg: 192x640 3 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/589_bun-tuoi_F_crop_1.jpg: 192x640 3 texts, 8.2ms\n",
      "Speed: 0.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/589_bun-tuoi_F_crop_2.jpg: 256x640 2 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/589_bun-tuoi_F_crop_3.jpg: 320x640 4 texts, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/589_bun-tuoi_F_crop_4.jpg: 352x640 2 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/590_gao-lut-hon-hop_F_crop_0.jpg: 352x640 2 texts, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/590_gao-lut-hon-hop_F_crop_1.jpg: 640x480 7 texts, 8.1ms\n",
      "Speed: 1.9ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/590_gao-lut-hon-hop_F_crop_2.jpg: 480x640 2 texts, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/591_sua-tam_F_crop_0.jpg: 640x384 2 texts, 8.5ms\n",
      "Speed: 1.3ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processed: 1850/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/591_sua-tam_F_crop_1.jpg: 256x640 8 texts, 8.4ms\n",
      "Speed: 1.1ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/591_sua-tam_F_crop_2.jpg: 384x640 2 texts, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/592_nuoc-rua-chen_F_crop_0.jpg: 640x416 3 texts, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/592_nuoc-rua-chen_F_crop_1.jpg: 192x640 8 texts, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/592_nuoc-rua-chen_F_crop_2.jpg: 384x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/592_nuoc-rua-chen_F_crop_3.jpg: 256x640 2 texts, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/593_nuoc-rua-chen_B_crop_0.jpg: 256x640 1 text, 8.4ms\n",
      "Speed: 0.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/594_bun-gao-lut_F_crop_0.jpg: 224x640 2 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/594_bun-gao-lut_F_crop_1.jpg: 416x640 3 texts, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/594_bun-gao-lut_F_crop_2.jpg: 224x640 2 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/595_banh-afc-vi-lua-mi_F_crop_0.jpg: 192x640 2 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/595_banh-afc-vi-lua-mi_F_crop_1.jpg: 128x640 2 texts, 8.5ms\n",
      "Speed: 0.6ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/595_banh-afc-vi-lua-mi_F_crop_2.jpg: 384x640 1 text, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/595_banh-afc-vi-lua-mi_F_crop_3.jpg: 224x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/595_banh-afc-vi-lua-mi_F_crop_4.jpg: 448x640 2 texts, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/596_sua-tam-hoa-anh-dao_B_crop_0.jpg: 128x640 5 texts, 9.5ms\n",
      "Speed: 0.6ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/596_sua-tam-hoa-anh-dao_B_crop_1.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/596_sua-tam-hoa-anh-dao_B_crop_2.jpg: 352x640 2 texts, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/597_sua-tam-hoa-anh-dao_F_crop_0.jpg: 192x640 1 text, 8.8ms\n",
      "Speed: 0.5ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/597_sua-tam-hoa-anh-dao_F_crop_1.jpg: 288x640 2 texts, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/598_sua-dau-nanh-fami-nguyen-chat_F_crop_0.jpg: 192x640 3 texts, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/598_sua-dau-nanh-fami-nguyen-chat_F_crop_1.jpg: 320x640 4 texts, 9.3ms\n",
      "Speed: 1.3ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/598_sua-dau-nanh-fami-nguyen-chat_F_crop_2.jpg: 512x640 2 texts, 8.8ms\n",
      "Speed: 1.5ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/599_sua-dau-nanh-fami-nguyen-chat_B_crop_0.jpg: 288x640 3 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/599_sua-dau-nanh-fami-nguyen-chat_B_crop_1.jpg: 288x640 3 texts, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/600_cha-bong-heo_F_crop_0.jpg: 416x640 1 text, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/600_cha-bong-heo_F_crop_1.jpg: 448x640 3 texts, 8.5ms\n",
      "Speed: 1.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/600_cha-bong-heo_F_crop_2.jpg: 480x640 2 texts, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/601_cha-bong-heo_B_crop_0.jpg: 160x640 3 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/601_cha-bong-heo_B_crop_1.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/601_cha-bong-heo_B_crop_2.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.6ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/601_cha-bong-heo_B_crop_3.jpg: 160x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/602_kho-heo-say-toi_F_crop_0.jpg: 384x640 1 text, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/602_kho-heo-say-toi_F_crop_1.jpg: 416x640 4 texts, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/602_kho-heo-say-toi_F_crop_2.jpg: 384x640 3 texts, 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/603_kho-heo-say-toi_B_crop_0.jpg: 192x640 4 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/603_kho-heo-say-toi_B_crop_1.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/603_kho-heo-say-toi_B_crop_2.jpg: 160x640 3 texts, 8.2ms\n",
      "Speed: 0.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/603_kho-heo-say-toi_B_crop_3.jpg: 160x640 3 texts, 8.3ms\n",
      "Speed: 0.7ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/604_kho-ga-la-chanh_F_crop_0.jpg: 416x640 1 text, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/604_kho-ga-la-chanh_F_crop_1.jpg: 384x640 4 texts, 9.6ms\n",
      "Speed: 1.6ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/604_kho-ga-la-chanh_F_crop_2.jpg: 416x640 2 texts, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/605_kho-ga-la-chanh_B_crop_0.jpg: 128x640 4 texts, 8.7ms\n",
      "Speed: 0.6ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/605_kho-ga-la-chanh_B_crop_1.jpg: 160x640 1 text, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/605_kho-ga-la-chanh_B_crop_2.jpg: 160x640 1 text, 8.4ms\n",
      "Speed: 0.6ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/605_kho-ga-la-chanh_B_crop_3.jpg: 160x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/606_kho-ga-cay_F_crop_0.jpg: 224x640 3 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/606_kho-ga-cay_F_crop_1.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/606_kho-ga-cay_F_crop_2.jpg: 416x640 2 texts, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/607_kho-ga-cay_B_crop_0.jpg: 416x640 1 text, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Processed: 1900/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/607_kho-ga-cay_B_crop_1.jpg: 224x640 3 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/607_kho-ga-cay_B_crop_2.jpg: 256x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/607_kho-ga-cay_B_crop_3.jpg: 256x640 1 text, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/608_thit-bo-kho_F_crop_0.jpg: 288x640 2 texts, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/608_thit-bo-kho_F_crop_1.jpg: 160x640 3 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/608_thit-bo-kho_F_crop_2.jpg: 352x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/609_thit-bo-kho_B_crop_0.jpg: 320x640 1 text, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/609_thit-bo-kho_B_crop_1.jpg: 192x640 3 texts, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/609_thit-bo-kho_B_crop_2.jpg: 224x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/609_thit-bo-kho_B_crop_3.jpg: 224x640 1 text, 8.1ms\n",
      "Speed: 0.8ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/610_bot-suong-sao-den_F_crop_0.jpg: 640x512 4 texts, 8.3ms\n",
      "Speed: 2.1ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/610_bot-suong-sao-den_F_crop_1.jpg: 352x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/610_bot-suong-sao-den_F_crop_2.jpg: 416x640 1 text, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/611_bot-suong-sao-den_B_crop_0.jpg: 224x640 4 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/611_bot-suong-sao-den_B_crop_1.jpg: 480x640 1 text, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/611_bot-suong-sao-den_B_crop_2.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/611_bot-suong-sao-den_B_crop_3.jpg: 160x640 1 text, 8.1ms\n",
      "Speed: 0.7ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/612_bot-rau-cau-deo_B_crop_0.jpg: 192x640 4 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/612_bot-rau-cau-deo_B_crop_1.jpg: 128x640 1 text, 9.1ms\n",
      "Speed: 0.6ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/612_bot-rau-cau-deo_B_crop_2.jpg: 128x640 1 text, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/613_bot-rau-cau-deo_F_crop_0.jpg: 192x640 4 texts, 14.4ms\n",
      "Speed: 1.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/613_bot-rau-cau-deo_F_crop_1.jpg: 384x640 1 text, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/613_bot-rau-cau-deo_F_crop_2.jpg: 416x640 2 texts, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/614_chao-mon_F_crop_0.jpg: 128x640 1 text, 8.7ms\n",
      "Speed: 0.6ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/614_chao-mon_F_crop_1.jpg: 160x640 1 text, 13.3ms\n",
      "Speed: 1.1ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/614_chao-mon_F_crop_2.jpg: 224x640 1 text, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/614_chao-mon_F_crop_3.jpg: 224x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/615_bot-suong-sam_F_crop_0.jpg: 192x640 3 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/615_bot-suong-sam_F_crop_1.jpg: 224x640 2 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/616_bot-suong-sam_B_crop_0.jpg: 160x640 3 texts, 10.1ms\n",
      "Speed: 0.9ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/616_bot-suong-sam_B_crop_1.jpg: 128x640 1 text, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/616_bot-suong-sam_B_crop_2.jpg: 128x640 1 text, 8.6ms\n",
      "Speed: 0.6ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/617_nuoc-tuong-dau-nanh_F_crop_0.jpg: 288x640 1 text, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/617_nuoc-tuong-dau-nanh_F_crop_1.jpg: 384x640 4 texts, 9.1ms\n",
      "Speed: 1.3ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/618_nuoc-tuong-dau-nanh_B_crop_0.jpg: 192x640 1 text, 9.5ms\n",
      "Speed: 0.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/619_nuoc-tuong-dau-nanh_B_crop_0.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/620_nuoc-mam-dau-bep-tom_F_crop_0.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/620_nuoc-mam-dau-bep-tom_F_crop_1.jpg: 640x480 3 texts, 8.4ms\n",
      "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/620_nuoc-mam-dau-bep-tom_F_crop_2.jpg: 288x640 2 texts, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/621_nuoc-mam-nam-ngu_F_crop_0.jpg: 224x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/621_nuoc-mam-nam-ngu_F_crop_1.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/621_nuoc-mam-nam-ngu_F_crop_2.jpg: 352x640 2 texts, 9.3ms\n",
      "Speed: 1.3ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/621_nuoc-mam-nam-ngu_F_crop_3.jpg: 640x640 2 texts, 8.8ms\n",
      "Speed: 2.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/621_nuoc-mam-nam-ngu_F_crop_4.jpg: 192x640 2 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/622_nuoc-mam-nam-ngu_F_crop_0.jpg: 320x640 2 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/622_nuoc-mam-nam-ngu_F_crop_1.jpg: 640x480 2 texts, 8.3ms\n",
      "Speed: 2.1ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/622_nuoc-mam-nam-ngu_F_crop_2.jpg: 352x640 2 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/622_nuoc-mam-nam-ngu_F_crop_3.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/623_hat-nem-tam-bao_F_crop_0.jpg: 352x640 2 texts, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/623_hat-nem-tam-bao_F_crop_1.jpg: 320x640 2 texts, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Processed: 1950/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/623_hat-nem-tam-bao_F_crop_2.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/623_hat-nem-tam-bao_F_crop_3.jpg: 256x640 2 texts, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/624_muoi-say-i-ot_F_crop_0.jpg: 160x640 2 texts, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/624_muoi-say-i-ot_F_crop_1.jpg: 192x640 3 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/624_muoi-say-i-ot_F_crop_2.jpg: 352x640 2 texts, 9.6ms\n",
      "Speed: 1.1ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/625_muoi-say-i-ot_B_crop_0.jpg: 288x640 1 text, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/625_muoi-say-i-ot_B_crop_1.jpg: 96x640 10 texts, 9.9ms\n",
      "Speed: 0.6ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/626_hat-nem-cao-cap-nam-huong_F_crop_0.jpg: 128x640 6 texts, 8.9ms\n",
      "Speed: 0.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/626_hat-nem-cao-cap-nam-huong_F_crop_1.jpg: 224x640 1 text, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/626_hat-nem-cao-cap-nam-huong_F_crop_2.jpg: 544x640 2 texts, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/627_hat-nem-cao-cap-nam-huong_B_crop_0.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/628_bot-ngot-miwon_F_crop_0.jpg: 160x640 5 texts, 9.5ms\n",
      "Speed: 0.9ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/628_bot-ngot-miwon_F_crop_1.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/628_bot-ngot-miwon_F_crop_2.jpg: 224x640 1 text, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/628_bot-ngot-miwon_F_crop_3.jpg: 416x640 2 texts, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/629_th-true-milk-sua-tuoi-tiet-trung-co-duong_F_crop_0.jpg: 640x544 3 texts, 8.4ms\n",
      "Speed: 2.4ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/629_th-true-milk-sua-tuoi-tiet-trung-co-duong_F_crop_1.jpg: 224x640 6 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/629_th-true-milk-sua-tuoi-tiet-trung-co-duong_F_crop_2.jpg: 480x640 2 texts, 8.6ms\n",
      "Speed: 2.3ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/630_th-true-milk-sua-tuoi-tiet-trung-co-duong_T_crop_0.jpg: 224x640 1 text, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/630_th-true-milk-sua-tuoi-tiet-trung-co-duong_T_crop_1.jpg: 256x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/631_mi-y-xuc-xich-kieu-nhat_F_crop_0.jpg: 480x640 2 texts, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/631_mi-y-xuc-xich-kieu-nhat_F_crop_1.jpg: 448x640 6 texts, 8.4ms\n",
      "Speed: 1.7ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/631_mi-y-xuc-xich-kieu-nhat_F_crop_2.jpg: 352x640 2 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/632_mi-y-xuc-xich-kieu-nhat_B_crop_0.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/632_mi-y-xuc-xich-kieu-nhat_B_crop_1.jpg: 192x640 1 text, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/633_staff-banh-mi-3-trong-1_F_crop_0.jpg: 320x640 1 text, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/633_staff-banh-mi-3-trong-1_F_crop_1.jpg: 128x640 5 texts, 8.4ms\n",
      "Speed: 0.6ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/633_staff-banh-mi-3-trong-1_F_crop_2.jpg: 224x640 1 text, 14.4ms\n",
      "Speed: 1.2ms preprocess, 14.4ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/633_staff-banh-mi-3-trong-1_F_crop_3.jpg: 544x640 2 texts, 14.2ms\n",
      "Speed: 1.7ms preprocess, 14.2ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/634_hat-dac-rim_F_crop_0.jpg: 640x320 3 texts, 9.5ms\n",
      "Speed: 1.2ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/634_hat-dac-rim_F_crop_1.jpg: 96x640 9 texts, 10.3ms\n",
      "Speed: 0.5ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/634_hat-dac-rim_F_crop_2.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/635_nhan-macca-daklak_F_crop_0.jpg: 320x640 3 texts, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/636_sua-trai-cay-nho-tu-nhien_F_crop_0.jpg: 160x640 4 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/636_sua-trai-cay-nho-tu-nhien_F_crop_1.jpg: 224x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/636_sua-trai-cay-nho-tu-nhien_F_crop_2.jpg: 256x640 5 texts, 9.5ms\n",
      "Speed: 1.1ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/636_sua-trai-cay-nho-tu-nhien_F_crop_3.jpg: 160x640 8 texts, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/636_sua-trai-cay-nho-tu-nhien_F_crop_4.jpg: 256x640 2 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/637_hat-macca-viet_F_crop_0.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.6ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/637_hat-macca-viet_F_crop_1.jpg: 128x640 2 texts, 8.8ms\n",
      "Speed: 0.5ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/637_hat-macca-viet_F_crop_2.jpg: 192x640 3 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/637_hat-macca-viet_F_crop_3.jpg: 224x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/638_dau-dua_F_crop_0.jpg: 256x640 3 texts, 10.6ms\n",
      "Speed: 1.2ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/638_dau-dua_F_crop_1.jpg: 288x640 4 texts, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/638_dau-dua_F_crop_2.jpg: 288x640 2 texts, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/639_mat-ong-hoa-ca-phe_F_crop_0.jpg: 256x640 3 texts, 9.7ms\n",
      "Speed: 1.0ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/639_mat-ong-hoa-ca-phe_F_crop_1.jpg: 320x640 5 texts, 9.5ms\n",
      "Speed: 1.1ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/639_mat-ong-hoa-ca-phe_F_crop_2.jpg: 160x640 7 texts, 8.7ms\n",
      "Speed: 0.6ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/639_mat-ong-hoa-ca-phe_F_crop_3.jpg: 192x640 2 texts, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/639_mat-ong-hoa-ca-phe_F_crop_4.jpg: 224x640 2 texts, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Processed: 2000/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/640_mat-ong-hoa-ca-phe_F_crop_0.jpg: 256x640 3 texts, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/640_mat-ong-hoa-ca-phe_F_crop_1.jpg: 352x640 5 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/640_mat-ong-hoa-ca-phe_F_crop_2.jpg: 96x640 7 texts, 9.6ms\n",
      "Speed: 0.5ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/640_mat-ong-hoa-ca-phe_F_crop_3.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/640_mat-ong-hoa-ca-phe_F_crop_4.jpg: 224x640 4 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/641_tinh-bot-nghe_F_crop_0.jpg: 320x640 1 text, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/641_tinh-bot-nghe_F_crop_1.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/641_tinh-bot-nghe_F_crop_2.jpg: 384x640 2 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/642_bot-chuoi-xanh_F_crop_0.jpg: 256x640 3 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/642_bot-chuoi-xanh_F_crop_1.jpg: 160x640 3 texts, 9.7ms\n",
      "Speed: 0.6ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/642_bot-chuoi-xanh_F_crop_2.jpg: 160x640 3 texts, 8.6ms\n",
      "Speed: 0.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/642_bot-chuoi-xanh_F_crop_3.jpg: 352x640 2 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/642_bot-chuoi-xanh_F_crop_4.jpg: 192x640 3 texts, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/642_bot-chuoi-xanh_F_crop_5.jpg: 224x640 3 texts, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/643_tra-tieu-thuc_F_crop_0.jpg: 640x288 3 texts, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 288)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/643_tra-tieu-thuc_F_crop_1.jpg: 256x640 2 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/644_kombucha-ct_F_crop_0.jpg: 288x640 4 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/644_kombucha-ct_F_crop_1.jpg: 224x640 5 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/645_tra-vai_F_crop_0.jpg: 320x640 1 text, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/645_tra-vai_F_crop_1.jpg: 640x544 2 texts, 8.2ms\n",
      "Speed: 2.0ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/646_tra-vai_L_crop_0.jpg: 320x640 2 texts, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/647_tra-vai_T_crop_0.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/647_tra-vai_T_crop_1.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/648_tra-bi-dao_F_crop_0.jpg: 320x640 1 text, 9.9ms\n",
      "Speed: 1.5ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/648_tra-bi-dao_F_crop_1.jpg: 640x640 3 texts, 8.6ms\n",
      "Speed: 2.4ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/649_tra-bi-dao_B_crop_0.jpg: 288x640 2 texts, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/650_tra-chanh-c2_F_crop_0.jpg: 448x640 2 texts, 8.6ms\n",
      "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/650_tra-chanh-c2_F_crop_1.jpg: 640x576 2 texts, 8.7ms\n",
      "Speed: 2.4ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/650_tra-chanh-c2_F_crop_2.jpg: 352x640 4 texts, 9.4ms\n",
      "Speed: 2.1ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/651_tra-chanh-c2_B_crop_0.jpg: 288x640 2 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/652_tra-bi-dao_F_crop_0.jpg: 352x640 1 text, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/652_tra-bi-dao_F_crop_1.jpg: 352x640 1 text, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/652_tra-bi-dao_F_crop_2.jpg: 352x640 1 text, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/652_tra-bi-dao_F_crop_3.jpg: 320x640 3 texts, 9.1ms\n",
      "Speed: 1.3ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/653_tra-bi-dao_B_crop_0.jpg: 416x640 1 text, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/653_tra-bi-dao_B_crop_1.jpg: 352x640 1 text, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/653_tra-bi-dao_B_crop_2.jpg: 288x640 2 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/654_hat-dieu-pho-mai_F_crop_0.jpg: 256x640 7 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/654_hat-dieu-pho-mai_F_crop_1.jpg: 352x640 4 texts, 8.9ms\n",
      "Speed: 1.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/654_hat-dieu-pho-mai_F_crop_2.jpg: 320x640 1 text, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/654_hat-dieu-pho-mai_F_crop_3.jpg: 320x640 1 text, 8.6ms\n",
      "Speed: 1.2ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/654_hat-dieu-pho-mai_F_crop_4.jpg: 416x640 2 texts, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 3.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/655_hat-dieu-toi-ot_F_crop_0.jpg: 320x640 7 texts, 9.4ms\n",
      "Speed: 2.6ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/655_hat-dieu-toi-ot_F_crop_1.jpg: 320x640 4 texts, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/655_hat-dieu-toi-ot_F_crop_2.jpg: 320x640 1 text, 10.3ms\n",
      "Speed: 1.1ms preprocess, 10.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/655_hat-dieu-toi-ot_F_crop_3.jpg: 352x640 1 text, 9.4ms\n",
      "Speed: 2.4ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/655_hat-dieu-toi-ot_F_crop_4.jpg: 384x640 2 texts, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/656_dau-phong-da-ca_F_crop_0.jpg: 224x640 1 text, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/656_dau-phong-da-ca_F_crop_1.jpg: 288x640 4 texts, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/657_mit-say_F_crop_0.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Processed: 2050/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/657_mit-say_F_crop_1.jpg: 640x544 2 texts, 8.6ms\n",
      "Speed: 4.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/657_mit-say_F_crop_2.jpg: 352x640 3 texts, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/658_mit-say_B_crop_0.jpg: 224x640 2 texts, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/658_mit-say_B_crop_1.jpg: 224x640 1 text, 8.3ms\n",
      "Speed: 0.9ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/658_mit-say_B_crop_2.jpg: 160x640 1 text, 9.3ms\n",
      "Speed: 0.6ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/658_mit-say_B_crop_3.jpg: 128x640 1 text, 10.0ms\n",
      "Speed: 0.6ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/659_trai-cay-say_F_crop_0.jpg: 288x640 2 texts, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/659_trai-cay-say_F_crop_1.jpg: 192x640 3 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/659_trai-cay-say_F_crop_2.jpg: 416x640 2 texts, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/660_trai-cay-say_B_crop_0.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/660_trai-cay-say_B_crop_1.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/661_ca-phe-sua_F_crop_0.jpg: 544x640 2 texts, 8.4ms\n",
      "Speed: 2.3ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/661_ca-phe-sua_F_crop_1.jpg: 416x640 3 texts, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/661_ca-phe-sua_F_crop_2.jpg: 512x640 2 texts, 8.9ms\n",
      "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/662_ca-phe-sua_D_crop_0.jpg: 320x640 1 text, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/662_ca-phe-sua_D_crop_1.jpg: 288x640 1 text, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/663_vien-tay-toilet_B_crop_0.jpg: 128x640 3 texts, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/663_vien-tay-toilet_B_crop_1.jpg: 640x608 2 texts, 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/663_vien-tay-toilet_B_crop_2.jpg: 96x640 3 texts, 9.7ms\n",
      "Speed: 0.5ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/663_vien-tay-toilet_B_crop_3.jpg: 96x640 3 texts, 9.4ms\n",
      "Speed: 0.5ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/663_vien-tay-toilet_B_crop_4.jpg: 320x640 2 texts, 9.7ms\n",
      "Speed: 1.4ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/664_vien-tay-toilet_F_crop_0.jpg: 160x640 3 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/664_vien-tay-toilet_F_crop_1.jpg: 640x576 2 texts, 8.3ms\n",
      "Speed: 2.0ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/665_nuoc-xit-vai_F_crop_0.jpg: 320x640 4 texts, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/665_nuoc-xit-vai_F_crop_1.jpg: 224x640 3 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/665_nuoc-xit-vai_F_crop_2.jpg: 416x640 2 texts, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/666_khan-uot-khong-mui_D_crop_0.jpg: 384x640 1 text, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/666_khan-uot-khong-mui_D_crop_1.jpg: 96x640 6 texts, 10.2ms\n",
      "Speed: 0.6ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/666_khan-uot-khong-mui_D_crop_2.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/666_khan-uot-khong-mui_D_crop_3.jpg: 128x640 5 texts, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/666_khan-uot-khong-mui_D_crop_4.jpg: 224x640 6 texts, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/667_khan-uotkhong-mui_D_crop_0.jpg: 416x640 1 text, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/667_khan-uotkhong-mui_D_crop_1.jpg: 128x640 6 texts, 9.3ms\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/667_khan-uotkhong-mui_D_crop_2.jpg: 544x640 2 texts, 8.8ms\n",
      "Speed: 1.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/667_khan-uotkhong-mui_D_crop_3.jpg: 160x640 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/667_khan-uotkhong-mui_D_crop_4.jpg: 128x640 5 texts, 9.2ms\n",
      "Speed: 0.6ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/667_khan-uotkhong-mui_D_crop_5.jpg: 416x640 1 text, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/667_khan-uotkhong-mui_D_crop_6.jpg: 256x640 6 texts, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/668_khan-giay-lua-tre_D_crop_0.jpg: 320x640 1 text, 9.3ms\n",
      "Speed: 1.5ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/668_khan-giay-lua-tre_D_crop_1.jpg: 128x640 4 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/668_khan-giay-lua-tre_D_crop_2.jpg: 96x640 7 texts, 10.0ms\n",
      "Speed: 0.6ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/668_khan-giay-lua-tre_D_crop_3.jpg: 256x640 3 texts, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/669_khan-uot-khong-mui_D_crop_0.jpg: 384x640 1 text, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/669_khan-uot-khong-mui_D_crop_1.jpg: 96x640 6 texts, 12.8ms\n",
      "Speed: 0.8ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/669_khan-uot-khong-mui_D_crop_2.jpg: 192x640 1 text, 9.3ms\n",
      "Speed: 0.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/669_khan-uot-khong-mui_D_crop_3.jpg: 480x640 2 texts, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/669_khan-uot-khong-mui_D_crop_4.jpg: 352x640 1 text, 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/669_khan-uot-khong-mui_D_crop_5.jpg: 224x640 6 texts, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/669_khan-uot-khong-mui_D_crop_6.jpg: 160x640 5 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/670_bot-chien-gion_F_crop_0.jpg: 160x640 1 text, 8.3ms\n",
      "Speed: 0.9ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "Processed: 2100/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/670_bot-chien-gion_F_crop_1.jpg: 160x640 3 texts, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/671_bot-chien-gion_F_crop_0.jpg: 160x640 1 text, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/671_bot-chien-gion_F_crop_1.jpg: 192x640 3 texts, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/671_bot-chien-gion_F_crop_2.jpg: 352x640 2 texts, 9.6ms\n",
      "Speed: 1.1ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/672_bot-chien-gion_L_crop_0.jpg: 192x640 1 text, 9.6ms\n",
      "Speed: 0.8ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/672_bot-chien-gion_L_crop_1.jpg: 160x640 1 text, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/673_baking-soda_F_crop_0.jpg: 384x640 1 text, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/673_baking-soda_F_crop_1.jpg: 160x640 2 texts, 9.7ms\n",
      "Speed: 1.0ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/673_baking-soda_F_crop_2.jpg: 416x640 2 texts, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/674_baking-soda_B_crop_0.jpg: 96x640 4 texts, 10.5ms\n",
      "Speed: 0.6ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/674_baking-soda_B_crop_1.jpg: 352x640 1 text, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/674_baking-soda_B_crop_2.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/674_baking-soda_B_crop_3.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/675_mi-hieu-hai-tom_F_crop_0.jpg: 224x640 1 text, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/675_mi-hieu-hai-tom_F_crop_1.jpg: 288x640 8 texts, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/675_mi-hieu-hai-tom_F_crop_2.jpg: 448x640 2 texts, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/676_mi-hieu-hai-tom_L_crop_0.jpg: 192x640 3 texts, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/676_mi-hieu-hai-tom_L_crop_1.jpg: 192x640 3 texts, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/677_mi-ly-hao-hao_F_crop_0.jpg: 480x640 1 text, 8.9ms\n",
      "Speed: 1.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/677_mi-ly-hao-hao_F_crop_1.jpg: 608x640 2 texts, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/677_mi-ly-hao-hao_F_crop_2.jpg: 384x640 2 texts, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/677_mi-ly-hao-hao_F_crop_3.jpg: 608x640 2 texts, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/678_mi-ly-ho-hao_D_crop_0.jpg: 288x640 3 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/678_mi-ly-ho-hao_D_crop_1.jpg: 288x640 3 texts, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/679_my-ly-hao-hao_F_crop_0.jpg: 256x640 1 text, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/679_my-ly-hao-hao_F_crop_1.jpg: 512x640 2 texts, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/679_my-ly-hao-hao_F_crop_2.jpg: 320x640 2 texts, 8.8ms\n",
      "Speed: 1.5ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/679_my-ly-hao-hao_F_crop_3.jpg: 544x640 2 texts, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/680_my-ly-hao-hao_D_crop_0.jpg: 192x640 3 texts, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/680_my-ly-hao-hao_D_crop_1.jpg: 160x640 3 texts, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/681_mi-indomie_F_crop_0.jpg: 256x640 1 text, 9.6ms\n",
      "Speed: 1.3ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/681_mi-indomie_F_crop_1.jpg: 384x640 3 texts, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/681_mi-indomie_F_crop_2.jpg: 352x640 2 texts, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/681_mi-indomie_F_crop_3.jpg: 160x640 3 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/682_mi-indomie_F_crop_0.jpg: 256x640 1 text, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/682_mi-indomie_F_crop_1.jpg: 608x640 2 texts, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/682_mi-indomie_F_crop_2.jpg: 448x640 5 texts, 8.8ms\n",
      "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/683_mi-indomie_F_crop_0.jpg: 224x640 1 text, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/683_mi-indomie_F_crop_1.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/683_mi-indomie_F_crop_2.jpg: 352x640 3 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/684_nuoc-uong-vi-sua-chua-goodmood_F_crop_0.jpg: 256x640 5 texts, 9.7ms\n",
      "Speed: 1.2ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/684_nuoc-uong-vi-sua-chua-goodmood_F_crop_1.jpg: 544x640 2 texts, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/685_nuoc-uong-vi-sua-chua-goodmood_T_crop_0.jpg: 320x640 1 text, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/685_nuoc-uong-vi-sua-chua-goodmood_T_crop_1.jpg: 256x640 1 text, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/686_nuoc-uong-vi-sua-chua-goodmood_B_crop_0.jpg: 640x640 2 texts, 8.5ms\n",
      "Speed: 2.4ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/686_nuoc-uong-vi-sua-chua-goodmood_B_crop_1.jpg: 320x640 5 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/686_nuoc-uong-vi-sua-chua-goodmood_B_crop_2.jpg: 384x640 2 texts, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/687_sua-dau-nanh_F_crop_0.jpg: 224x640 3 texts, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/687_sua-dau-nanh_F_crop_1.jpg: 576x640 2 texts, 9.1ms\n",
      "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/688_sua-dau-nanh_T_crop_0.jpg: 352x640 1 text, 9.4ms\n",
      "Speed: 1.3ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Processed: 2150/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/688_sua-dau-nanh_T_crop_1.jpg: 352x640 1 text, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/689_grass-jelly-drink_F_crop_0.jpg: 640x640 2 texts, 8.7ms\n",
      "Speed: 2.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/689_grass-jelly-drink_F_crop_1.jpg: 640x320 3 texts, 9.3ms\n",
      "Speed: 1.5ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/689_grass-jelly-drink_F_crop_2.jpg: 512x640 2 texts, 9.0ms\n",
      "Speed: 1.7ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/689_grass-jelly-drink_F_crop_3.jpg: 160x640 1 text, 9.4ms\n",
      "Speed: 0.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/689_grass-jelly-drink_F_crop_4.jpg: 160x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/690_nutri-boostf_F_crop_0.jpg: 544x640 2 texts, 8.8ms\n",
      "Speed: 2.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/690_nutri-boostf_F_crop_1.jpg: 288x640 2 texts, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/691_nuoc-cam-ep_F_crop_0.jpg: 448x640 2 texts, 9.3ms\n",
      "Speed: 1.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/691_nuoc-cam-ep_F_crop_1.jpg: 192x640 3 texts, 9.6ms\n",
      "Speed: 0.9ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/692_nuoc-cam-ep_D_crop_0.jpg: 448x640 1 text, 9.2ms\n",
      "Speed: 1.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/692_nuoc-cam-ep_D_crop_1.jpg: 384x640 1 text, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/693_redbull_F_crop_0.jpg: 256x640 1 text, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/694_redull_D_crop_0.jpg: 224x640 1 text, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/694_redull_D_crop_1.jpg: 288x640 1 text, 9.6ms\n",
      "Speed: 1.2ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/695_dau-phong-da-ca-cot-dua_F_crop_0.jpg: 416x640 2 texts, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/695_dau-phong-da-ca-cot-dua_F_crop_1.jpg: 320x640 6 texts, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/695_dau-phong-da-ca-cot-dua_F_crop_2.jpg: 352x640 2 texts, 9.5ms\n",
      "Speed: 1.3ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/696_hat-dieu-original_F_crop_0.jpg: 128x640 3 texts, 11.3ms\n",
      "Speed: 0.8ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/696_hat-dieu-original_F_crop_1.jpg: 384x640 2 texts, 9.3ms\n",
      "Speed: 1.4ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/697_hat-dieu-original_B_crop_0.jpg: 192x640 3 texts, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/697_hat-dieu-original_B_crop_1.jpg: 160x640 3 texts, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/697_hat-dieu-original_B_crop_2.jpg: 640x640 2 texts, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/698_dau-phong-nuoc-cot-dua_F_crop_0.jpg: 256x640 2 texts, 9.5ms\n",
      "Speed: 1.2ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/698_dau-phong-nuoc-cot-dua_F_crop_1.jpg: 320x640 5 texts, 9.6ms\n",
      "Speed: 1.2ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/698_dau-phong-nuoc-cot-dua_F_crop_2.jpg: 288x640 2 texts, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/699_dau-phong-nuoc-cot-dua_D_crop_0.jpg: 288x640 1 text, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/699_dau-phong-nuoc-cot-dua_D_crop_1.jpg: 256x640 1 text, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/700_banh-goute_F_crop_0.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/700_banh-goute_F_crop_1.jpg: 224x640 5 texts, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/700_banh-goute_F_crop_2.jpg: 288x640 2 texts, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/701_banh-gote_D_crop_0.jpg: 192x640 1 text, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/701_banh-gote_D_crop_1.jpg: 224x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/701_banh-gote_D_crop_2.jpg: 96x640 7 texts, 9.8ms\n",
      "Speed: 0.5ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/702_banh-xop-que_F_crop_0.jpg: 640x352 2 texts, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 352)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/702_banh-xop-que_F_crop_1.jpg: 192x640 3 texts, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/703_banh-xop-que_B_crop_0.jpg: 192x640 1 text, 9.1ms\n",
      "Speed: 0.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/703_banh-xop-que_B_crop_1.jpg: 192x640 1 text, 8.3ms\n",
      "Speed: 0.7ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/703_banh-xop-que_B_crop_2.jpg: 256x640 2 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/704_banh-quy-dua_F_crop_0.jpg: 128x640 1 text, 9.1ms\n",
      "Speed: 0.6ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/704_banh-quy-dua_F_crop_1.jpg: 256x640 1 text, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/704_banh-quy-dua_F_crop_2.jpg: 160x640 3 texts, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/704_banh-quy-dua_F_crop_3.jpg: 128x640 1 text, 9.0ms\n",
      "Speed: 0.6ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/705_banh-quy-dua_F_crop_0.jpg: 128x640 3 texts, 8.2ms\n",
      "Speed: 0.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/705_banh-quy-dua_F_crop_1.jpg: 352x640 2 texts, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/705_banh-quy-dua_F_crop_2.jpg: 352x640 2 texts, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/706_ca-phe-sua-nong_F_crop_0.jpg: 256x640 3 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/706_ca-phe-sua-nong_F_crop_1.jpg: 256x640 4 texts, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/706_ca-phe-sua-nong_F_crop_2.jpg: 352x640 2 texts, 11.1ms\n",
      "Speed: 1.2ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/707_ca-phe-sua-nong_B_crop_0.jpg: 224x640 3 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Processed: 2200/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/707_ca-phe-sua-nong_B_crop_1.jpg: 128x640 4 texts, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/707_ca-phe-sua-nong_B_crop_2.jpg: 128x640 1 text, 14.3ms\n",
      "Speed: 0.8ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/707_ca-phe-sua-nong_B_crop_3.jpg: 288x640 4 texts, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/708_tra-huong-lai_F_crop_0.jpg: 160x640 2 texts, 9.5ms\n",
      "Speed: 0.7ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/708_tra-huong-lai_F_crop_1.jpg: 192x640 3 texts, 9.3ms\n",
      "Speed: 0.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/708_tra-huong-lai_F_crop_2.jpg: 448x640 2 texts, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/708_tra-huong-lai_F_crop_3.jpg: 480x640 2 texts, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/709_tra-huong-lai_B_crop_0.jpg: 640x160 5 texts, 8.8ms\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 160)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/709_tra-huong-lai_B_crop_1.jpg: 640x128 1 text, 9.1ms\n",
      "Speed: 0.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/710_tra-huong-dao_F_crop_0.jpg: 384x640 1 text, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/710_tra-huong-dao_F_crop_1.jpg: 416x640 4 texts, 8.8ms\n",
      "Speed: 1.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/711_tra-huong-dao_B_crop_0.jpg: 576x640 2 texts, 8.7ms\n",
      "Speed: 1.9ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/711_tra-huong-dao_B_crop_1.jpg: 160x640 3 texts, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/711_tra-huong-dao_B_crop_2.jpg: 160x640 1 text, 8.7ms\n",
      "Speed: 0.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/711_tra-huong-dao_B_crop_3.jpg: 160x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/712_tra-vai-huong-hoa-hong_F_crop_0.jpg: 512x640 2 texts, 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/712_tra-vai-huong-hoa-hong_F_crop_1.jpg: 288x640 1 text, 9.7ms\n",
      "Speed: 1.4ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/712_tra-vai-huong-hoa-hong_F_crop_2.jpg: 448x640 5 texts, 8.8ms\n",
      "Speed: 1.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/712_tra-vai-huong-hoa-hong_F_crop_3.jpg: 384x640 2 texts, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/713_tra-vai-huong-hoa-hong_B_crop_0.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/713_tra-vai-huong-hoa-hong_B_crop_1.jpg: 160x640 1 text, 8.9ms\n",
      "Speed: 0.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/714_tra-vi-vai-va-huong-hoa-lai_F_crop_0.jpg: 96x640 7 texts, 10.2ms\n",
      "Speed: 0.7ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/714_tra-vi-vai-va-huong-hoa-lai_F_crop_1.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/714_tra-vi-vai-va-huong-hoa-lai_F_crop_2.jpg: 384x640 2 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/715_tra-vi-vai-va-huong-hoa-lai_D_crop_0.jpg: 224x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/715_tra-vi-vai-va-huong-hoa-lai_D_crop_1.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/716_tra-gung_F_crop_0.jpg: 288x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/716_tra-gung_F_crop_1.jpg: 224x640 2 texts, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/717_tra-gung_B_crop_0.jpg: 256x640 1 text, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/717_tra-gung_B_crop_1.jpg: 192x640 1 text, 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/717_tra-gung_B_crop_2.jpg: 192x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/717_tra-gung_B_crop_3.jpg: 192x640 1 text, 8.4ms\n",
      "Speed: 0.8ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/718_milo_F_crop_0.jpg: 224x640 1 text, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/718_milo_F_crop_1.jpg: 224x640 1 text, 8.4ms\n",
      "Speed: 1.1ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/718_milo_F_crop_2.jpg: 288x640 2 texts, 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/719_milo_B_crop_0.jpg: 224x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/720_milo_F_crop_0.jpg: 288x640 1 text, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/720_milo_F_crop_1.jpg: 288x640 1 text, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/720_milo_F_crop_2.jpg: 256x640 1 text, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/721_milo_B_crop_0.jpg: 192x640 3 texts, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/721_milo_B_crop_1.jpg: 192x640 3 texts, 8.1ms\n",
      "Speed: 0.8ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/721_milo_B_crop_2.jpg: 256x640 1 text, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/722_kem-dac-co-duong_F_crop_0.jpg: 224x640 2 texts, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/722_kem-dac-co-duong_F_crop_1.jpg: 192x640 4 texts, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/722_kem-dac-co-duong_F_crop_2.jpg: 256x640 2 texts, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/722_kem-dac-co-duong_F_crop_3.jpg: 224x640 9 texts, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/723_kem-dac-co-duong_T_crop_0.jpg: 224x640 1 text, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/724_kem-dac-co-duong_F_crop_0.jpg: 448x640 2 texts, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/724_kem-dac-co-duong_F_crop_1.jpg: 320x640 1 text, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/724_kem-dac-co-duong_F_crop_2.jpg: 256x640 1 text, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Processed: 2250/2284\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/724_kem-dac-co-duong_F_crop_3.jpg: 96x640 4 texts, 9.9ms\n",
      "Speed: 0.6ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/724_kem-dac-co-duong_F_crop_4.jpg: 352x640 3 texts, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/725_hat-chia_F_crop_0.jpg: 192x640 1 text, 10.0ms\n",
      "Speed: 0.9ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/725_hat-chia_F_crop_1.jpg: 160x640 1 text, 8.5ms\n",
      "Speed: 0.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/725_hat-chia_F_crop_2.jpg: 160x640 1 text, 8.4ms\n",
      "Speed: 0.7ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/725_hat-chia_F_crop_3.jpg: 192x640 2 texts, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/725_hat-chia_F_crop_4.jpg: 288x640 2 texts, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/726_hat-chia_F_crop_0.jpg: 128x640 1 text, 10.2ms\n",
      "Speed: 0.7ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/726_hat-chia_F_crop_1.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/726_hat-chia_F_crop_2.jpg: 192x640 1 text, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/726_hat-chia_F_crop_3.jpg: 160x640 2 texts, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/726_hat-chia_F_crop_4.jpg: 320x640 2 texts, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/727_yen-mach-nep-cam_F_crop_0.jpg: 352x640 1 text, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/727_yen-mach-nep-cam_F_crop_1.jpg: 288x640 4 texts, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/727_yen-mach-nep-cam_F_crop_2.jpg: 416x640 2 texts, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/728_yen-mach-nep-cam_B_crop_0.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/728_yen-mach-nep-cam_B_crop_1.jpg: 192x640 1 text, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/729_milo_F_crop_0.jpg: 224x640 1 text, 9.5ms\n",
      "Speed: 0.9ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/729_milo_F_crop_1.jpg: 256x640 1 text, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/729_milo_F_crop_2.jpg: 224x640 3 texts, 9.6ms\n",
      "Speed: 0.9ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/730_milo_B_crop_0.jpg: 224x640 1 text, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/730_milo_B_crop_1.jpg: 384x640 2 texts, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/731_milo_F_crop_0.jpg: 288x640 1 text, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/731_milo_F_crop_1.jpg: 224x640 1 text, 9.6ms\n",
      "Speed: 1.1ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/731_milo_F_crop_2.jpg: 192x640 3 texts, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/731_milo_F_crop_3.jpg: 352x640 2 texts, 9.3ms\n",
      "Speed: 1.3ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/732_dau-goi-duoc-lieu-hoa-phong-lan_F_crop_0.jpg: 352x640 3 texts, 8.4ms\n",
      "Speed: 1.7ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/732_dau-goi-duoc-lieu-hoa-phong-lan_F_crop_1.jpg: 224x640 7 texts, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/732_dau-goi-duoc-lieu-hoa-phong-lan_F_crop_2.jpg: 256x640 2 texts, 9.5ms\n",
      "Speed: 1.1ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/733_dau-goi-duoc-lieu-hoa-phong-lan_F_crop_0.jpg: 320x640 3 texts, 9.9ms\n",
      "Speed: 1.6ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/733_dau-goi-duoc-lieu-hoa-phong-lan_F_crop_1.jpg: 192x640 7 texts, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/733_dau-goi-duoc-lieu-hoa-phong-lan_F_crop_2.jpg: 224x640 2 texts, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/nckh-2425-crops/734_dau-goi-duoc-lieu-hoa-phong-lan_D_crop_0.jpg: 160x640 1 text, 9.2ms\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n"
     ]
    }
   ],
   "source": [
    "df = read_annotations(CSV_ANN)\n",
    "\n",
    "results = []\n",
    "for idx, row in df.iterrows():\n",
    "    fname = row['filename']\n",
    "    desc_gt = row['description_gt']\n",
    "    label = row.get('label', '')\n",
    "    img_path = os.path.join(IMG_DIR, fname)\n",
    "\n",
    "    try:\n",
    "        t1 = time.perf_counter()\n",
    "        pred = yolo_ocr_pipeline(img_path, conf_threshold=0.5, y_threshold=80)\n",
    "        t2 = time.perf_counter()\n",
    "        infer_time = round(t2 - t1, 3)\n",
    "    except Exception as e:\n",
    "        pred = f\"OCR_Error: {e}\"\n",
    "        infer_time = 0.0\n",
    "\n",
    "    metrics = compute_metrics(desc_gt, pred)\n",
    "\n",
    "    results.append({\n",
    "        \"filename\": fname,\n",
    "        \"label\": label,\n",
    "        \"ground_truth\": desc_gt,\n",
    "        \"predicted_text\": pred,\n",
    "        \"cer\": metrics[\"cer\"],\n",
    "        \"wer\": metrics[\"wer\"],\n",
    "        \"lev\": metrics[\"lev\"],\n",
    "        \"acc\": metrics[\"acc\"],\n",
    "        \"time\": infer_time\n",
    "    })\n",
    "    if idx % 50 == 0:\n",
    "        print(f\"Processed: {idx}/{len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T10:49:09.835799Z",
     "iopub.status.busy": "2025-07-13T10:49:09.835221Z",
     "iopub.status.idle": "2025-07-13T10:49:09.864428Z",
     "shell.execute_reply": "2025-07-13T10:49:09.863721Z",
     "shell.execute_reply.started": "2025-07-13T10:49:09.835773Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lưu thành công: /kaggle/working/compare_ocr_benchmark/results/cnntr_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "OUT_CSV = '/kaggle/working/compare_ocr_benchmark/results/cnntr_results.csv'\n",
    "os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
    "save_results(results, OUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7549834,
     "sourceId": 12001849,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 399222,
     "modelInstanceId": 379243,
     "sourceId": 470110,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
