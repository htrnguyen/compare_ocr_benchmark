{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":12001849,"datasetId":7549834,"databundleVersionId":12518958},{"sourceType":"datasetVersion","sourceId":12180218,"datasetId":7636080,"databundleVersionId":12717688},{"sourceType":"modelInstanceVersion","sourceId":470181,"databundleVersionId":13029414,"modelInstanceId":379303}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":" !git clone https://github.com/htrnguyen/vietocr.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-13T11:58:56.042085Z","iopub.execute_input":"2025-07-13T11:58:56.042315Z","iopub.status.idle":"2025-07-13T11:58:57.278691Z","shell.execute_reply.started":"2025-07-13T11:58:56.042291Z","shell.execute_reply":"2025-07-13T11:58:57.277900Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'vietocr'...\nremote: Enumerating objects: 3301, done.\u001b[K\nremote: Counting objects: 100% (805/805), done.\u001b[K\nremote: Compressing objects: 100% (131/131), done.\u001b[K\nremote: Total 3301 (delta 729), reused 691 (delta 673), pack-reused 2496 (from 2)\u001b[K\nReceiving objects: 100% (3301/3301), 3.83 MiB | 37.35 MiB/s, done.\nResolving deltas: 100% (2445/2445), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import sys, os, time\nimport torch\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nsys.path.append('/kaggle/working/vietocr')\nfrom vietocr.tool.config import Cfg\nfrom vietocr.tool.predictor import Predictor\n\n# Đảm bảo dùng GPU nếu có\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)\n\n# Đường dẫn dữ liệu và model\nDATA_ROOT = '/kaggle/input/nckh-2425-crops'\nCSV_ANN = '/kaggle/input/nckh-2425-crops/crops_gt.csv'\nWEIGHT_PATH = '/kaggle/input/vietocr_fineturning/gguf/default/1/transformerocr.pth'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T11:58:57.280515Z","iopub.execute_input":"2025-07-13T11:58:57.280762Z","iopub.status.idle":"2025-07-13T11:59:08.024202Z","shell.execute_reply.started":"2025-07-13T11:58:57.280736Z","shell.execute_reply":"2025-07-13T11:59:08.023591Z"}},"outputs":[{"name":"stdout","text":"Device: cuda:0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def extract_vocab_from_labels(label_files):\n    chars = set()\n    for fpath in label_files:\n        with open(fpath, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                try:\n                    _, label = line.strip().split(\"\\t\")\n                    chars.update(label)\n                except:\n                    continue\n    return \"\".join(sorted(chars))\n\nvocab = extract_vocab_from_labels([\n    '/kaggle/input/vietocr-data-pretrain/dataset/test_annotation.txt',\n    '/kaggle/input/vietocr-data-pretrain/dataset/train_annotation.txt'\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T11:59:08.024910Z","iopub.execute_input":"2025-07-13T11:59:08.025557Z","iopub.status.idle":"2025-07-13T11:59:08.064050Z","shell.execute_reply.started":"2025-07-13T11:59:08.025536Z","shell.execute_reply":"2025-07-13T11:59:08.063546Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"config = Cfg.load_config_from_name(\"vgg_transformer\")\nconfig[\"vocab\"] = vocab\nconfig[\"weights\"] = WEIGHT_PATH\nconfig[\"device\"] = device\npredictor = Predictor(config)\nconfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T11:59:11.800201Z","iopub.execute_input":"2025-07-13T11:59:11.800695Z","iopub.status.idle":"2025-07-13T11:59:47.769877Z","shell.execute_reply.started":"2025-07-13T11:59:11.800670Z","shell.execute_reply":"2025-07-13T11:59:47.769088Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /root/.cache/torch/hub/checkpoints/vgg19_bn-c79401a0.pth\n100%|██████████| 548M/548M [00:30<00:00, 18.8MB/s] \n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'vocab': \" !%&'(),-./0123456789:ABCDEFGHIJKLMNOPQRSTUVWXYZ\\\\abcdefghijklmnopqrstuvwxyzÀÁÂÈÉÊÌÍÒÓÔÙÚÝàáâãèéêìíòóôùúĂăĐđĨŨũŪƠơƯưẠạẢảẤấẦầẨẩẫẬậẮắẰằẵẶặẸẹẺẻẾếỀềỂểỄỆệỉỊịỌọỎỏỐốỒồỔổỖỘộỚớỜờỞởỠỡỢợỤụỦủỨứỪừỬửỮữỰựỲỸ\",\n 'device': 'cuda:0',\n 'seq_modeling': 'transformer',\n 'transformer': {'d_model': 256,\n  'nhead': 8,\n  'num_encoder_layers': 6,\n  'num_decoder_layers': 6,\n  'dim_feedforward': 2048,\n  'max_seq_length': 1024,\n  'pos_dropout': 0.1,\n  'trans_dropout': 0.1},\n 'optimizer': {'max_lr': 0.0003, 'pct_start': 0.1},\n 'trainer': {'batch_size': 32,\n  'print_every': 200,\n  'valid_every': 4000,\n  'iters': 100000,\n  'export': './weights/transformerocr.pth',\n  'checkpoint': './checkpoint/transformerocr_checkpoint.pth',\n  'log': './train.log',\n  'metrics': None},\n 'dataset': {'name': 'data',\n  'data_root': './img/',\n  'train_annotation': 'annotation_train.txt',\n  'valid_annotation': 'annotation_val_small.txt',\n  'image_height': 32,\n  'image_min_width': 32,\n  'image_max_width': 512},\n 'dataloader': {'num_workers': 3, 'pin_memory': True},\n 'aug': {'image_aug': True, 'masked_language_model': True},\n 'predictor': {'beamsearch': False},\n 'quiet': False,\n 'pretrain': 'https://vocr.vn/data/vietocr/vgg_transformer.pth',\n 'weights': '/kaggle/input/vietocr_fineturning/gguf/default/1/transformerocr.pth',\n 'backbone': 'vgg19_bn',\n 'cnn': {'pretrained': True,\n  'ss': [[2, 2], [2, 2], [2, 1], [2, 1], [1, 1]],\n  'ks': [[2, 2], [2, 2], [2, 1], [2, 1], [1, 1]],\n  'hidden': 256}}"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"!git clone https://github.com/htrnguyen/compare_ocr_benchmark.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T11:59:47.771267Z","iopub.execute_input":"2025-07-13T11:59:47.771585Z","iopub.status.idle":"2025-07-13T11:59:49.482677Z","shell.execute_reply.started":"2025-07-13T11:59:47.771566Z","shell.execute_reply":"2025-07-13T11:59:49.481974Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'compare_ocr_benchmark'...\nremote: Enumerating objects: 72, done.\u001b[K\nremote: Counting objects: 100% (72/72), done.\u001b[K\nremote: Compressing objects: 100% (45/45), done.\u001b[K\nremote: Total 72 (delta 30), reused 63 (delta 21), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (72/72), 4.09 MiB | 6.12 MiB/s, done.\nResolving deltas: 100% (30/30), done.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install python-Levenshtein jiwer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T11:59:49.483796Z","iopub.execute_input":"2025-07-13T11:59:49.484552Z","iopub.status.idle":"2025-07-13T11:59:55.531350Z","shell.execute_reply.started":"2025-07-13T11:59:49.484513Z","shell.execute_reply":"2025-07-13T11:59:55.530585Z"}},"outputs":[{"name":"stdout","text":"Collecting python-Levenshtein\n  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\nCollecting jiwer\n  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting Levenshtein==0.27.1 (from python-Levenshtein)\n  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.2.1)\nDownloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\nDownloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jiwer-4.0.0-py3-none-any.whl (23 kB)\nDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, jiwer, python-Levenshtein\nSuccessfully installed Levenshtein-0.27.1 jiwer-4.0.0 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working/compare_ocr_benchmark/common')\nfrom metrics import compute_metrics\nfrom utils import save_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T11:59:55.532990Z","iopub.execute_input":"2025-07-13T11:59:55.533198Z","iopub.status.idle":"2025-07-13T11:59:55.559882Z","shell.execute_reply.started":"2025-07-13T11:59:55.533175Z","shell.execute_reply":"2025-07-13T11:59:55.559341Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df = pd.read_csv(CSV_ANN)\n\nresults = []\nfor idx, row in df.iterrows():\n    fname = row['filename']\n    desc_gt = row['description_gt']\n    label = row.get('label', '')\n    img_path = os.path.join(DATA_ROOT, fname)\n\n    try:\n        image = Image.open(img_path).convert(\"RGB\")\n        t1 = time.perf_counter()\n        pred = predictor.predict(image)\n        t2 = time.perf_counter()\n        infer_time = round(t2 - t1, 3)\n    except Exception as e:\n        pred = f\"OCR_Error: {e}\"\n        infer_time = 0.0\n\n    # Dùng hàm metrics chung (import từ compare_ocr_benchmark/common/metrics.py)\n    from metrics import compute_metrics\n    metrics = compute_metrics(desc_gt, pred)\n\n    results.append({\n        \"filename\": fname,\n        \"label\": label,\n        \"ground_truth\": desc_gt,\n        \"predicted_text\": pred,\n        \"cer\": metrics[\"cer\"],\n        \"wer\": metrics[\"wer\"],\n        \"lev\": metrics[\"lev\"],\n        \"acc\": metrics[\"acc\"],\n        \"time\": infer_time\n    })\n    if idx % 50 == 0:\n        print(f\"Processed {idx}/{len(df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T11:59:55.560538Z","iopub.execute_input":"2025-07-13T11:59:55.560756Z","iopub.status.idle":"2025-07-13T12:02:54.039862Z","shell.execute_reply.started":"2025-07-13T11:59:55.560739Z","shell.execute_reply":"2025-07-13T12:02:54.039177Z"}},"outputs":[{"name":"stdout","text":"Processed 0/2284\nProcessed 50/2284\nProcessed 100/2284\nProcessed 150/2284\nProcessed 200/2284\nProcessed 250/2284\nProcessed 300/2284\nProcessed 350/2284\nProcessed 400/2284\nProcessed 450/2284\nProcessed 500/2284\nProcessed 550/2284\nProcessed 600/2284\nProcessed 650/2284\nProcessed 700/2284\nProcessed 750/2284\nProcessed 800/2284\nProcessed 850/2284\nProcessed 900/2284\nProcessed 950/2284\nProcessed 1000/2284\nProcessed 1050/2284\nProcessed 1100/2284\nProcessed 1150/2284\nProcessed 1200/2284\nProcessed 1250/2284\nProcessed 1300/2284\nProcessed 1350/2284\nProcessed 1400/2284\nProcessed 1450/2284\nProcessed 1500/2284\nProcessed 1550/2284\nProcessed 1600/2284\nProcessed 1650/2284\nProcessed 1700/2284\nProcessed 1750/2284\nProcessed 1800/2284\nProcessed 1850/2284\nProcessed 1900/2284\nProcessed 1950/2284\nProcessed 2000/2284\nProcessed 2050/2284\nProcessed 2100/2284\nProcessed 2150/2284\nProcessed 2200/2284\nProcessed 2250/2284\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nOUT_CSV = '/kaggle/working/compare_ocr_benchmark/results/vietocr_pretrain_results.csv'\nos.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\nsave_results(results, OUT_CSV)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T12:02:54.041255Z","iopub.execute_input":"2025-07-13T12:02:54.041539Z","iopub.status.idle":"2025-07-13T12:02:54.071230Z","shell.execute_reply.started":"2025-07-13T12:02:54.041513Z","shell.execute_reply":"2025-07-13T12:02:54.070626Z"}},"outputs":[{"name":"stdout","text":"Lưu thành công: /kaggle/working/compare_ocr_benchmark/results/vietocr_pretrain_results.csv\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}